namespace: UKG PRO
groups:
  - name: Default - Infrastructure Alerts
    interval: 1m
    rules:
      # CPU monitoring
      - alert: '[Alert] : DimCritical : P1 : ALL : CPU Usage (Above 95%)'
        expr: '(100 - (avg by(instance,service_name) (rate(node_cpu_seconds_total{mode="idle",instance!~".*ans.*|.*log.*"}[5m])) * 100) > 95)'
        for: 30m
        labels:
          severity: critical
          route: pagerduty_dim_rules
          wfm_service: true
        annotations:
          summary: Host high CPU load (instance {{ $labels.instance }})
          description: "CPU load is > 95%\n  VALUE = {{ $value }}"
          SOPs: "API Gateway - https://engconf.int.kronos.com/display/AGT/SOP+-+FAILOVER+-+High+CPU+or+Memory+or+Disk+Usage+Observed\n Database/PPAS - https://engconf.int.kronos.com/display/CDS/SOP+%3A+ALERT+%3A+High+CPU+Usage\n ECS - https://engconf.int.kronos.com/display/ETS/CPU+Usage+Alert+SOP\n Integration service - https://engconf.int.kronos.com/display/Falcon/CPU+Usage+Alert+SOP\n Orchestration - https://engconf.int.kronos.com/display/CIA/SOP+-+FAILOVER+-+High+CPU+Usage\n RabbitMQ (hostname contains rmq) - https://engconf.int.kronos.com/display/FAR/RabbitMQ+Common+Alerts+and+SOP#RabbitMQCommonAlertsandSOP-[Alert]:DimCritical:P1:ALL:CPUUsage(Above95%)\n Redis (hostname contains dmc) - https://engconf.int.kronos.com/display/FAR/Redis+SOPs+and+Alerts\n Reporting Engine Service - https://engconf.int.kronos.com/display/PA/Engine-CPU+Usage\n Reporting Information Console - https://engconf.int.kronos.com/display/PA/InfoConsole+CPU+Usage\n TMS - https://engconf.int.kronos.com/display/FT/SOP+-+For+High+CPU+Usage+Observed\n Workflow service (Engine/Designer or Admin) - https://engconf.int.kronos.com/display/FT/SOP+-+FAILOVER+-+High+CPU+or+Memory+or+Disk+Usage+Observed\n OpenAM - https://engconf.int.kronos.com/display/FT/SOP+%3A+OpenAM+CPU+Usage+Alert\n Tenant Router - https://engconf.int.kronos.com/display/FT/SOP+%3A+TR+CPU+Usage+Alert\n UMS - https://engconf.int.kronos.com/display/FT/SOP+%3A+UMS+CPU+Usage+Alert\n WFM - https://engconf.int.kronos.com/pages/viewpage.action?pageId=758812004\n \nHead over to https://ukg.grafana.net/d/000000010/linux-servers?orgId=1 for further analysis"
          __dashboardUid__: 000000010
      - alert: '[TestAlert] : Testing Github Actions'
        expr: 'rate(Test_OTLP_Counter_Integer_total{job="spring-boot-otel-metric-demo2"}[5m]) > 0.1'
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: Test
          description: "Test"
  # Process monitoring
  - name: Cloud DBA
    interval: 1m
    rules:
      - alert: '[Alert] : Cloud DBA : P1 : UPC SQL Server Not Responding'
        expr: 'max_over_time(up{instance=~".*(db|ssn|vp|st[0-9]).*",job="integrations/windows_exporter",instance!~".*(i951|nx|ex|g02x).*"}[10m]) unless max_over_time(up{instance=~".*(db|ssn|vp|st[0-9]).*",instance=~".*(db|ssn|vp|st[0-9]).*",instance!~".*(i951|nx|ex|g02x).*",job="integrations/windows_exporter"}[5m])'
        for: 2m
        labels:
          severity: critical
          route: cloud_dba_pagerduty
        annotations:
          summary: SQL Server is not available (instance {{ $labels.instance }})
          description: "SQL Server is down and not responding"
          SOPs: "WIP"
      - alert: '[Alert] : Cloud DBA : P1 : UPC SQL Server Service Down'
        expr: 'windows_service_state{name=~"mssqlserver|sqlserveragent|msdtsserver150|sqlserverreportingservices",instance!~".*(ssn|dbn|old|new|i951|ex|nx|g02x).*"} < 1'
        for: 1m
        labels:
          severity: critical
          route: cloud_dba_pagerduty
        annotations:
          summary: SQL Server Service is down. (instance {{ $labels.instance }})
          description: "SQL Server Service is down and not responding"
          SOPs: "WIP"
      - alert: '[Alert] : Cloud DBA : P1 : UPC SQL Server CPU Usage High > 80%'
        expr: '(100 - (avg by(instance) (rate(windows_cpu_time_total{mode="idle",instance=~".*(db|ssn|vp|st[0-9]).*",instance!~".*i951.*"}[5m])) * 100) > 80)'
        for: 15m
        labels:
          severity: critical
          route: cloud_dba_pagerduty
        annotations:
          summary: CPU usage on host {{ $labels.instance }} is above 90%. The currect value is {{ $value | printf "%.2f" }}%.
          description: "High CPU usage on Windows host."
          SOPs: "WIP"
      - alert: '[Alert] : Cloud DBA : P2 : UPC SQL Server CPU Usage High Between 70%-80%'
        expr: '(100 - (avg by(instance) (rate(windows_cpu_time_total{mode="idle",instance=~".*(db|ssn|vp|st[0-9]).*",instance!~".*i951.*"}[5m])) * 100) > 70 < 80)'
        for: 15m
        labels:
          severity: warning
          route: cloud_dba_pagerduty
        annotations:
          summary: CPU usage on host {{ $labels.instance }} is above 90%. The currect value is {{ $value | printf "%.2f" }}%.
          description: "High CPU usage on Windows host."
          SOPs: "WIP"
      - alert: '[Alert] : Cloud DBA : P2 : UPC SQL Server Low Disk Space < 25% Free'
        expr: '100 - ((windows_logical_disk_free_bytes{volume!~"HarddiskVolume.*",volume=~"E:|S:|T:|U:",job=~"integrations/windows_exporter", instance=~".*(db|ssn|vp|st[0-9]).*",instance!~"e0sutedb.*",instance!~".*i951.*"} ) / (windows_logical_disk_size_bytes{volume!~"HarddiskVolume.*",volume=~"E:|S:|T:|U:", job=~"integrations/windows_exporter", instance=~".*(db|ssn|vp|st[0-9]).*",instance!~"e0sutedb.*",instance!~".*i951.*"})) * 100  > 75 < 85'
        for: 15m
        labels:
          severity: warning
          route: cloud_dba_pagerduty
        annotations:
          summary: Volume {{ $labels.volume }} is almost full on host {{ $labels.instance }}, more than 75% of space is used. The currect volume utilization is {{ $value | printf "%.2f" }}%.
          description: "Disk is almost full on Windows host."
          SOPs: "WIP"
      - alert: '[Alert] : Cloud DBA : P1 : UPC SQL Server Low Disk Space < 15% Free'
        expr: '100 - ((windows_logical_disk_free_bytes{volume!~"HarddiskVolume.*",volume=~"E:|S:|T:|U:",job=~"integrations/windows_exporter", instance=~".*(db|ssn|vp|st[0-9]).*",instance!~"e0sutedb.*",instance!~".*i951.*"} ) / (windows_logical_disk_size_bytes{volume!~"HarddiskVolume.*",volume=~"E:|S:|T:|U:", job=~"integrations/windows_exporter", instance=~".*(db|ssn|vp|st[0-9]).*",instance!~"e0sutedb.*",instance!~".*i951.*"})) * 100  > 85'
        for: 15m
        labels:
          severity: critical
          route: cloud_dba_pagerduty
        annotations:
          summary: Volume {{ $labels.volume }} is almost full on host {{ $labels.instance }}, more than 85% of space is used. The currect volume utilization is {{ $value | printf "%.2f" }}%.
          description: "Disk is almost full on Windows host."
          SOPs: "WIP"
      - alert: '[Alert] : Cloud DBA : P3 : UPC SQL Server Low Disk Space < 35% Free'
        expr: '100 - ((windows_logical_disk_free_bytes{volume!~"HarddiskVolume.*",volume=~"E:|S:|T:|U:",job=~"integrations/windows_exporter", instance=~".*(db|ssn|vp|st[0-9]).*",instance!~"e0sutedb.*",instance!~".*i951.*"} ) / (windows_logical_disk_size_bytes{volume!~"HarddiskVolume.*",volume=~"E:|S:|T:|U:", job=~"integrations/windows_exporter", instance=~".*(db|ssn|vp|st[0-9]).*",instance!~"e0sutedb.*",instance!~".*i951.*"})) * 100  > 65 < 75'
        for: 15m
        labels:
          severity: info
          route: cloud_dba_pagerduty
        annotations:
          summary: Volume {{ $labels.volume }} is almost full on host {{ $labels.instance }}, more than 65% of space is used. The currect volume utilization is {{ $value | printf "%.2f" }}%.
          description: "Disk is almost full on Windows host."
          SOPs: "WIP"
      - alert: '[Alert] : Cloud DBA : P1 : UPC databases in unhealthy state'
        expr: 'mssqlmi_health_database_offlinedbs{instance!~".*(i951|ex|nx|g02x).*"} > 0'
        for: 15m
        labels:
          severity: info
          route: cloud_dba_pagerduty
        annotations:
          summary: Databases on {{ $labels.instance }} are currently in an unhealthy state.
          description: "UPC Databases in unhealthy state"
          SOPs: "WIP"
      - alert: '[Alert] : Cloud DBA : P1 : UPC SQL Server with High TempDB Usage'
        expr: 'avg_over_time(mssqlmi_health_database_hightempdb{instance!~".*(i951|ez|nz|tz).*"}[10m]) == 1'
        for: 15m
        labels:
          severity: info
          route: cloud_dba_pagerduty
        annotations:
          summary: SQL Server, {{ $labels.instance }}, is having high TempDB usage.
          description: "UPC SQL Server with High TempDB Usage"
          SOPs: "WIP"
      - alert: '[Alert] : Cloud DBA : P1 : UPC SQL Server with Low Memory'
        expr: 'avg_over_time(mssqlmi_health_database_lowmemory{instance!~".*(i951).*"}[5m]) == 1'
        for: 15m
        labels:
          severity: info
          route: cloud_dba_pagerduty
        annotations:
          summary: SQL Server, {{ $labels.instance }}, has Low Memory.
          description: "UPC SQL Server with Low Memory"
          SOPs: "WIP"
      - alert: '[Alert] : Cloud DBA : P2 : UPC SQL Server Blocked Sessions'
        expr: 'avg_over_time(mssqlmi_health_database_blocking{instance!~".*(i951|ez|nz|tz|fnlco|970|e0i).*"}[2m]) == 1'
        for: 15m
        labels:
          severity: info
          route: cloud_dba_pagerduty
        annotations:
          summary: SQL Server, {{ $labels.instance }}, has blocked sessions
          description: "UPC SQL Server Blocked Sessions"
          SOPs: "WIP"             
      - alert: '[Alert] : Cloud DBA : P2 : UPC SQL Server Long running Transactions'
        expr: 'avg_over_time(mssqlmi_health_database_longrunning{instance!~".*(i951|ez|nz|tz|fnlco|970|e0i).*"}[5m]) == 1'
        for: 15m
        labels:
          severity: info
          route: cloud_dba_pagerduty
        annotations:
          summary: SQL Server, {{ $labels.instance }}, has long running transactions
          description: "UPC SQL Server has long running transactions"
          SOPs: "WIP" 
      - alert: '[Alert] : Cloud DBA : P1 : UPC SQL Server Trace causing contention'
        expr: '(avg by(instance) (rate(mssqlmi_wait_time_ms{wait_type="TRACEWRITE",instance=~".*(db|ssn|vp|st[0-9]).*",instance!~".*i951.*"}[2m]))) > 2000'
        for: 2m
        labels:
          severity: info
          route: cloud_dba_pagerduty
        annotations:
          summary: SQL Server, {{ $labels.instance }}, has a sql trace causing contention
          description: "UPC SQL Server has a sql trace running causing contention"
          SOPs: "WIP"   
  - name: Default - Process monitoring
    interval: 1m
    rules:
      - alert: '[Alert] : DimCritical : P1 : Process Check Failed : Antivirus'
        expr: '(sum by(groupname,instance,service_name,service_function) (namedprocess_namegroup_num_procs{groupname=~"ometascan|ometascan-node"} < 1) and on (instance) (sum by(groupname,instance,service_name,service_function) (namedprocess_namegroup_num_procs{groupname=~"splunk.*"}) > 0))'
        for: 5m
        labels:
          severity: critical
          route: pagerduty_dim_rules
          wfm_service: true
        annotations:
          summary: '{{ $labels.groupname }} process not running (instance {{ $labels.instance }})'
          description: '{{ $labels.groupname }} process count = {{ $value }}'
          __dashboardUid__: 7UCI70H4z
  - name: UKG Authn Auth0 Logstream Alerts - Prod
    rules:
      #Auditor Webhook Status
      - alert: (Critical) No communication with Auth0
        expr: |
          sum by(domain) (increase(auth0_logStream_http2xx_total{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}[5m])) <= 0 and 
          (sum by(domain) (increase(auth0_logStream_http4xx_total{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}[5m])) > 0 or
          sum by(domain) (increase(auth0_logStream_http5xx_total{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}[5m])) > 0)
        for: 30s
        labels:
          severity: critical
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: Auth0 Logstream no 2xx response
          description: "No communication with Auth0 Logstream in {{ $labels.domain }}"
          __dashboardUid__: edne83s2gydc0d
          __panelId__: '38'
  - name: UKG Authn ARS Alerts for System Metrics
    rules:
      # 5xx Response Count
      - alert: (Critical) AuthN Auditor 5xx Response Count Alert
        expr: (sum by(namespace) (increase(auth_auditor_http_code_http500_total{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}[1m]))) >= 5
        for: 5m
        labels:
          severity: critical
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: AuthN Auditor 5xx Response Count Alert
          description: "5xx response codes have been triggering in a given time in {{ $labels.namespace }}"
          __dashboardUid__: ra20C8PIz
          __panelId__: '73'
      # Unavailable Replicas
      - alert: (Critical) Unavailable Replicas in AuthN Auditor Reporting Service
        expr: (kube_deployment_spec_replicas{deployment="iam-ukg-authn-auditor", namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"} - on (namespace) kube_deployment_status_replicas_available{deployment="iam-ukg-authn-auditor",namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) > 0
        for: 5m
        labels:
          severity: critical
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: Unavailable Replicas in AuthN Auditor Reporting Service
          description: "1 or more ARS replicas have become available in {{ $labels.namespace }}"
          __dashboardUid__: ra20C8PIz
          __panelId__: '72'
      # Disk Space Usage
      - alert: (Critical) Disk Space Usage Past a Certain Threshold
        expr: (1- (sum by(pod, namespace) (disk_free_bytes{component="iam-ukg-authn-auditor", namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) / sum by(pod, namespace) (disk_total_bytes{component="iam-ukg-authn-auditor", namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}))) > 0.7
        for: 5m
        labels:
          severity: critical
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: Disk Space Usage Past a Certain Threshold
          description: "ARS disk space usage past a certain threshold in {{$labels.namespace}} {{$labels.pod}}"
          __dashboardUid__: ra20C8PIz
          __panelId__: '52'
      # Container Usage Alert > 70
      - alert: (Critical) Container Memory Usage Above 70%
        expr: (sum by(pod, namespace) (container_memory_working_set_bytes{container="iam-ukg-authn-auditor", namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})/sum by(pod, namespace) (kube_pod_container_resource_limits{container="iam-ukg-authn-auditor", namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", resource="memory"})) >= 0.7
        for: 5m
        labels:
          severity: critical
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: Container Memory Usage Above 70%
          description: "Container Memory Usage past 70% {{$labels.namespace}} {{$labels.pod}}"
          __dashboardUid__: ra20C8PIz
          __panelId__: '76'
  - name: UKG Authn ARS Auth0 Alerts - Prod
    rules:
      #Auditor
      #Blocked Account
      - alert: (WARNING) Blocked Account
        expr: (sum by(domain) (increase(auth0_events_total{type="limit_wc"}[5m]))) > 10
        for: 1m
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: Blocked Accounts
          description: "Multiple IP address are blocked because they reached the maximum failed login attempts into a single account in {{ $labels.domain }}"
          __dashboardUid__: edne83s2gydc0d
          __panelId__: '10'
      #Blocked IP address
      - alert: (WARNING) Blocked IP Address
        expr: (sum by(domain) (increase(auth0_events_total{type="limit_mu"}[5m]))) > 10
        for: 1m
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: Blocked IP Address
          description: "Multiple IP address are blocked because of too many failed logins without a successful login in {{ $labels.domain }}"
          __dashboardUid__: edne83s2gydc0d
          __panelId__: '11'
      #Rate Limit
      - alert: (CRITICAL) API Rate Limit
        expr: (sum by(domain) (increase(auth0_events_total{type="api_limit"}[10m]))) > 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_dev
        annotations:
          summary: Auth0 Api Rate Limit
          description: "The maximum number of requests to the Authentication or Management APIs in a given time has been reached in {{ $labels.domain }}"
          __dashboardUid__: edne83s2gydc0d
          __panelId__: '14'
      # Failed MFA Enrollment
      - alert: (WARNING) MFA Enrollment Failed
        expr: sum by(domain) (increase(auth0_events_total{type="gd_start_enroll_failed"}[1s])) > 0
        for: 1s
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: MFA Enrollment Failed
          description: "User failed MFA enrollment in {{ $labels.domain }}"
          __dashboardUid__: edne83s2gydc0d
          __panelId__: '29'
      # Failed SSO Login
      - alert: (WARNING) Failed SSO Login
        expr: sum by(domain) (increase(auth0_events_total{type=~"f|fc|fco|fcoa|fens|fp|fu", strategy="samlp"}[1s])) > 0
        for: 1s
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: SSO Login
          description: "User failed to log in with SSO in {{ $labels.domain }}"
          __dashboardUid__: edne83s2gydc0d
          __panelId__: '31'
      # MFA
      - alert: (WARNING) Failed MFA Authentication
        expr: (sum by(domain) (increase(auth0_events_total{type="api_limit"}[10m]))) > 0
        for: 10m
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: MFA
          description: "Users have been failing to authenticate with MFA for more than 10 minutes in {{ $labels.domain }}"
          __dashboardUid__: adns93ez09xxcc
          __panelId__: '1'
      # Email Notifications
      - alert: (WARNING) Failed Email Notifications
        expr: (sum by(domain) (increase(auth0_events_total{type="fn"}[10m]))) > 0
        for: 10m
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: Email
          description: "Email MFA notifications have been failing for more than 10 minutes in {{ $labels.domain }}"
          __dashboardUid__: adns93ez09xxcc
          __panelId__: '4'
      # SMS Notifications
      - alert: (WARNING) Failed SMS Notifications
        expr: (sum by(domain) (increase(auth0_events_total{type="gd_send_sms_failure"}[10m]))) > 0
        for: 10m
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: SMS
          description: "SMS MFA notifications have been failing for more than 10 minutes in {{ $labels.domain }}"
          __dashboardUid__: adns93ez09xxcc
          __panelId__: '2'
  - name: UKG Authn Synthetics Alerts
    interval: 5m
    rules:
      # Testing Alerts for Auth0 Access Tokens
      - alert: Failed to get Auth0 Access Token
        expr: (sum by(domain) (increase(auth_synthetic_clientCredentialFlowFails_total[5m]))) > 0
        for: 30s
        labels:
          severity: critical
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: Failed to get Auth0 Access Token
          description: "Failed to get an access token from Auth0 in {{ $labels.domain }}"
          __dashboardUid__: edne83s2gydc0d
          __panelId__: '34'
      #Test Health
      - alert: No test running
        expr: (sum by(domain) (increase(auth0_synthetic_TEST_RUN_total{namespace="ukg-authn-prod-us-east1"}[30m]))) <= 0
        for: 1m
        labels:
          severity: Warning
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: Synthetic Tests have stopped
          description: "Synthetic tests on {{ $labels.domain }} are not running at the expected time (Every 5 minutes). This could be because they are taking too long or are not running at all. Check dashboard"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '80'
      #AMS Health
      - alert: AMS Synthetic Health
        expr: (sum by(domain) (increase(auth0_synthetic_AMS_FAIL_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 2
        for: 30s
        labels:
          severity: Warning
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: AMS failed to respond
          description: "The synthetic test failed to communicate with AMS in {{ $labels.domain }}"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '81'
        #TCS Health
      - alert: TCS Synthetic Health
        expr: (sum by(domain) (increase(auth0_synthetic_TCS_FAIL_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 2
        for: 30s
        labels:
          severity: Warning
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: TCS failed to respond
          description: "The synthetic test failed to communicate with TCS in {{ $labels.domain }}"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '83'
      #SMS Health
      - alert: SMS Synthetic Health
        expr: (sum by(domain) (increase(auth0_synthetic_SMS_FAIL_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 2
        for: 30s
        labels:
          severity: Warning
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: SMS failed to respond
          description: "SMS test has failed in {{ $labels.domain }}. Could be due to a network issue or UI complications. Check dashboard to see if the failure is consistent"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '84'
      #Email Health
      - alert: EMAIL Synthetic Health
        expr: (sum by(domain) (increase(auth0_synthetic_EMAIL_FAIL_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 2
        for: 30s
        labels:
          severity: Warning
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: EMAIL failed to respond
          description: "Email test has failed in {{ $labels.domain }}. Could be due to a network issue or UI complications. Check dashboard to see if the failure is consistent"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '82'
      #Direct Login Health
      - alert: Direct Login Synthetic Health
        expr: (sum by(domain) (increase(auth0_synthetic_direct_login_fail_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 2
        for: 30s
        labels:
          severity: Warning
          route: UKG-AuthN-Pagerduty-Mail
        annotations:
          summary: Direct Login failed to respond
          description: "Direct Login test has failed in {{ $labels.domain }}. Could be due to a network issue or UI complications. Check dashboard to see if the failure is consistent"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '86'
      # Unavailable Replicas
      - alert: (Critical) Unavailable Replicas in AuthN A10Y Reporting Service
        expr: (kube_deployment_spec_replicas{deployment="ukg-authn-a10y-reporting", namespace="ukg-authn-prod-us-east1"} - on (namespace) kube_deployment_status_replicas_available{deployment="ukg-authn-a10y-reporting",namespace="ukg-authn-prod-us-east1"}) > 0
        for: 5m
        labels:
          severity: critical
          route: UKG-AuthN-Pagerduty-Mail
        annotations:
          summary: Unavailable Replicas in AuthN A10Y Reporting Service
          description: "1 or more A10Y replicas have become available in {{ $labels.namespace }}"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '72'
      #Client Credential Failures
      - alert: Client Credential Synthetic Failure
        expr: (sum by(domain) (increase(auth0_synthetic_CLIENT_CREDENTIAL_FAIL_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 1
        for: 30s
        labels:
          severity: Warning
          route: iam_ukgauthn_prod
        annotations:
          summary: Client Credential Failed
          description: "Client Credential has failed in {{ $labels.domain }}. Check dashboard to see if the failure is consistent"
          SOP: "https://engconf.int.kronos.com/display/FT/Client+Credential+Fail+SOP"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '100'
      #Client Grant Access Failures
      - alert: Client Grant Access Synthetic Failure
        expr: (sum by(domain) (increase(auth0_synthetic_CLIENT_GRANT_ACCESS_FAIL_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 1
        for: 30s
        labels:
          severity: Warning
          route: iam_ukgauthn_prod
        annotations:
          summary: Client Grant Access Failed
          description: "Client Grant Access has failed in {{ $labels.domain }}. Check dashboard to see if the failure is consistent"
          SOP: "https://engconf.int.kronos.com/display/FT/Grant+Client+Access+SOP"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '98'
      #Tenant Specific Client Failures
      - alert: Tenant Specific Client Synthetic Failure
        expr: (sum by(domain) (increase(auth0_synthetic_TENANT_SPECIFIC_CLIENT_FAIL_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 1
        for: 30s
        labels:
          severity: Warning
          route: iam_ukgauthn_prod
        annotations:
          summary: Tenant Specific Client Failed
          description: "Tenant Specific Client has failed in {{ $labels.domain }}. Check dashboard to see if the failure is consistent"
          SOP: "https://engconf.int.kronos.com/display/FT/Tenant+Specific+Client+Fail+SOP"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '99'
      #Reset Password Failures
      - alert: Reset Password Synthetic Failure
        expr: (sum by(domain) (increase(auth0_synthetic_RESET_PASSWORD_FAIL_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 1
        for: 30s
        labels:
          severity: Warning
          route: iam_ukgauthn_prod
        annotations:
          summary: Reset Password Failed
          description: "Reset Password has failed in {{ $labels.domain }}. Check dashboard to see if the failure is consistent"
          SOP: "https://engconf.int.kronos.com/display/FT/Reset+Password+Fail+SOP"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '96'
      #Create Bulk User Failures
      - alert: Create Bulk User Synthetic Failure
        expr: (sum by(domain) (increase(auth0_synthetic_CREATE_BULK_USER_FAIL_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 1
        for: 30s
        labels:
          severity: Warning
          route: iam_ukgauthn_prod
        annotations:
          summary: Create Bulk User Failed
          description: "Create Bulk User has failed in {{ $labels.domain }}. Check dashboard to see if the failure is consistent"
          SOP: "https://engconf.int.kronos.com/display/FT/Create+Bulk+User+Fail+SOP"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '106'
      #Create User Failures
      - alert: Create User Synthetic Failure
        expr: (sum by(domain) (increase(auth0_synthetic_CREATE_USER_FAIL_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 1
        for: 30s
        labels:
          severity: Warning
          route: iam_ukgauthn_prod
        annotations:
          summary: Create User Failed
          description: "Create User has failed in {{ $labels.domain }}. Check dashboard to see if the failure is consistent"
          SOP: "https://engconf.int.kronos.com/display/FT/Create+User+Fail+SOP"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '97'
      #Authorize MFA Code Failures
      - alert: Authorize MFA Code Synthetic Failure
        expr: (sum by(domain) (increase(auth0_synthetic_AUTHORIZE_MFA_CODE_FAIL_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 1
        for: 30s
        labels:
          severity: Warning
          route: iam_ukgauthn_prod
        annotations:
          summary: Authorize MFA Code Failed
          description: "Authorize MFA Code has failed in {{ $labels.domain }}. Check dashboard to see if the failure is consistent"
          SOP: "https://engconf.int.kronos.com/display/FT/Authorization+MFA+Code+Flow+SOP"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '94'
      #Authorize Code Failures
      - alert: Authorize Code Synthetic Failure
        expr: (sum by(domain) (increase(auth0_synthetic_AUTHORIZE_CODE_FAIL_total{namespace="ukg-authn-prod-us-east1"}[10m]))) >= 1
        for: 30s
        labels:
          severity: Warning
          route: iam_ukgauthn_prod
        annotations:
          summary: Authorize Code Failed
          description: "Authorize Code has failed in {{ $labels.domain }}. Check dashboard to see if the failure is consistent"
          SOP: "https://engconf.int.kronos.com/display/FT/Authorization+Code+Flow+SOP"
          __dashboardUid__: fdu4y8gdy2v40a
          __panelId__: '95'
  # Conversational Reporting Prod Alerts
  - name: Conversational Reporting - PRD
    rules:
      - alert: (Critical) Conversational Reporting - App Availability - PRD
        expr: (sum by(phase) (kube_pod_status_phase{namespace="conversational-reporting-prod", pod=~".*looker-explore-assistant-data-api.*", phase="Running"})) < 1
        for: 5m
        labels:
          severity: critical
          route: UKG-Conversational-Reporting-Mail
        annotations:
          summary: Conversational Reporting - All Pods Down - PRD
          description: "All Pods are down, for the application in the namespace conversational-reporting-prod. Please check and do the needful"
          __dashboardUid__: fdpv5k112fbwgc
          __panelId__: '33'
      - alert: (WARNING) Conversational Reporting - Minimum Pods Availability - PRD
        expr: (kube_horizontalpodautoscaler_status_current_replicas{namespace="conversational-reporting-prod", horizontalpodautoscaler="looker-explore-assistant-data-api"} - kube_horizontalpodautoscaler_spec_min_replicas{namespace="conversational-reporting-prod", horizontalpodautoscaler="looker-explore-assistant-data-api"}) < 0
        for: 5m
        labels:
          severity: warning
          route: UKG-Conversational-Reporting-Mail
        annotations:
          summary: Conversational Reporting - Min Pods Running  - PRD
          description: "Number of running pods are less than minimum replicas defined for conversational reporting application in the namespace conversational-reporting-prod. Please check and do the needful"
          __dashboardUid__: fdpv5k112fbwgc
          __panelId__: '32'
      - alert: (WARNING) Conversational Reporting - Maximum Pods Availability - PRD
        expr: (kube_horizontalpodautoscaler_status_current_replicas{namespace="conversational-reporting-prod", horizontalpodautoscaler="looker-explore-assistant-data-api"} - kube_horizontalpodautoscaler_spec_max_replicas{namespace="conversational-reporting-prod", horizontalpodautoscaler="looker-explore-assistant-data-api"}) >= 0
        for: 5m
        labels:
          severity: warning
          route: UKG-Conversational-Reporting-Mail
        annotations:
          summary: Conversational Reporting - Max Pods Running - PRD
          description: "Number of running pods have reached maximum limit in the namespace conversational-reporting-prod. Please check and do the needful"
          __dashboardUid__: fdpv5k112fbwgc
          __panelId__: '32'
      - alert: (WARNING) Conversational Reporting - High CPU Usage - PRD
        expr: (sum by (namespace)(kube_resourcequota{namespace="conversational-reporting-prod", resource="requests.cpu", type= "used"}) /sum by (namespace)(kube_resourcequota{namespace="conversational-reporting-prod", resource="requests.cpu", type= "hard"}) * 100) >= 90
        for: 5m
        labels:
          severity: warning
          route: UKG-Conversational-Reporting-Mail
        annotations:
          summary: Conversational Reporting - High CPU usage - PRD
          description: "CPU Usage is above 90% from last 5 mins in the namespace conversational-reporting-prod. Please check and do the needful."
          __dashboardUid__: fdpv5k112fbwgc
          __panelId__: '29'
      - alert: (WARNING) Conversational Reporting - High Memory Usage - PRD
        expr: (sum (container_memory_working_set_bytes{cluster_name="kc-p-fleet-1", namespace="conversational-reporting-prod", container="looker-explore-assistant-data-api"})by (container) / sum (kube_pod_container_resource_requests{cluster_name="kc-p-fleet-1", namespace="conversational-reporting-prod", container="looker-explore-assistant-data-api", resource="memory"}) by (container) * 100) >= 90
        for: 5m
        labels:
          severity: warning
          route: UKG-Conversational-Reporting-Mail
        annotations:
          summary: UKG-Conversational-Reporting-Mail - High Memory usage - PRD
          description: "Memory Usage is above 90% from last 5 mins in the namespace conversational-reporting-prod. Please check and do the needful."
          __dashboardUid__: fdpv5k112fbwgc
          __panelId__: '30'
 #Reporting hub alerting Pod crash
  - name: Reporting Hub - Prod
    rules:
      - alert: (Critical) Pod Unhealthy
        expr: (sum by(phase) (kube_pod_status_phase{namespace="ukg-reporting-hub", phase="Running", pod!="acceptance-tests"})) <= 1
        for: 5m
        labels:
          severity: critical
          route: Rhub_Mail
        annotations:
          summary: Reporting Hub - Pod Unhealthy
          description: "Please check and do the needful, as there are no running pods for Reporting Hub Prod : {{ $labels.namespace }}"
          __dashboardUid__: bdq49rcr931moa
          __panelId__: '1'
  # UKG AuthN Alerts Starts
  # Infra Alerts
  - name: IAM - UKG AuthN - Infra Alerts - PROD
    rules:
      - alert: (P2 - CRITICAL) CPU Utilization
        expr: (sum by (pod, namespace, container)(rate(container_cpu_usage_seconds_total{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", container!~"istio-proxy|account-management-bulk"}[5m])) / sum by (pod, namespace, container) (kube_pod_container_resource_requests{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", resource="cpu", container!~"istio-proxy|account-management-bulk"} * 6 )) * 100 >= 80
        for: 15m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: CPU Usage Above 80% for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}
          description: "CPU Usage is above 80% from last 15 mins for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}. Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/CPU+Usage+Alert+SOP"
      - alert: (P3 - WARNING) CPU Utilization
        expr: (sum by (pod, namespace, container)(rate(container_cpu_usage_seconds_total{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", container!~"istio-proxy|account-management-bulk"}[5m])) / sum by (pod, namespace, container)(kube_pod_container_resource_requests{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", resource="cpu", container!~"istio-proxy|account-management-bulk"} * 4) * 100) >= 70
        for: 15m
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: CPU Usage Above 70% for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}
          description: "CPU Usage is above 70% from last 15 mins for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}. Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/CPU+Usage+Alert+SOP"
      - alert: (P2 - CRITICAL) AMS Bulk CPU Utilization
        expr: (sum by (pod, namespace, container) (rate(container_cpu_usage_seconds_total{container!="istio-proxy", namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", pod=~".*management-bulk.*"}[5m])) / (sum by (pod, namespace, container) (kube_pod_container_resource_requests{container!="istio-proxy", namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", pod=~".*management-bulk.*", resource="cpu"}) * 16) * 100) >= 80
        for: 15m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: CPU Usage Above 80% for {{ $labels.container }} - {{ $labels.pod }} in {{ $labels.namespace }}
          description: "CPU Usage is above 80% from last 15 mins for {{ $labels.container }} - {{ $labels.pod }} in {{ $labels.namespace }}. Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/CPU+Usage+Alert+SOPs"
      - alert: (P3 - WARNING) AMS Bulk CPU Utilization
        expr: (sum by (pod, namespace, container) (rate(container_cpu_usage_seconds_total{container!="istio-proxy", namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", pod=~".*management-bulk.*"}[5m])) / (sum by (pod, namespace, container) (kube_pod_container_resource_requests{container!="istio-proxy", namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", pod=~".*management-bulk.*", resource="cpu"}) * 16) * 100) >= 70
        for: 15m
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: CPU Usage Above 70% for {{ $labels.container }} - {{ $labels.pod }} in {{ $labels.namespace }}
          description: "CPU Usage is above 70% from last 15 mins for {{ $labels.container }} - {{ $labels.pod }} in {{ $labels.namespace }}. Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/CPU+Usage+Alert+SOPs"
      - alert: (P2 - CRITICAL) Memory Utilization
        expr: (sum by (pod, namespace, container) (container_memory_working_set_bytes{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", container!="istio-proxy"}) / sum by (pod, namespace, container) (kube_pod_container_resource_limits{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", resource="memory", container!="istio-proxy"}) * 100) >= 80
        for: 15m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Memory Usage Above 80% for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}
          description: "Memory Usage is above 80% from last 15 mins for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}. Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Memory+Usage+Alert+SOP"
      - alert: (P3 - WARNING) Memory Utilization
        expr: (sum by (pod, namespace, container)(container_memory_working_set_bytes{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", container!="istio-proxy"}) / sum by (pod, namespace, container) (kube_pod_container_resource_limits{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", resource="memory", container!="istio-proxy"}) * 100) >= 70
        for: 15m
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: Memory Usage Above 70% for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}
          description: "Memory Usage is above 70% from last 15 mins for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}. Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Memory+Usage+Alert+SOP"
      - alert: (P2 - CRITICAL) Pod Replica Unavailability
        expr: ((sum by(deployment, namespace) (kube_deployment_spec_replicas{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) - (sum by (deployment, namespace)(kube_deployment_status_replicas_available{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}))) > 0
        for: 30m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: "Pod Replica is less than expected for {{ $labels.deployment }} in {{ $labels.namespace }}"
          description: "Pod Replica is less than expected for Deployment: {{ $labels.deployment }} in Namespace: {{ $labels.namespace }}"
          SOP: "https://engconf.int.kronos.com/display/FT/TCS+CMD+Health+Check+Failure+SOP"
      - alert: (P2 - CRITICAL) Container Restarts
        expr: ((sum by (pod, container, namespace)(increase(kube_pod_container_status_restarts_total{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", container!~"istio-proxy|nginx"}[2m])))) > 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Container is getting restarted for POD - {{ $labels.pod }} Container -  {{ $labels.container }} Namespace - {{ $labels.namespace }}
          description: "Container is getting restarted for POD - {{ $labels.pod }} Container -  {{ $labels.container }} Namespace - {{ $labels.namespace }}  Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Gateways+Health+Check+SOP"
  # Application Alerts
  - name: IAM - UKG AuthN - Application Alerts - PROD
    rules:
      - alert: (P2 - CRITICAL) 5xx Requests
        expr: (100 * (sum by (name, namespace)(increase(http_server_requests_seconds_count{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", status=~"5.."}[5m]))) / (sum by (name, namespace)(increase(http_server_requests_seconds_count{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}[5m])))) >= 50
        for: 15m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: More than 50% of the Requests are 5xx for {{ $labels.name }} in {{ $labels.namespace }}
          description: "More than 50% of the Requests are 5xx for {{ $labels.name }} in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/pages/viewpage.action?spaceKey=FT&title=5xx+failure+Alerts+SOP"
      - alert: (P2 - CRITICAL) Auth0 Authentication Failures
        expr: (sum by(name, namespace)(increase(ams_commons_auth0_authentication_total{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", name=~"account-management-bulk|account-management-cmd|account-management-query", counter_metric="failure"}[5m]))) >=4
        for: 15m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Auth0 Authentication Failures for {{ $labels.name }} in {{ $labels.namespace }}
          description: "4 or more than 4 Auth0 Authentication Failures are getting reported from last 15 mins for {{ $labels.name }} in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Auth0+Management+API+Failure+Alert+SOP"
      - alert: (P3 - WARNING) Auth0 Authentication Failures
        expr: (sum by(name, namespace)(increase(ams_commons_auth0_authentication_total{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", name=~"account-management-bulk|account-management-cmd|account-management-query", counter_metric="failure"}[5m]))) >=2
        for: 15m
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: Auth0 Authentication Failures for {{ $labels.name }} in {{ $labels.namespace }}
          description: "2 or more than 2 Auth0 Authentication Failures are getting reported from last 15 mins for {{ $labels.name }} in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Auth0+Management+API+Failure+Alert+SOP"
      - alert: (P2 - CRITICAL) SAML Proxy IDP Certificate Expiry
        expr: (sum by (IDP)(saml_idp_certificate_expiry_days{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", name="saml-proxy"})) < 45
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: SAML Proxy - IDP Certificate Expiring Soon for {{ $labels.IDP }}
          description: "IDP Certificate is expiring within 45 days for {{ $labels.IDP }} - Kindly check the alert for exact details. Please follow the SOP."
          __dashboardUid__: ddp0ncu11qnswd
          __panelId__: '6'
          SOP: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=721276091"
      - alert: (P3 - WARNING) API Failure
        expr: (sum by (status, uri, outcome, name, namespace) (increase(http_server_requests_seconds_count{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", status!~"2.."}[5m]))) > 0
        for: 1m
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: API Failure in {{ $labels.name }} Service in {{ $labels.namespace }} Namespace for URI- {{ $labels.uri }} Outcome- {{ $labels.outcome }} Status- {{ $labels.status }}
          description: "{{ $labels.name }} Service API Failure in {{ $labels.namespace }} -> URI: {{ $labels.uri }} Outcome: {{ $labels.outcome }} Status: {{ $labels.status }}"
      - alert: (P3 - WARNING) HTTP Request Rates Breach
        expr: (sum by (name,namespace) (rate(http_server_requests_seconds_count{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", uri!~"/actuator/health|/actuator/prometheus|/health.*|/prometheus|"}[5m]))) > 90
        for: 1m
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: HTTP Request Rate More Than 90 Req Per Second for {{ $labels.name }} Service in {{ $labels.namespace }} Environment
          description: "{{ $labels.name }} Service HTTP Request Rate More Than 90 req/sec in {{ $labels.namespace }} Environment"
          SOP: "https://engconf.int.kronos.com/display/FT/HTTP+Request+Rate+Alert+SOPs"
      - alert: (P2 - CRITICAL) HTTP Request Rates Breach
        expr: (sum by (name,namespace) (rate(http_server_requests_seconds_count{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", uri!~"/actuator/health|/actuator/prometheus|/health.*|/prometheus|"}[5m]))) > 100
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: HTTP Request Rate More Than 100 Req Per Second for {{ $labels.name }} Service in {{ $labels.namespace }} Environment
          description: "{{ $labels.name }} Service HTTP Request Rate More Than 90 req/sec in {{ $labels.namespace }} Environment"
          SOP: "https://engconf.int.kronos.com/display/FT/HTTP+Request+Rate+Alert+SOPs"
      - alert: (P3 - WARNING) HTTP Request Sucess Rate Less Than 99.9%
        expr: ((sum by (name, namespace)(increase(http_server_requests_seconds_count{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", status!~"5..", uri!~"/actuator/health|/actuator/prometheus|/health.*|/prometheus|"}[60m]))/ sum by (name, namespace)(increase(http_server_requests_seconds_count{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", uri!~"/actuator/health|/actuator/prometheus|/health.*|/prometheus|"}[60m]))) * 100) < 99.9
        for: 1m
        labels:
          severity: warning
          route: iam_ukgauthn_dev
        annotations:
          summary: HTTP Request Sucess Rate Less Than 99.9 % for {{ $labels.name }} Service in {{ $labels.namespace }} Environment
          description: "{{ $labels.name }} Service HTTP Request Sucess Rate Less Than 99.9 % in {{ $labels.namespace }} Environment"
          SOP: "https://engconf.int.kronos.com/display/FT/HTTP+Request+Success+Rate+Alert+SOPs"
      - alert: (P2 - CRITICAL) HTTP Request Sucess Rate Less Than 99%
        expr: ((sum by (name, namespace)(increase(http_server_requests_seconds_count{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", status!~"5..", uri!~"/actuator/health|/actuator/prometheus|/health.*|/prometheus|"}[60m]))/ sum by (name, namespace)(increase(http_server_requests_seconds_count{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)", uri!~"/actuator/health|/actuator/prometheus|/health.*|/prometheus|"}[60m]))) * 100) < 99
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: HTTP Request Sucess Rate Less Than 99% for {{ $labels.name }} Service in {{ $labels.namespace }} Environment
          description: "{{ $labels.name }} Service HTTP Request Sucess Rate Less Than 99% in {{ $labels.namespace }} Environment"
          SOP: "https://engconf.int.kronos.com/display/FT/HTTP+Request+Success+Rate+Alert+SOPs"
  # Application A10Y Alerts
  - name: IAM - UKG AuthN - Application A10Y Alerts - PROD
    rules:
      - alert: (P1 - CRITICAL) AM-Bulk A10Y
        expr: (a10y_AMS_BULK{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: AM-Bulk Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that AM-Bulk service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/AMS+Bulk+Health+Check+SOP"
      - alert: (P1 - CRITICAL) AM-CMD A10Y
        expr: (a10y_AMS_CMD{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: AM-CMD Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that AM-CMD service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/AMS+CMD+Health+Check+SOP"
      - alert: (P1 - CRITICAL) AM-Gateway A10Y
        expr: (a10y_AMS_Gateway{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: AM-Gateway Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that AM-Gateway service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Gateways+Health+Check+SOP"
      - alert: (P1 - CRITICAL) AM-Query A10Y
        expr: (a10y_AMS_QUERY{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: AM-Query Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that AM-Query service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/AMS+Query+Health+Check+SOP"
      - alert: (P1 - CRITICAL) Branding A10Y
        expr: (a10y_Branding{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Branding Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Branding service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Branding+Health+Check+SOP"
      - alert: (P1 - CRITICAL) Identity CCPA A10Y
        expr: (a10y_Identity_CCPA{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Identity CCPA Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Identity CCPA service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/idtentity-ccpa+Health+Check+Failure+SOP"
      - alert: (P1 - CRITICAL) SAML Proxy A10Y
        expr: (a10y_Saml_Proxy{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: SAML Proxy Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that SAML Proxy service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Health+Check+Failure+SOP"
      - alert: (P1 - CRITICAL) SAML Proxy Gateway A10Y
        expr: (a10y_Saml_Proxy_Gateway{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: SAML Proxy Gateway Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that SAML Proxy Gateway service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Gateways+Health+Check+SOP"
      - alert: (P1 - CRITICAL) TCS CMD A10Y
        expr: (a10y_TCS_CMD{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: TCS CMD Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that TCS CMD service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/TCS+CMD+Health+Check+Failure+SOP"
      - alert: (P1 - CRITICAL) TCS Gateway A10Y
        expr: (a10y_TCS_Gateway{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: TCS Gateway Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that TCS Gateway service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Gateways+Health+Check+SOP"
      - alert: (P1 - CRITICAL) TCS Query A10Y
        expr: (a10y_TCS_QUERY{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: TCS Query Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that TCS Query service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/TCS+Query+Health+Check+Failure+SOP"
      - alert: (P1 - CRITICAL) Templating Engine A10Y
        expr: (a10y_Template_Engine{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Templating Engine Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Templating Engine service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Templating+Engine+Health+Check+Failure+SOP"
      - alert: (P1 - CRITICAL) Tenant Adapter A10Y
        expr: (a10y_TCS_ADAPTER{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Tenant Adapter Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Tenant Adapter service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/TCS+Adapter+Health+Check+Failure+SOP"
      - alert: (P1 - CRITICAL) Tenant Integrator A10Y
        expr: (a10y_TIS{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Tenant Integrator Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Tenant Integrator service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/TIS+Health+Check+SOP"
      - alert: (P1 - CRITICAL) Tenant UI Backend A10Y
        expr: (a10y_Tenant_UI_Backend{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Tenant UI Backend Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Tenant UI Backend service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Health+Check+failure+Alert+SOP"
      - alert: (P1 - CRITICAL) Migration Tool Backend A10Y
        expr: (a10y_Migration_Tool_Backend{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_dev
        annotations:
          summary: Migration Tool Backend Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Migration Tool Backend service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/Migration+Tool+Backend+Health+Check+Failure+SOP"
      - alert: (P1 - CRITICAL) API Proxy A10Y
        expr: (a10y_Api_Proxy{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"}) == 0
        for: 1m
        labels:
          severity: critical
          route: iam_ukgauthn_dev
        annotations:
          summary: API Proxy Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that API Proxy service is down in {{ $labels.namespace }} - Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/FT/API+Proxy+Health+Check+Failure+SOP"
  # Managed Services A10Y Alerts
  - name: IAM - UKG AuthN - Managed Services A10Y Alerts - PROD
    rules:
      - alert: (P1 - CRITICAL) TIS MongoDB Health
        expr: (sum by (namespace)(a10y_TIS_component_db{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: TIS MongoDB Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that TIS MongoDB Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) TIS Kafka Health
        expr: (sum by (namespace)(a10y_TIS_component_kafka{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: TIS Kafka Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that TIS Kafka Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) Tenant UI Backend Kafka Health
        expr: (sum by (namespace)(a10y_Tenant_UI_Backend_component_kafka{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Tenant UI Backend Kafka Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Tenant UI Backend Kafka Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) AM-Bulk MySQL Health
        expr: (sum by (namespace)(a10y_AMS_BULK_component_db{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: AM-Bulk MySQL Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that AM-Bulk MySQL Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) AM-Bulk RabbitMQ Health
        expr: (sum by (namespace)(a10y_AMS_BULK_component_rabbit{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: AM-Bulk RabbitMQ Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that AM-Bulk RabbitMQ Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) AM-CMD MySQL Health
        expr: (sum by (namespace)(a10y_AMS_CMD_component_db{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: AM-CMD MySQL Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that AM-CMD MySQL Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) AM-CMD RabbitMQ Health
        expr: (sum by (namespace)(a10y_AMS_CMD_component_rabbit{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: AM-CMD RabbitMQ Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that AM-CMD RabbitMQ Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) AM-Query MySQL Health
        expr: (sum by (namespace)(a10y_AMS_QUERY_component_db{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: AM-Query MySQL Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that AM-Query MySQL Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) Branding MySQL Health
        expr: (sum by (namespace)(a10y_Branding_component_db{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Branding MySQL Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Branding MySQL Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) Branding Redis Health
        expr: (sum by (namespace)(a10y_Branding_component_redis{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Branding Redis Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Branding Redis Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) SAML-Proxy MongoDB Health
        expr: (sum by (namespace)(a10y_Saml_Proxy_component_db{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: SAML-Proxy MongoDB Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that SAML-Proxy MongoDB Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) TCS-CMD Redis Health
        expr: (sum by (namespace)(a10y_TCS_CMD_component_redis{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: TCS-CMD Redis Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that TCS-CMD Redis Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) TCS-CMD MySQL Health
        expr: (sum by (namespace)(a10y_TCS_CMD_component_db{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: TCS-CMD MySQL Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that TCS-CMD MySQL Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) TCS-CMD Kafka Health
        expr: (sum by (namespace)(a10y_TCS_CMD_component_kafka{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: TCS-CMD Kafka Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that TCS-CMD Kafka Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) TCS-Query MySQL Health
        expr: (sum by (namespace)(a10y_TCS_QUERY_component_db{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: TCS-Query MySQL Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that TCS-Query MySQL Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) TCS-Query Redis Health
        expr: (sum by (namespace)(a10y_TCS_QUERY_component_redis{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: TCS-Query Redis Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that TCS-Query Redis Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) Templating-Engine MySQL Health
        expr: (sum by (namespace)(a10y_Template_Engine_component_db{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Templating-Engine MySQL Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Templating-Engine MySQL Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) Templating-Engine Redis Health
        expr: (sum by (namespace)(a10y_Template_Engine_component_redis{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Templating-Engine Redis Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Templating-Engine Redis Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) Tenant-Adapter Kafka Health
        expr: (sum by (namespace)(a10y_TCS_ADAPTER_component_kafka{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Tenant-Adapter Kafka Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Tenant-Adapter Kafka Service is down in {{ $labels.namespace }}"
      - alert: (P1 - CRITICAL) Tenant-Adapter MySQL Health
        expr: (sum by (namespace)(a10y_TCS_ADAPTER_component_db{namespace=~"ukg-authn-(?:prod-us-east1|cfn-us-east1)"})) == 0
        for: 5m
        labels:
          severity: critical
          route: iam_ukgauthn_prod
        annotations:
          summary: Tenant-Adapter MySQL Service Down in {{ $labels.namespace }}
          description: "A10Y service is reporting that Tenant-Adapter MySQL Service is down in {{ $labels.namespace }}"
  # UKG AuthN Alerts Ends
  # People Fabric : Platform Service Alerts Starts
  - name: People Fabric - Platform Service
    rules:
      - alert: (CRITICAL)PeopleFabric - Platform Service - App Availability - CFN
        expr: (sum(kube_pod_status_phase{namespace="p-ulti-pf-use1-cfn-s01", pod=~"portal-app-.*", phase="Running"})) < 1
        for: 1m
        labels:
          severity: critical
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - All Pods Down - CFN
          description: "All Pods are down, for the application in env [$labels.namespace]. Please check and do the needful"
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '15'
      - alert: (CRITICAL) People Fabric - Platform Service - Minimum Pods Availability - CFN
        expr: (kube_horizontalpodautoscaler_status_current_replicas{namespace = "p-ulti-pf-use1-cfn-s01"} - kube_horizontalpodautoscaler_spec_min_replicas{namespace = "p-ulti-pf-use1-cfn-s01"}) <0
        for: 30m
        labels:
          severity: critical
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - Min Pods Running  - CFN
          description: "Number of running pods are less than minimum replicas defined for platform service application in env [$labels.namespace]. Please check and do the needful"
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '15'
      - alert: (WARNING) People Fabric - Platform Service - Maximum Pods Availability - CFN
        expr: (kube_horizontalpodautoscaler_status_current_replicas{namespace = "p-ulti-pf-use1-cfn-s01"} - kube_horizontalpodautoscaler_spec_max_replicas{namespace = "p-ulti-pf-use1-cfn-s01"})>= 0
        for: 5m
        labels:
          severity: warning
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - Max Pods Running - CFN
          description: "Number of running pods have reached maximum limit in env [$labels.namespace]. Please check and do the needful"
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '15'
      - alert: (WARNING) People Fabric - Platform Service - High CPU Usage - CFN
        expr: (sum(rate(container_cpu_usage_seconds_total{container!="istio-proxy",namespace="p-ulti-pf-use1-cfn-s01"}[1m])) / (sum (kube_pod_container_resource_requests{container!="istio-proxy",namespace="p-ulti-pf-use1-cfn-s01",resource="cpu"})) * 100) >= 90
        for: 5m
        labels:
          severity: warning
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - High CPU usage - CFN
          description: "CPU Usage is above 90% from last 5 mins in environment $labels.namespace . Please check and do the needful."
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '5'
      - alert: (WARNING) People Fabric - Platform Service - High Memory Usage - CFN
        expr: (sum (container_memory_working_set_bytes{namespace="p-ulti-pf-use1-cfn-s01", container!="istio-proxy"})by (container) / sum (kube_pod_container_resource_requests{namespace="p-ulti-pf-use1-cfn-s01", container!="istio-proxy", resource="memory"}) by (container) * 100) >= 90
        for: 5m
        labels:
          severity: warning
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - High Memory usage - CFN
          description: "Memory Usage is above 90% from last 5 mins in environment $labels.namespace . Please check and do the needful."
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '8'
      - alert: (CRITICAL)PeopleFabric - Platform Service - App Availability - NPR
        expr: (sum(kube_pod_status_phase{namespace="p-ulti-pf-use1-npr-s01", pod=~"portal-app-.*", phase="Running"})) < 1
        for: 1m
        labels:
          severity: critical
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - All Pods Down - NPR
          description: "All Pods are down, for the application in env [$labels.namespace]. Please check and do the needful"
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '15'
      - alert: (WARNING) People Fabric - Platform Service - Minimum Pods Availability - NPR
        expr: (kube_horizontalpodautoscaler_status_current_replicas{namespace = "p-ulti-pf-use1-npr-s01"} - kube_horizontalpodautoscaler_spec_min_replicas{namespace = "p-ulti-pf-use1-npr-s01"}) <0
        for: 30m
        labels:
          severity: critical
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - Min Pods Running  - NPR
          description: "Number of running pods are less than minimum replicas defined for platform service application in env [$labels.namespace]. Please check and do the needful"
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '15'
      - alert: (WARNING) People Fabric - Platform Service - Maximum Pods Availability - NPR
        expr: (kube_horizontalpodautoscaler_status_current_replicas{namespace = "p-ulti-pf-use1-npr-s01"} - kube_horizontalpodautoscaler_spec_max_replicas{namespace = "p-ulti-pf-use1-npr-s01"})>= 0
        for: 5m
        labels:
          severity: warning
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - Max Pods Running - NPR
          description: "Number of running pods have reached maximum limit in env [$labels.namespace]. Please check and do the needful"
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '15'
      - alert: (WARNING) People Fabric - Platform Service - High CPU Usage - NPR
        expr: (sum(rate(container_cpu_usage_seconds_total{container!="istio-proxy",namespace="p-ulti-pf-use1-npr-s01"}[1m])) / (sum (kube_pod_container_resource_requests{container!="istio-proxy",namespace="p-ulti-pf-use1-npr-s01",resource="cpu"})) * 100) >= 90
        for: 5m
        labels:
          severity: warning
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - High CPU usage - NPR
          description: "CPU Usage is above 90% from last 5 mins in environment $labels.namespace . Please check and do the needful."
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '5'
      - alert: (WARNING) People Fabric - Platform Service - High Memory Usage - NPR
        expr: (sum (container_memory_working_set_bytes{namespace="p-ulti-pf-use1-npr-s01", container!="istio-proxy"})by (container) / sum (kube_pod_container_resource_requests{namespace="p-ulti-pf-use1-npr-s01", container!="istio-proxy", resource="memory"}) by (container) * 100) >= 90
        for: 5m
        labels:
          severity: warning
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - High Memory usage - NPR
          description: "Memory Usage is above 90% from last 5 mins in environment $labels.namespace . Please check and do the needful."
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '8'
      - alert: (CRITICAL)PeopleFabric - Platform Service - App Availability - PRD
        expr: (sum(kube_pod_status_phase{namespace="p-ulti-pf-use1-prd-s01", pod=~"portal-app-.*", phase="Running"})) < 1
        for: 1m
        labels:
          severity: critical
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - All Pods Down - PRD
          description: "All Pods are down, for the application in env [$labels.namespace]. Please check and do the needful"
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '15'
      - alert: (CRITICAL) People Fabric - Platform Service - Minimum Pods Availability - PRD
        expr: (kube_horizontalpodautoscaler_status_current_replicas{namespace = "p-ulti-pf-use1-prd-s01"} - kube_horizontalpodautoscaler_spec_min_replicas{namespace = "p-ulti-pf-use1-prd-s01"}) <0
        for: 30m
        labels:
          severity: critical
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - Min Pods Running  - PRD
          description: "Number of running pods are less than minimum replicas defined for platform service application in env [$labels.namespace]. Please check and do the needful"
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '15'
      - alert: (WARNING) People Fabric - Platform Service - Maximum Pods Availability - PRD
        expr: (kube_horizontalpodautoscaler_status_current_replicas{namespace = "p-ulti-pf-use1-prd-s01"} - kube_horizontalpodautoscaler_spec_max_replicas{namespace = "p-ulti-pf-use1-prd-s01"})>= 0
        for: 5m
        labels:
          severity: warning
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - Max Pods Running - PRD
          description: "Number of running pods have reached maximum limit in env [$labels.namespace]. Please check and do the needful"
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '15'
      - alert: (WARNING) People Fabric - Platform Service - High CPU Usage - PRD
        expr: (sum(rate(container_cpu_usage_seconds_total{container!="istio-proxy",namespace="p-ulti-pf-use1-prd-s01"}[1m])) / (sum (kube_pod_container_resource_requests{container!="istio-proxy",namespace="p-ulti-pf-use1-prd-s01",resource="cpu"})) * 100) >= 90
        for: 5m
        labels:
          severity: warning
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - High CPU usage - PRD
          description: "CPU Usage is above 90% from last 5 mins in environment $labels.namespace . Please check and do the needful."
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '5'
      - alert: (WARNING) People Fabric - Platform Service - High Memory Usage - PRD
        expr: (sum (container_memory_working_set_bytes{namespace="p-ulti-pf-use1-prd-s01", container!="istio-proxy"})by (container) / sum (kube_pod_container_resource_requests{namespace="p-ulti-pf-use1-prd-s01", container!="istio-proxy", resource="memory"}) by (container) * 100) >= 90
        for: 5m
        labels:
          severity: warning
          route: PF_Platform_service_prod_PD
        annotations:
          summary: People Fabric - Platform Service - High Memory usage - PRD
          description: "Memory Usage is above 90% from last 5 mins in environment $labels.namespace . Please check and do the needful."
          __dashboardUid__: ddrbzbvo1pszkf
          __panelId__: '8'
  # People Fabric : Platform Service Alerts Ends
  # TRS Alerts Starts
  # TRS Infra Alerts
  - name: TRS Infra Alerts
    rules:
      # Prod US-EAST1 system cpu usage
      - alert: Prod US-EAST1 System CPU Usage
        expr: (avg by (service) (avg_over_time(system_cpu_usage_ratio{service=~"^trs.*", environment="prod", datacenter="us-east1"}[1m])) * 100) >= 90
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: System CPU usage is greater than 90
          description: "System CPU Usage is high"
          __dashboardUid__: yFMpLZUIz
          __panelId__: '36'
      # CFN US-EAST1 system cpu usage
      - alert: CFN US-EAST1 System CPU Usage
        expr: (avg by (service) (avg_over_time(system_cpu_usage_ratio{service=~"^trs.*", environment="cfn"}[1m])) * 100) >= 90
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: System CPU usage is greater than 90
          description: "System CPU Usage is high"
          __dashboardUid__: yFMpLZUIz
          __panelId__: '28'
      # Prod NA-NE1 system cpu usage
      - alert: Prod NA-NE1 System CPU Usage
        expr: (avg by (service) (avg_over_time(system_cpu_usage_ratio{service=~"^trs.*", environment="prod", datacenter="northamerica-northeast1"}[1m])) * 100) >= 90
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: System CPU usage is greater than 90
          description: "System CPU Usage is high"
          __dashboardUid__: yFMpLZUIz
          __panelId__: '6'
      # Prod US-East1 Disk free Space
      - alert: Prod US-East1 Disk free Space
        expr: (avg by (service) (avg_over_time(disk_free_bytes{service=~"^trs.*", environment="prod", datacenter="us-east1"}[1m]))) < 5000000000
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: Disk free space is less than 5 GB
          description: "Disk free space is less than 5 GB Prod US-East1"
          __dashboardUid__: yFMpLZUIz
          __panelId__: '34'
      # CFN US-East1 Disk free Space
      - alert: CFN US-East1 Disk free Space
        expr: (avg by (service) (avg_over_time(disk_free_bytes{service=~"^trs.*", environment="cfn"}[1m]))) < 5000000000
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: Disk free space is less than 5 GB
          description: "Disk free space is less than 5 GB CFN"
          __dashboardUid__: yFMpLZUIz
          __panelId__: '30'
      # Prod NA-NE1 Disk free Space
      - alert: NA-NE1 Disk free Space
        expr: (avg by (service) (avg_over_time(disk_free_bytes{service=~"^trs.*", environment="prod", datacenter="northamerica-northeast1"}[1m]))) < 5000000000
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: Disk free space is less than 5 GB
          description: "Disk free space is less than 5 GB NA-NE1"
          __dashboardUid__: yFMpLZUIz
          __panelId__: '16'
      # Prod US-East1 Pod Restarts
      - alert: Prod US-EAST1 Pod Restarts
        expr: (sum by(container) (increase(kube_pod_container_status_restarts_total{namespace="tenancy-prod-us", container=~"trs-gateway|trs-hydrator|trs-tenant-service|trs-tenancy-proxy"}[30m]))) > 2
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Pods Restart in last 30 mins
          description: "Pods Restarted more than twice in last 30 mins US-EAST1"
          __dashboardUid__: yFMpLZUIz
          __panelId__: '32'
      # CFN US-East1 Pod Restarts
      - alert: CFN Pod Restarts
        expr: (sum by(container) (increase(kube_pod_container_status_restarts_total{namespace="tenancy-cfn", container=~"trs-gateway|trs-hydrator|trs-tenant-service|trs-tenancy-proxy"}[30m]))) > 2
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Pods Restart in last 30 mins
          description: "Pods Restarted more than twice in last 30 mins CFN"
          __dashboardUid__: yFMpLZUIz
          __panelId__: '26'
      # Prod NA-NE1 Pod Restarts
      - alert: NA-NE1 Pod Restarts
        expr: (sum by(container) (increase(kube_pod_container_status_restarts_total{namespace="tenancy-prod-ca", container=~"trs-gateway|trs-hydrator|trs-tenant-service|trs-tenancy-proxy"}[30m]))) > 2
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Pods Restart in last 30 mins
          description: "Pods Restarted more than twice in last 30 mins NA-NE1"
          __dashboardUid__: yFMpLZUIz
          __panelId__: '20'
      # Prod US-EAST1 Memory Used
      - alert: US-EAST1 Memory Used
        expr: (avg by (id,area,service) (avg_over_time(jvm_memory_used_bytes{service=~"^trs.*", environment="prod", datacenter="us-east1"}[1m])))/ (avg by (id,area,service) (avg_over_time(jvm_memory_max_bytes{service=~"^trs.*", environment="prod", datacenter="us-east1"}[1m]))) > 0.8
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Memory Used more than 80%
          description: "Memory used more than 80% Prod US-EAST1"
          __dashboardUid__: yFMpLZUIz
          __panelId__: '8'
      # CFN US-EAST1 Memory Used
      - alert: CFN US-EAST1 Memory Used
        expr: (avg by (id,area,service) (avg_over_time(jvm_memory_used_bytes{service=~"^trs.*", environment="cfn"}[1m])))/(avg by (id,area,service) (avg_over_time(jvm_memory_max_bytes{service=~"^trs.*", environment="cfn"}[1m]))) > 0.8
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Memory Used more than 80%
          description: "Memory used more than 80% CFN"
          __dashboardUid__: yFMpLZUIz
          __panelId__: '10'
      # Prod NA-NE1 Memory Used
      - alert: NA-NE1 Memory Used
        expr: (avg by (id,area,service) (avg_over_time(jvm_memory_used_bytes{service=~"^trs.*", environment="prod", datacenter="northamerica-northeast1"}[1m])))/(avg by (id,area,service) (avg_over_time(jvm_memory_max_bytes{service=~"^trs.*", environment="prod", datacenter="northamerica-northeast1"}[1m]))) > 0.8
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Memory Used more than 80%
          description: "Memory used more than 80% NA-NE1"
          __dashboardUid__: yFMpLZUIz
          __panelId__: '18'
      # Prod TRS-Gateway Replicas Available
      - alert: Prod TRS-Gateway Replicas Available
        expr: (avg by (deployment) (avg_over_time(kube_deployment_status_replicas_available{namespace="tenancy-prod-us", deployment="trs-gateway"}[1m]))) < 2.9
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: Prod TRS Gateway Replicas less than 3
          description: "Prod TRS Gateway Replicas less than 3"
          __dashboardUid__: WcM1pu-Sz
          __panelId__: '24'
      # Prod TRS-Hydrator Replicas Available
      - alert: Prod TRS-Hydrator Replicas Available
        expr: (avg by (deployment) (avg_over_time(kube_deployment_status_replicas_available{namespace="tenancy-prod-us", deployment="trs-hydrator"}[1m]))) < 2.9
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: Prod TRS Hydrator Replicas less than 3
          description: "Prod TRS Hydrator Replicas less than 3"
          __dashboardUid__: WcM1pu-Sz
          __panelId__: '26'
      # Prod TRS-Tenant Service Replicas Available
      - alert: Prod TRS-Tenant Service Replicas Available
        expr: (avg by (deployment) (avg_over_time(kube_deployment_status_replicas_available{namespace="tenancy-prod-us", deployment="trs-tenant-service"}[1m]))) < 2.9
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: Prod TRS Tenant Service Replicas less than 3
          description: "Prod TRS Tenant Service Replicas less than 3"
          __dashboardUid__: WcM1pu-Sz
          __panelId__: '25'
      # Prod TRS-Tenancy-Proxy Replicas Available
      - alert: Prod TRS-Tenancy-Proxy Replicas Available
        expr: (avg by (deployment) (avg_over_time(kube_deployment_status_replicas_available{namespace="tenancy-prod-us", deployment="trs-tenancy-proxy"}[1m]))) < 2.9
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: Prod TRS Tenancy Proxy Replicas less than 3
          description: "Prod TRS Tenancy Proxy Replicas less than 3"
          __dashboardUid__: WcM1pu-Sz
          __panelId__: '27'
      # CFN TRS-Gateway Replicas Available
      - alert: CFN TRS-Gateway Replicas Available
        expr: (avg by (deployment) (avg_over_time(kube_deployment_status_replicas_available{namespace="tenancy-cfn", deployment="trs-gateway"}[1m]))) < 2.9
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: CFN TRS Gateway Replicas less than 3
          description: "CFN TRS Gateway Replicas less than 3"
          __dashboardUid__: NSgLtuaIk
          __panelId__: '24'
      # CFN TRS-Hydrator Replicas Available
      - alert: CFN TRS-Hydrator Replicas Available
        expr: (avg by (deployment) (avg_over_time(kube_deployment_status_replicas_available{namespace="tenancy-cfn", deployment="trs-hydrator"}[1m]))) < 2.9
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: CFN TRS Hydrator Replicas less than 3
          description: "CFN TRS Hydrator Replicas less than 3"
          __dashboardUid__: NSgLtuaIk
          __panelId__: '26'
      # CFN TRS-Tenant Service Replicas Available
      - alert: CFN TRS-Tenant Service Replicas Available
        expr: (avg by (deployment) (avg_over_time(kube_deployment_status_replicas_available{namespace="tenancy-cfn", deployment="trs-tenant-service"}[1m]))) < 2.9
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: CFN TRS Tenant Service Replicas less than 3
          description: "CFN TRS Tenant Service Replicas less than 3"
          __dashboardUid__: NSgLtuaIk
          __panelId__: '25'
      # CFN TRS-Tenancy-Proxy Replicas Available
      - alert: CFN TRS-Tenancy-Proxy Replicas Available
        expr: (avg by (deployment) (avg_over_time(kube_deployment_status_replicas_available{namespace="tenancy-cfn", deployment="trs-tenancy-proxy"}[1m]))) < 2.9
        for: 15m
        labels:
          severity: critical
          route: TRS_Prod
        annotations:
          summary: CFN TRS Tenancy Proxy Replicas less than 3
          description: "CFN TRS Tenancy Proxy Replicas less than 3"
          __dashboardUid__: NSgLtuaIk
          __panelId__: '27'
  # TRS Custom Metrics Alerts - Failures, Exceptions
  - name: TRS Custom Metrics Alerts - Failures
    rules:
      # Prod TRS Publisher Exceptions
      - alert: Prod US-East1 Publisher Event Exceptions
        expr: (sum(increase(trs_publisher_exception_total{service="trs-tenant-service", environment="prod", datacenter="us-east1"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Failure on Event Publishing Prod US-EAST1
          description: "Publisher Event Failure on Prod US-East1"
          __dashboardUid__: nLgWWEJIk
          __panelId__: '4'
      # Prod TRS Consumer Event Failures
      - alert: Prod US-East1 Consumer Event Exceptions
        expr: (sum(increase(trs_collection_gauge{service="trs-tenant-service", environment="prod", datacenter="us-east1", collection_name="consumerEventFailures"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Consumer Event Failures on US-EAST1
          description: "Consumer Event Failure on Prod US-East1"
          __dashboardUid__: nLgWWEJIk
          __panelId__: '8'
      # Collection Count Change in Prod US-EAST1
      - alert: Prod US-East1 Collection Count Change
        expr: (avg by (collection_name) (delta(trs_collection_gauge{service="trs-tenant-service", environment="prod", datacenter="us-east1", collection_name="consumerEventFailures"}[5m]))) > 0.1
        for: 30m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Collection Count Change in US-EAST1
          description: "Collection Count Change in Prod US-East1"
          __dashboardUid__: QQFXMF_Sk
          __panelId__: '2'
      # Collection Count Change in CFN
      - alert: CFN Collection Count Change
        expr: (avg by (collection_name) (delta(trs_collection_gauge{service="trs-tenant-service", environment="cfn", collection_name="consumerEventFailures"}[5m]))) > 0.1
        for: 30m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Collection Count Change in CFN
          description: "Collection Count Change in CFN"
          __dashboardUid__: QQFXMF_Sk
          __panelId__: '3'
      # Collection Count Change in NA-NE1
      - alert: NA-NE1 Collection Count Change
        expr: (avg by (collection_name) (delta(trs_collection_gauge{service="trs-tenant-service", environment="prod", datacenter="northamerica-northeast1", collection_name="consumerEventFailures"}[5m]))) > 0.1
        for: 30m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Collection Count Change in NA-NE1
          description: "Collection Count Change in NA-NE1"
          __dashboardUid__: QQFXMF_Sk
          __panelId__: '4'
      # Customer Data Ingest Failure in Prod US-EAST1
      - alert: Customer Data Ingest Failure in Prod US-EAST1
        expr: (sum(increase(trs_customer_sync_ingest_total{service="trs-tenant-service", environment="prod", datacenter="us-east1", succeeded="false"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Customer Data Ingest Failed in Prod US-EAST1
          description: "Customer Data Ingest Failed in Prod US-EAST1"
          __dashboardUid__: AllJnKlIk
          __panelId__: '11'
      # Customer Data Ingest Failure in CFN
      - alert: Customer Data Ingest Failure in CFN
        expr: (sum(increase(trs_customer_sync_ingest_total{service="trs-tenant-service", environment="cfn", succeeded="false"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Customer Data Ingest Failed in CFN
          description: "Customer Data Ingest Failed in CFN"
          __dashboardUid__: AllJnKlIk
          __panelId__: '13'
      # Customer Data Ingest Failure in NA-NE1
      - alert: Customer Data Ingest Failure in Prod NA-NE1
        expr: (sum(increase(trs_customer_sync_ingest_total{service="trs-tenant-service", environment="prod", datacenter="northamerica-northeast1", succeeded="false"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Customer Data Ingest Failed in Prod NA-NE1
          description: "Customer Data Ingest Failed in Prod NA-NE1"
          __dashboardUid__: AllJnKlIk
          __panelId__: '12'
      # Customer Data Process Failure in Prod US-EAST1
      - alert: Customer Data Process Failure in Prod US-EAST1
        expr: (sum(increase(trs_customer_sync_process_total{service="trs-tenant-service", environment="prod", datacenter="us-east1", succeeded="false"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Customer Data Process Failed in Prod US-EAST1
          description: "Customer Data Process Failed in Prod US-EAST1"
          __dashboardUid__: AllJnKlIk
          __panelId__: '14'
      # Customer Data Process Failure in CFN
      - alert: Customer Data Process Failure in CFN
        expr: (sum(increase(trs_customer_sync_process_total{service="trs-tenant-service", environment="cfn", succeeded="false"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Customer Data Process Failed in CFN
          description: "Customer Data Process Failed in CFN"
          __dashboardUid__: AllJnKlIk
          __panelId__: '16'
      # Customer Data Process Failure in Prod NA-NE1
      - alert: Customer Data Process Failure in Prod NA-NE1
        expr: (sum(increase(trs_customer_sync_process_total{service="trs-tenant-service", environment="prod", datacenter="northamerica-northeast1", succeeded="false"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Customer Data Process Failed in NA-NE1
          description: "Customer Data Process Failed in NA-NE1"
          __dashboardUid__: AllJnKlIk
          __panelId__: '15'
      # Failed Consumer Events Prod US-EAST1
      - alert: Consumer Events Failure in Prod US-EAST1
        expr: (sum(increase(trs_consumer_exception_total{service="trs-tenant-service", environment="prod", datacenter="us-east1", exception!="DeserializationClassNotFoundException"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Consumer Events Failure in Prod US-EAST1
          description: "Consumer Events Failure in Prod US-EAST1"
          __dashboardUid__: aqSrSKlIk
          __panelId__: '5'
      # Failed Consumer Events CFN
      - alert: Consumer Events Failure in CFN
        expr: (sum(increase(trs_consumer_exception_total{service="trs-tenant-service", environment="cfn", exception!="DeserializationClassNotFoundException"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Consumer Events Failure in CFN
          description: "Consumer Events Failure in CFN"
          __dashboardUid__: aqSrSKlIk
          __panelId__: '6'
      # Failed Consumer Events Prod NA-NE1
      - alert: Consumer Events Failure in Prod NA-NE1
        expr: (sum(increase(trs_consumer_exception_total{service="trs-tenant-service", environment="prod", datacenter="northamerica-northeast1", exception!="DeserializationClassNotFoundException"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Consumer Events Failure in Prod NA-NE1
          description: "Consumer Events Failure in Prod NA-NE1"
          __dashboardUid__: aqSrSKlIk
          __panelId__: '7'
      # Failed Publisher Events Prod US-EAST1
      - alert: Publisher Events Failure in Prod US-EAST1
        expr: sum(round(increase(trs_publisher_exception_total{service="trs-tenant-service", environment="prod", datacenter="us-east1"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Publisher Events Failure in Prod US-EAST1
          description: "Publisher Events Failure in Prod US-EAST1"
          __dashboardUid__: fFiVIK_Ik
          __panelId__: '2'
      # Failed Publisher Events CFN
      - alert: Publisher Events Failure in CFN
        expr: sum(round(increase(trs_publisher_exception_total{service="trs-tenant-service", environment="cfn"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Publisher Events Failure in CFN
          description: "Publisher Events Failure in CFN"
          __dashboardUid__: fFiVIK_Ik
          __panelId__: '7'
      # Failed Publisher Events Prod NA-NE1
      - alert: Publisher Events Failure in Prod NA-NE1
        expr: sum(round(increase(trs_publisher_exception_total{service="trs-tenant-service", environment="prod", datacenter="northamerica-northeast1"}[1m]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Publisher Events Failure in Prod NA-NE1
          description: "Publisher Events Failure in Prod NA-NE1"
          __dashboardUid__: fFiVIK_Ik
          __panelId__: '6'
      # Hydrator Failed Events - Prod US-EAST1
      - alert: Hydrator Failed Events - Prod US-EAST1
        expr: (sum by (exception) (increase(hydrator_listener_exception_total{service="trs-hydrator", environment="prod", datacenter="us-east1", exception!="tenancy.tenant.created", exception!="tenancy.tenantlevelserviceinstance.created", exception!="tenancy.tenantlevelserviceinstance.updated", exception!="tenancy.tenantlevelserviceinstance.configured"}[1m:]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Hydrator Failed Events - Prod US-EAST1
          description: "Hydrator Failed Events - Prod US-EAST1"
          __dashboardUid__: ft3-SLPSk
          __panelId__: '4'
      # Hydrator Failed Events - CFN
      - alert: Hydrator Failed Events - CFN
        expr: (sum by (exception) (increase(hydrator_listener_exception_total{service="trs-hydrator", environment="cfn", exception!="tenancy.tenant.created"}[1m:]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Hydrator Failed Events - CFN
          description: "Hydrator Failed Events - CFN"
          __dashboardUid__: ft3-SLPSk
          __panelId__: '3'
      # Hydrator Failed Events - NA-NE1
      - alert: Hydrator Failed Events - NA-NE1
        expr: (sum by (exception) (increase(hydrator_listener_exception_total{service="trs-hydrator", environment="prod", datacenter="northamerica-northeast1", exception!="tenancy.tenant.created"}[1m:]))) > 0
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Hydrator Failed Events - NA-NE1
          description: "Hydrator Failed Events - NA-NE1"
          __dashboardUid__: ft3-SLPSk
          __panelId__: '6'
  # TRS Custom Metrics Alerts - Average Response Time
  - name: TRS Custom Metrics Alerts - Average Response Time
    rules:
      # Mobile Public Endpoint V1 Response Time  - Prod US-EAST1
      - alert: Average Response Time for Mobile Public Endpoint V1 Prod US-East1
        expr: (sum by(method) (rate(http_server_requests_seconds_sum{service="trs-tenant-service", environment="prod", datacenter="us-east1", uri="/api/v1/activation"}[1m])) / sum by(method) (rate(http_server_requests_seconds_count{service="trs-tenant-service", environment="prod", datacenter="us-east1", uri="/api/v1/activation"}[1m]))) * 1000 > 100
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Average Response Time of Mobile Public Endpoint V1 is High
          description: "Average Response Time is High for Mobile Public Endpoint V1 Prod US-EAST1"
          __dashboardUid__: e5ZW4TwSz
          __panelId__: '2'
      # Mobile Public Endpoint V2 Response Time - Prod US-EAST1
      - alert: Average Response Time of Mobile Public Endpoint V2 Prod US-East1
        expr: (sum by(method) (rate(http_server_requests_seconds_sum{service="trs-tenant-service", environment="prod", datacenter="us-east1", uri="/api/v2/activation"}[1m])) / sum by(method) (rate(http_server_requests_seconds_count{service="trs-tenant-service", environment="prod", datacenter="us-east1", uri="/api/v2/activation"}[1m]))) * 1000 > 100
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Average Response Time of Mobile Public Endpoint V2 is High
          description: "Average Response Time is High for Mobile Public Endpoint V2 Prod US-EAST1"
          __dashboardUid__: e5ZW4TwSz
          __panelId__: '3'
      # Mobile Public Endpoint V1 Response Time - CFN
      - alert: Average Response Time of Mobile Public Endpoint V1 CFN
        expr: (sum by(method) (rate(http_server_requests_seconds_sum{service="trs-tenant-service", environment="cfn", uri="/api/v1/activation"}[1m])) / sum by(method) (rate(http_server_requests_seconds_count{service="trs-tenant-service", environment="cfn", uri="/api/v1/activation"}[1m]))) * 1000 > 100
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Average Response Time of Mobile Public Endpoint V1 is High
          description: "Average Response Time is High for Mobile Public Endpoint V1 CFN"
          __dashboardUid__: e5ZW4TwSz
          __panelId__: '4'
      # Mobile Public Endpoint V2 Response Time - CFN
      - alert: Average Response Time of Mobile Public Endpoint V2 CFN
        expr: (sum by(method) (rate(http_server_requests_seconds_sum{service="trs-tenant-service", environment="cfn", uri="/api/v2/activation"}[1m])) / sum by(method) (rate(http_server_requests_seconds_count{service="trs-tenant-service", environment="cfn", uri="/api/v2/activation"}[1m]))) * 1000 > 100
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Average Response Time of Mobile Public Endpoint V2 is High
          description: "Average Response Time is High for Mobile Public Endpoint V2 CFN"
          __dashboardUid__: e5ZW4TwSz
          __panelId__: '5'
      # Get Full Tenant Object API Response Time - Prod US-EAST1
      - alert: Average Response Time for Full Tenant Object API Prod US-East1
        expr: (sum by(method) (rate(http_server_requests_seconds_sum{service="trs-tenant-service", environment="prod", datacenter="us-east1", uri="/api/v1/tenants/search"}[1m])) / sum by(method) (rate(http_server_requests_seconds_count{service="trs-tenant-service", environment="prod", datacenter="us-east1", uri="/api/v1/tenants/search"}[1m]))) * 1000 > 300
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Average Response Time of Get Full Tenant Object is High
          description: "Response Time is High for Get Full Tenant Object Prod US-EAST1"
          __dashboardUid__: TUm1l7wSz
          __panelId__: '12'
      # Get Full Tenant Object API Response Time - CFN
      - alert: Average Response Time for Full Tenant Object API CFN
        expr: (sum by(method) (rate(http_server_requests_seconds_sum{service="trs-tenant-service", environment="cfn", uri="/api/v1/tenants/search"}[1m])) / sum by(method) (rate(http_server_requests_seconds_count{service="trs-tenant-service", environment="cfn", uri="/api/v1/tenants/search"}[1m]))) * 1000 > 300
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Average Response Time of Get Full Tenant Object is High
          description: "Response Time is High for Get Full Tenant Object CFN"
          __dashboardUid__: TUm1l7wSz
          __panelId__: '11'
      # Get Full Tenant Object API Response Time - Prod NA-NE1
      - alert: Average Response Time for Full Tenant Object API Prod NA-NE1
        expr: (sum by(method) (rate(http_server_requests_seconds_sum{service="trs-tenant-service", environment="prod", datacenter="northamerica-northeast1", uri="/api/v1/tenants/search"}[1m])) / sum by(method) (rate(http_server_requests_seconds_count{service="trs-tenant-service", environment="prod", datacenter="northamerica-northeast1", uri="/api/v1/tenants/search"}[1m]))) * 1000 > 300
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Average Response Time of Get Full Tenant Object is High
          description: "Response Time is High for Get Full Tenant Object Prod NA-NE1"
          __dashboardUid__: TUm1l7wSz
          __panelId__: '14'
      # Get Full Tenant Object Response Time - Staging
      - alert: Average Response Time for Full Tenant Object API Staging
        expr: (sum by(method) (rate(http_server_requests_seconds_sum{service="trs-tenant-service", environment="staging", uri="/api/v1/tenants/search"}[1m])) / sum by(method) (rate(http_server_requests_seconds_count{service="trs-tenant-service", environment="staging", uri="/api/v1/tenants/search"}[1m]))) * 1000 > 300
        for: 15m
        labels:
          severity: warning
          route: TRS_Prod
        annotations:
          summary: Average Response Time of Get Full Tenant Object is High
          description: "Response Time is High for Get Full Tenant Object Staging"
          __dashboardUid__: TUm1l7wSz
          __panelId__: '13'
  # TRS Alerts Ends
  #region PaymentServices
  - name: PaymentServices - Event Failures
    interval: 10m
    rules:
      - alert: PS Garn Prod FTC Events
        expr: (max by(environment, instance) (sps_failed_consume_events_gauge{namespace="ps-garn-prod"})) > 0
        for: 30m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-garnishments
        annotations:
          summary: PS Garnishments Prod - FTC Events
          description: Failed to consume (FTC) events in Payment Services Garnishment service(s)
          __dashboardUid__: vjhy-PlZz
          __panelId__: '6'

      - alert: PS Garn Prod High Volume FTC Events
        expr: ((max by(instance)(sum by(instance, pod) (sps_failed_consume_events_gauge{namespace="ps-garn-prod"}) OR (min by(instance) (min_over_time(sps_failed_consume_events_gauge{namespace="ps-garn-prod"}[1d])) * 0))) - (max by(instance) (sum by(instance, pod) (sps_failed_consume_events_gauge{namespace="ps-garn-prod"} offset 12h) OR (min by(instance) (min_over_time(sps_failed_consume_events_gauge{namespace="ps-garn-prod"}[1d])) * 0)))) >= 10
        for: 10m
        labels:
          severity: error
          route: PS-PagerDuty
          team_name: ps-garnishments
        annotations:
          summary: PS Garnishments Prod - High Volume FTC Events
          description: Failed to consume (FTC) events in Payment Services Garnishment service(s)
          __dashboardUid__: vjhy-PlZz
          __panelId__: '17'

      - alert: PS SSP Prod Cash Management FTC Events
        expr: (max by(eventname) (sps_failed_consume_events_gauge{environment="prod", instance="ssp-coredep", eventname=~"payment.bai2-bank-transaction..*|payment.bai2-file-bank-transaction-exception..*|payment.bank-account-day..*|payment.bank-transaction..*|payment.bank-transaction-service..*|payment.checkprintfilerequest..*|payment.checkprintfilerequest-service..*|payment.collection..*|payment.collectionfilerequest..*|payment.collectionfilerequest-service..*|payment.collection-request..*|payment.collections..*|payment.collection-service..*|payment.collections-service..*|payment.confirmation-file-transaction..*|payment.customerbankaccount..*|payment.exposure-base-amount..*|payment.external-payment..*|payment.fileproducer..*|payment.generalledgeraccount..*|payment.inboundfile..*|payment.journalentry..*|payment.journal-entry-digest..*|payment.journalentry-service..*|payment.liabilities..*|payment.liability..*|payment.liability-service..*|payment.nacha-return-file-bank-transaction-exception..*|payment.nettedcollection..*|payment.nettedcollections-service..*|payment.outboundfile..*|payment.outboundfile-service..*|payment.payment..*|payment.paymentfilerequest..*|payment.paymentfilerequest-service..*|payment.payment-service..*|payment.usg-bank..*|payment.usg-bank-account..*|tax-engine.fund-request..*|tax-integration.cash-receivable..*"})) > 0
        for: 30m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-cash-management
        annotations:
          summary: PS SSP Prod - FTC Events - Cash Management
          description: Failed to consume (FTC) events in Payment Services SSP for Cash Management {{ $labels.eventname }}
          __dashboardUid__: vjhy-PlZz
          __panelId__: '11'

      - alert: PS SSP Prod Core Capabilities FTC Events
        expr: (max (sps_failed_consume_events_gauge{environment="prod", instance="ssp-coredep", eventname=~"payment.company.product.*|payment.company-service.*|payment.component-company-service.*|payment.datasync-payroll-processor.*|payment.datasync-service.tenant.*|payment.datasync-tenant-service.*|payment.payrollinstance-service.payroll.*|.*encryption.*|ultipro.ded.distribution-center.*|payment.payrollinstance-service.payroll.*|payment.datasync-pay-processor.ultipro-pay-batch-observed|payment.datasync-payroll-unit-service.payroll-unit-schedules-observed|payment.datasync-pay-service.ultipro-pay-observed|payment.datasync-service.pay-missed-suspected|payment.pay.created|payment.pay-auditing-service.pay-missed|payment.payrollinstance.pay-imported-after-closed|payment.payrollinstance.process-requested|payment.payrollinstance-service.closed-payroll-confirmed|payment.payrollinstance-service.pay-pickup-reset-requested|payment.payroll-service.payroll-closed|payment.payroll-service.payroll-closed-verified|payment.payrollunit-service.payroll-unit-schedule-sync-requested|payment.pay-service.pay-batch-confirmed|payment.pay-service.pay-created-confirmed|payment.pay-service.pay-missed|payment.scheduler-service.datasync-audit-process-scheduled|payment.scheduler-service.datasync-statistics-aggregation-scheduled|payment.scheduler-service.event-failures-monitoring-scheduled|payment.scheduler-service.hung-payroll-reset-scheduled|payment.scheduler-service.tenant-sync-statistics-scheduled|payment.service.replay-requested|payment.system-management-service.bulk-replay-outgoing-messages-requested|payment.tenant.integration-updated|payment.tenant.product-added|payment.tenant-service.payment-services-gateway-requested|payment.tenant-service.product-payment-services-gateway-requested|payment.tenant-service.tenant-activation-requested|payment.tenant-service.tenant-connectivity-test-requested|payment.tenant-service.tenant-sync-requested|payment.ultipro-payrollunit.observed|tax.reportrequest.created|tax.service.replay-requested|ultipro.ded.payroll-completed|payment.pay.verified-nok|payment.pay.verified-ok|payment.system-management-service.batch-replay-outgoing-messages|tax.service.expire-old-report-requests|ultipro.ded.master-company-change-event|ultipro.ded.pay-group-change-event|ultipro.ded.payroll-codes-change-event|ultipro.ded.payroll-registry-change-event|payment.company-service.company-updated-retry|payment.distribution-center-service.mark-ignored-retry|payment.payrollinstance-service.payroll-closed-retry|payment.payrollinstance-service.payroll-metadata-received-retry|payment.tenant-service.tenant-sync-completed-retry|payment.company-service.activation-requested-forwarded.*|payment.company-service.deactivate-tax-migration-requested-forwarded.*|payment.company-service.product.*|payment.dedbridge-service.payroll-close-completed-forwarded.*|payment.dedbridge-service.save-pay-data-completed-forwarded.*|payment.pay-auditing-service.pay-missed-forwarded.*|payment.payrollinstance-service.closed-payroll-confirmed-forwarded.*|payment.payrollinstance-service.pay-pickup-reset-requested-forwarded.*|payment.payrollunit-service.payroll-unit-schedule-sync-requested-forwarded.*|payment.pay-service.pay-missed-forwarded.*|payment.tenant-service.payment-services-gateway-requested-forwarded.*|payment.tenant-service.product-payment-services-gateway-requested-forwarded.*|payment.tenant-service.tenant.*|ultipro.ded.company-change-event-forwarded.*|payment.tenant.created|payment.tenant.sync-result-updated|payment.datasync-audit-process.scheduled|payment.datasync-service.payroll-metadata-received"})) > 0
        for: 30m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-core-capabilities
        annotations:
          summary: PS SSP Prod - FTC Events - Core Capabilities
          description: Failed to consume (FTC) events in Payment Services SSP for Core Capabilities
          __dashboardUid__: vjhy-PlZz
          __panelId__: '12'

      - alert: PS SSP Prod Employee Pay FTC Events
        expr: (max (sps_failed_consume_events_gauge{environment="prod", instance="ssp-coredep", eventname=~"payment.scheduler-service.process-bai2-file-scheduled|payment.employeeddprenotecustomerrequest.set-processingstatus-generated|payment.employeeddprenotecustomerrequest.set-processingstatus-failed|payment.employeeddprenotecustomerrequest.sync-completed|payment.employeeddprenotecustomerrequest-service.prenote-file-production-initiated|payment.employeeddprenotecustomerfileproducer-service.prenote-file-production-retry-requested|payment.scheduler-service.monitor-customer-prenote-request-update-syncing-scheduled|payment.employeeddprenotecustomerrequest.created|payment.pay.portion-action-applied|payment.masspayaction.created|payment.paycancelworkflow.claim-info-added|payment.paycancelworkflow-service.claims-initiated|payment.paycancelworkflow.status-updated|payment.paycancelworkflow.unclaimed|payment.pay.partially-refunded|payment.pay.portion-action-applied|payment.pay.refund-revised|payment.pay.portion-refund-undone|payment.payrollinstance-service.closed-payroll-confirmed-forwarded-.*|payment.pay-service.pay-batch-confirmed|payment.pay-auditing-service.pay-missed-forwarded-.*|payment.pay-service.pay-missed-forwarded-.*|payment.prioritizedpayroll-service.prioritizedpayroll-sync-requested-forwarded-.*|payment.pay.cancelworkflow-info-added|payment.pay.portion-action-applied|payment.tenant-service.docnumberrange-requested-.*|payment.scheduler-service.monitor-stop-payment-requests-scheduled"})) > 0
        for: 30m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-employee-pay
        annotations:
          summary: PS SSP Prod - FTC Events - Employee Pay
          description: Failed to consume (FTC) events in Payment Services SSP for Employee Pay
          __dashboardUid__: vjhy-PlZz
          __panelId__: '15'

      - alert: PS SSP Prod Garnishments FTC Events
        expr: (max (sps_failed_consume_events_gauge{environment="prod", instance="ssp-coredep", eventname=~"garnishment.*|ultipro.ded.employee-garnishments.*|ultipro.ded.wage-attachment.*|ultipro.ded.garnishmen-deduction.*|ultipro.ded.deduction-hold.*"})) > 0
        for: 30m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-garnishments
        annotations:
          summary: PS SSP Prod - FTC Events - Garnishments
          description: Failed to consume (FTC) events in Payment Services SSP for Garnishments
          __dashboardUid__: vjhy-PlZz
          __panelId__: '13'

      - alert: PS SSP Prod Trust Accounting FTC Events
        expr: (max by(eventname)(sps_failed_consume_events_gauge{environment="prod", instance="ssp-coredep", eventname=~"payment.bank-transaction.*|payment.bai2-bank-transaction.*|payment.external-payment.*|payment.journalentry.*|payment.journal-entry-digest.*|tax-integration.payment.*|garnishment.composer-service.garnishment-action-bank-transaction-cancel-changed|garnishment.garnishment.marked-for-refund|garnishment.garnishment.marked-for-undo|garnishment.garnishment-refund.associated-with-bank-account|tax.ach-file.created|tax.ach-file.voided|tax.check-service.exported|tax.check.voided|tax.inputtaxinstance.assembly-status-updated|tax.liability.cash-mgmt-liability-id-updated|tax.payment.exported|tax.payment.wired|tax.payment-service.export-voided|tax.payment-service.wired|tax.periodictaxinstance.assembly-status-updated|payment.accountbalancesnapshots-service.create-monthly-accountbalancesnapshot-requested|payment.bank-transaction-service.manual-entries-bulkcreated|payment.collection.confirmation-info-undone|payment.collection-service.test-collections-created|payment.datasync-payroll-processor.ukgpro-payrolls-closed-observed|payment.liability.assigned-to-collection|payment.liability.payment-status-updated|payment.liability.status-updated|payment.pay.partially-refunded|payment.pay.refund-revised|payment.pay.portion-refund-undone|payment.preliminary-stash-service.process-request|payment.scheduler-service.monitor-journal-entry-digest-status-scheduled|payment.scheduler-service.create-monthly-accountbalancesnapshot-scheduled|payment.scheduler-service.process-preliminary-journal-entries-scheduled|payment.scheduler-service.datasync-site-server-heart-beat-scheduled"})) > 0
        for: 30m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-trust-accounting
        annotations:
          summary: PS SSP Prod - FTC Events - Trust Accounting
          description: Failed to consume (FTC) events in Payment Services SSP for Trust Accounting {{ $labels.eventname }}
          __dashboardUid__: vjhy-PlZz
          __panelId__: '16'

      - alert: PS SSP Prod US Tax FTC Events
        expr: (max (sps_failed_consume_events_gauge{environment="prod", instance="ssp-coredep", eventname=~"tax-integration.pts-regeneration.created.*|tax-integration.pts-tracking-record999.acknowledged.*|tax-integration.pts-tracking-status.acknowledged.*|tax-integration.rts-regeneration.created.*|payment.scheduler-service.outbox-poll-scheduled.*|payment.tenant-service.outbox-poll-requested.*|cu-payroll.payroll.close-completed.*|cu-payroll.payroll.save-pay-data-completed.*|payment.dedbridge-service.payroll-close-completed-forwarded.*|payment.dedbridge-service.save-pay-data-completed-forwarded.*"})) > 0
        for: 30m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: PS SSP Prod - FTC Events - US Tax
          description: Failed to consume (FTC) events in Payment Services SSP for US Tax
          __dashboardUid__: vjhy-PlZz
          __panelId__: '14'

      - alert: PS Prod FTP Events
        expr: (max (sps_failed_publish_events_gauge{environment="prod"})) >= 1
        for: 45m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-core-capabilities
        annotations:
          summary: PS Prod - FTP Events
          description: Failed to publish (FTP) events in Payment Services
          __dashboardUid__: bdu2f4shg05j4b
          __panelId__: '6'

      - alert: Cash Import File Not Running for 4 Hours
        expr: (floor(sum(increase(taxintegration_cashimportfileautomationpolleventsubscriber_counter{environment="prod", subscriberresult="Ok"}[4h])))) == 0
        for: 4h
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Job Not Running Alert
          description: Successful Cash Import File Automation Poll Events have not run for 4 hours.
          __dashboardUid__: bdzg91jxshk3kf
          __panelId__: '44'

      - alert: Create Collection Failed
        expr: (floor(sum(increase(taxintegration_collectionextractfiledownloadedeventsubscriber_counter{filestatus="Failed", environment="prod"}[5m])))) >= 1
        for: 10m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Create Collection Failed
          description: This alert is configured as a collection has failed to create
          __dashboardUid__: bdzg91jxshk3ke
          __panelId__: '59'


      - alert: Collection Completed with Exception
        expr: (floor(sum(increase(taxintegration_collectionextractfiledownloadedeventsubscriber_counter{environment="prod", filestatus="CompletedWithExceptions"}[5m])))) >= 1
        for: 10m
        labels:
          severity: info
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Collection Completed with Exception Alert
          description: Collection files have been processed with the status "Completed with Exception"
          __dashboardUid__: bdzg91jxshk3ke
          __panelId__: '78'

      - alert: Collection Posting to SSP Failed
        expr: (floor(sum(increase(taxintegration_collectionextractfileuploadedeventsubscriber_counter{environment="prod", measurement="PostFailedToSSP"}[5m])))) >= 1
        for: 10m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Collection Posting to SSP Failed
          description: There have been failures in posting collection data to SSP
          __dashboardUid__: bdzg91jxshk3ke
          __panelId__: '60'

      - alert: Daily Processing Job Not Run for 25 Hours
        expr: (floor(sum(increase(taxintegration_dailyprocessingautomationpolleventsubscriber_counter{environment="prod", measurement="DownloadDailyProcessingPTSConfirmationFileFromMTax_Success"}[25h])))) == 0
        for: 25h
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Daily Processing Job Alert
          description: PTS Confirmation scheduled job has not run successfully for the last 25 hours.
          __dashboardUid__: bdzg8mm2142rke
          __panelId__: '62'

      - alert: Master Tax Process History Not Running for 12 Hours
        expr: (floor(sum(increase(taxintegration_mtaxprocesshistorydownloadedsubscriber_counter{environment="prod", subscriberresult="Ok"}[12h])))) == 0
        for: 12h
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Process History Alert
          description: This alert is configured to check if process history is running.
          __dashboardUid__: bdzg91jxshk3kg
          __panelId__: '42'

      - alert: Alert for Time to upload a grouped file to MT
        expr: (avg(avg_over_time(taxintegration_mtaxoutboundfileservice_timer{environment="prod", quantile="0.95", measurement="ProcessPayrollTaxSummaryGroup_TimeToUploadPTSGroupFileToMT"}[5m]))) > 180000
        for: 5m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Time to upload a grouped file to MT
          description: Alert when file upload to master tax web service takes more than a minute
          __dashboardUid__: HGfIDajnk56
          __panelId__: '27'

      - alert: PTS Group Aggregate Creation Failed
        expr: (floor(sum(increase(taxintegration_payrolltaxsummaryfilestatusupdatedsubscriber_counter{environment="prod", subscriberresult="Error"}[2m])))) > 1
        for: 5m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: PTS Group aggregate Creation Failure Count
          description: Alert when system failed to create PTS group aggregate upon receiving the file
          __dashboardUid__: HGfIDajnk56
          __panelId__: '57'

      - alert: Alert for PTS Group Upload Stats
        expr: (floor(sum(increase(taxintegration_mtaxoutboundfileservice_counter{environment="prod", measurement="PTSGroupUploadFailed"}[2m])))) > 5
        for: 5m
        labels:
          severity: info
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: PTS Group Upload Stats
          description: Alert when system failed to upload a file to MasterTax
          __dashboardUid__: HGfIDajnk56
          __panelId__: '58'

      - alert: Alert for PTS Group Command results
        expr: (floor(sum(increase(taxintegration_payrolltaxsummarygroupautomationgroupeventsubscriber_counter{environment="prod", subscriberresult="Error"}[2m])))) > 5
        for: 30m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: PTS Group Command results
          description: Alert when system failed to group files
          __dashboardUid__: HGfIDajnk56
          __panelId__: '56'

      - alert: Alert for MTax webservice status
        expr: (increase(taxintegration_mtaxcomponentstatushandler_valuegauge{environment="prod"}[2m])) >= 1
        for: 5m
        labels:
          severity: info
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: MTax webservice status
          description: Alert when MT webservice is down
          __dashboardUid__: HGfIDajnk56
          __panelId__: '41'

      - alert: Alert for PTS Group Retry Upload Exhausted Alert
        expr: (floor(sum(increase(taxintegration_payrollinstancecreatedsubscriber_counter{environment="prod", measurement="NumberOfPTSRetryUploadsExhausted"}[10m])))) > 0
        for: 1m
        labels:
          severity: info
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: PTS Group Retry Upload Exhausted Alert
          description: PTS Group Retry Upload Attempts Exhausted while trying to upload the file to Master Tax
          __dashboardUid__: HGfIDajnk56
          __panelId__: '67'

      - alert: Alert for PTS MTax Import or Post Failure
        expr: (floor(sum(increase(taxintegration_payrolltaxsummarygroupimportcompletedsubscriber_counter{environment="prod", payrolltaxsummarygroupimportcompletedsubscriber="Import_Failed|Post_Failed"}[10m])))) > 0
        for: 1m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: PTS MTax Import or Post Failure
          description: This alert is raised when a PTS file has failed to import or post to Master Tax
          __dashboardUid__: HGfIDajnk56
          __panelId__: '119'

      - alert: Alert for Ded bridge Payrollclose events failed to parse
        expr: (floor(sum(increase(sps_dedbridgefailedparsingrabbitmessage_counter{environment="prod", event_name="cu-payroll.payroll.close-completed"}[2m])))) > 2
        for: 5m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Ded bridge Payrollclose events failed to parse
          description: This alert is triggered when Ded bridge Payrollclose events fail to parse
          __dashboardUid__: HGfIDajnk56
          __panelId__: '99'

      - alert: Alert for DataSync failed to process Save Pay Data Completed
        expr: (floor(sum(increase(sps_payrolltaxsummaryprocessingservice_counter{savepaydatacompletedresult="False", environment="prod"}[2m])))) > 1
        for: 5m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: DataSync failed to process Save Pay Data Completed
          description: This alert is triggered when DataSync failed to process Save Pay Data Completed
          __dashboardUid__: HGfIDajnk56
          __panelId__: '105'

      - alert: Alert for Ded bridge save pay data completed event parsing
        expr: (floor(sum(increase(sps_dedbridgefailedparsingrabbitmessage_counter{environment="prod", event_name="cu-payroll.payroll.save-pay-data-completed"}[2m])))) > 1
        for: 5m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Ded bridge save pay data completed event parsing alert
          description: This alert is triggered when Ded bridge save pay data completed event parsing cause error
          __dashboardUid__: HGfIDajnk56
          __panelId__: '101'

      - alert: ATL Data Sync UKGPRO SQL Connection Errors
        expr: (floor(sum(increase(sps_payrolltaxsummaryprocessingservice_counter{environment="prod", sqlexception_severity_level="FatalError"}[2m])))) > 10
        for: 5m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: SQL Connection Error Alert
          description: Fatal SQL connection errors have been detected in ATL Data Sync UKGPRO
          __dashboardUid__: HGfIDajnk56
          __panelId__: '107'

      - alert: ATL DataSync Failed Payroll Close Completed Alert
        expr: (floor(sum(increase(sps_payrolltaxsummaryprocessingservice_counter{environment="prod", payrollclosecompletedresult="False"}[2m])))) > 1
        for: 5m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Payroll Close Completed Failure Alert
          description: This alert is triggered when Payroll Close Completed events have failed to process
          __dashboardUid__: HGfIDajnk56
          __panelId__: '103'

      - alert: ATL DataSync UKGPro Connectivity Errors Alert
        expr: (floor(sum(increase(sps_payrolltaxsummaryprocessingservice_counter{environment="prod", sqlexception_severity_level="OtherError"}[2m])))) > 10
        for: 5m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: UKGPro Connectivity Error Alert
          description: This alert is triggered when Connectivity errors have been detected in ATL DataSync UKGPro
          __dashboardUid__: HGfIDajnk56
          __panelId__: '109'

      - alert: Alert for Actual Payroll Received Before Estimated
        expr: (floor(sum(increase(taxintegration_payrolltaxsummaryfileprocessingservice_counter{environment="prod", measurement="Actual_Received_Before_Estimated"}[2m])))) > 1
        for: 5m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Actual Payroll Timing Alert
          description: This alert is triggered when Actual payroll has been received before the estimated time
          __dashboardUid__: HGfIDajnk56
          __panelId__: '111'

      - alert: TaxHub Payroll Tax Summary Generated Event Alert
        expr: (floor(sum(increase(taxintegration_payrolltaxsummarygeneratedeventsubscriber_counter{environment="prod", result="Error"}[2m])))) > 1
        for: 5m
        labels:
          severity: info
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Payroll Tax Summary Event Error Alert
          description: This alert is triggered when Errors have been detected in the TaxHub payrollTaxSummary generated events
          __dashboardUid__: HGfIDajnk56
          __panelId__: '115'

      - alert: TaxHub Payroll Close Event Alerts
        expr: (floor(sum(increase(taxintegration_payrollinstancecreatedsubscriber_counter{environment="prod", subscriberresult="Error"}[2m])))) > 1
        for: 5m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Payroll Close Event Creation Failure Alert
          description: This alert is triggered when Failed to create payroll from payroll close events in TaxHub
          __dashboardUid__: HGfIDajnk56
          __panelId__: '113'

      - alert: Alert for PTS File Poll Event Failed To Process
        expr: (floor(sum(increase(taxintegration_payrolltaxsummaryfilepolleventsubscriber_counter{environment="prod", measurement="PayrollTaxSummaryFilePollEventFailedToProcess"}[2m])))) > 1
        for: 5m
        labels:
          severity: info
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: PTS File Poll Event Failed To Process Detected
          description: This alert is triggered when PTS File Poll Event Failed To Process
          __dashboardUid__: HGfIDajnk56
          __panelId__: '121'

      - alert: Alert for Payroll Tax Summary Group Automation Poll Event Failed To Process
        expr: (floor(sum(increase(taxintegration_payrolltaxsummarygroupautomationpolleventsubscriber_counter{environment="prod", measurement="PayrollTaxSummaryGroupAutomationPollEventFailedToProcess"}[2m])))) > 1
        for: 5m
        labels:
          severity: info
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Payroll Tax Summary Group Automation Poll Event Failed To Process
          description: This alert is triggered when Payroll Tax Summary Group Automation Poll Event fails to process
          __dashboardUid__: HGfIDajnk56
          __panelId__: '121'

      - alert: Alert for Reconciliation Tax Summary File Poll Event Failed To Process
        expr: (floor(sum(increase(taxintegration_reconciliationtaxsummaryfilepolleventsubscriber_counter{environment="prod", measurement="ReconciliationTaxSummaryFilePollEventFailedToProcess"}[2m])))) > 1
        for: 5m
        labels:
          severity: info
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Reconciliation Tax Summary File Poll Event Failed To Process
          description: This alert is triggered when Reconciliation Tax Summary File Poll Event Failed To Process
          __dashboardUid__: HGfIDajnk56
          __panelId__: '121'

      - alert: Alert for Reconciliation Tax Summary Group Automation Poll Event Failed To Process
        expr: (floor(sum(increase(taxintegration_reconciliationtaxsummarygroupautomationpolleventsubscriber_counter{environment="prod", measurement="ReconciliationTaxSummaryGroupAutomationPollEventFailedToProcess"}[2m])))) > 1
        for: 5m
        labels:
          severity: info
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Reconciliation Tax Summary Group Automation Poll Event Failed To Process
          description: This alert is triggered when Reconciliation Tax Summary Group Automation Poll Event Failed To Process
          __dashboardUid__: HGfIDajnk56
          __panelId__: '121'

      - alert: Alert for Payroll Tax Summary Group Self Heal Poll Event Failed To Process
        expr: (floor(sum(increase(taxintegration_payrolltaxsummarygroupselfhealscheduledsubscriber_counter{environment="prod", measurement="PayrollTaxSummaryGroupSelfHealPollEventFailedToProcess"}[2m])))) > 1
        for: 5m
        labels:
          severity: info
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Payroll Tax Summary Group Self Heal Poll Event Failed To Process
          description: This alert is triggered when Payroll Tax Summary Group Self Heal Poll Event Failed To Process
          __dashboardUid__: HGfIDajnk56
          __panelId__: '121'

      - alert: Alert for Reconciliation Tax Summary Group Self Heal Scheduled Event Failed To Process
        expr: (floor(sum(increase(taxintegration_reconciliationtaxsummarygroupselfhealscheduledsubscriber_counter{environment="prod", measurement="ReconciliationTaxSummaryGroupSelfHealScheduledEventFailedToProcess"}[2m])))) > 1
        for: 5m
        labels:
          severity: info
          route: PS-PagerDuty
          team_name: ps-us-tax
        annotations:
          summary: Reconciliation Tax Summary Group Self Heal Scheduled Event Failed To Process
          description: This alert is triggered when Reconciliation Tax Summary Group Self Heal Scheduled Event Failed To Process
          __dashboardUid__: HGfIDajnk56
          __panelId__: '121'

  - name: Payment Services
    rules:
      - alert: PS Identity Request Failures
        expr: (sum (sps_identity_request_counter{environment="prod", requestresponse!="OK"})) > 5
        for: 5m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-core-capabilities
        annotations:
          summary: PS Prod - Identity Request Failures
          description: A large number of identity requests are failing
          __dashboardUid__: QbuQ1glmz
          __panelId__: '32'
  #endregion PaymentServices

  #region PaymentServices Reporting
  - name: Payment Services Reporting Critical Alerts
    interval: 1m
    rules:
      - alert: PS Reporting Prod Ingestion Delay
        expr: (sum (reportingingestion_event_ingestion_delay{environment="prod"})) > 480
        for: 30m
        labels:
          severity: critical
          route: PS-PagerDuty
          team_name: ps-core-capabilities
        annotations:
          summary: PS Prod - Reporting Ingestion Delay
          description: Reporting ingestion is delayed.
          __dashboardUid__: de4jjlr1qpn9cc
          __panelId__: '24'
      - alert: PS Reporting Prod FTC Alert
        expr: (sum (reportingingestion_failed_consume_events_gauge{environment="prod"})) > 480
        for: 30m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-core-capabilities
        annotations:
          summary: PS Prod - Reporting FTC event detected.
          description: Reporting ingestion is delayed.
          __dashboardUid__: de4jjlr1qpn9cc
          __panelId__: '24'
  - name: Payment Services Reporting Warning Alerts
    interval: 5m
    rules:
      - alert: PS Reporting Prod FTC Alert
        expr: (sum (reportingingestion_failed_consume_events_gauge{environment="prod"})) > 100
        for: 30m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-core-capabilities
        annotations:
          summary: PS Prod - Reporting FTC event detected.
          description: New events in FTC for Reporting Ingestion.
          __dashboardUid__: de4jjlr1qpn9cc
          __panelId__: '29'
      - alert: PS Reporting Staging FTC Alert
        expr: (sum (reportingingestion_failed_consume_events_gauge{environment="staging"})) > 100
        for: 30m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-core-capabilities
        annotations:
          summary: PS Staging - Reporting FTC event detected.
          description: New events in FTC for Reporting Ingestion.
          __dashboardUid__: de4jjlr1qpn9cc
          __panelId__: '29'
  - name: Payment Services Reporting Daily Alerts
    interval: 24h
    rules:
      - alert: PS Reporting Prod Unhandled Events
        expr: (sum (reportingingestion_unhandled_events{environment="prod"})) > 0
        for: 1m
        labels:
          severity: warning
          route: PS-PagerDuty
          team_name: ps-core-capabilities
        annotations:
          summary: PS Prod - Reporting Unhandled events detected.
          description: New events in UnhandledEvents collection for Reporting Ingestion.
          __dashboardUid__: de4jjlr1qpn9cc
          __panelId__: '34'
  #endregion PaymentServices Reporting

  #region Suite provisioning alerts
  - name: Suite provisioning alerts
    rules:
      - alert: Suite Provisioning - Service unavailability
        expr: (sum(kube_pod_status_phase{namespace="suite-provision-prod", pod=~".*provis-backend-service.*", phase="Running"})) == 0
        for: 2m
        labels:
          severity: critical
          route: Suite-provisioning
        annotations:
          summary: Suite Provsioning - Service unavailability
          description: Suite provision service is not available for last 1 minute
          __dashboardUid__: cdtwnkrpbglj4d
          __panelId__: '9'

      - alert: Suite Provisioning - High CPU usage - warning
        expr: (sum(rate(container_cpu_usage_seconds_total{namespace="suite-provision-prod", pod=~".*provis.*"}[1m])) / sum (kube_pod_container_resource_requests{namespace="suite-provision-prod", pod=~".*provis.*", resource="cpu"}) * 100)>90
        for: 10m
        labels:
          severity: warning
          route: Suite-provisioning
        annotations:
          summary: Suite Provisioning - High CPU usage
          description: Suite provisioning is using more than 90% of CPU for last 10 minutes
          __dashboardUid__: cdtwnkrpbglj4d
          __panelId__: '1'

      - alert: Suite Provisioning - High Memory usage - warning
        expr: (sum (container_memory_working_set_bytes{namespace="suite-provision-prod", pod=~".*provis.*"}) / sum (kube_pod_container_resource_requests{namespace="suite-provision-prod", pod=~".*provis.*", resource="memory"}) * 100) > 90
        for: 10m
        labels:
          severity: warning
          route: Suite-provisioning
        annotations:
          summary: Suite Provisioning - High Memory usage
          description: Suite provisioning is using more than 90% of Memory for last 10 minutes
          __dashboardUid__: cdtwnkrpbglj4d
          __panelId__: '2'

      - alert: Suite Provisioning - Runner service unavailable
        expr: (sum(kube_deployment_status_replicas_available{namespace="suite-provision-prod", deployment="provis-runner-service"})) == 0
        for: 2m
        labels:
          severity: critical
          route: Suite-provisioning
        annotations:
          summary: Suite Provisioning - Runner Service Unavailable
          description: Suite provision runner service is unavailable for last 2 minutes
          __dashboardUid__: cdtwnkrpbglj4d
          __panelId__: '12'
  #endregion Suite provisioning alerts

  #HAapi Healthcheck Alerting
  - name: HAapi Healthcheck Alert
    rules:
      - alert: HAapi_Healthcheck_is_failing
        expr: probe_success == 0
        for: 1m
        labels:
          severity: critical
          route: HaAPI
        annotations:
          summary: "API Down"
          description: "The API {{ $labels.instance }} is down for more than 1 minute"
          __dashboardUid__: bdtztwllz9fy8d
          __panelId__: '1'
  #Pro-SRE Datadog agent UP on SQL
  - name: Datadog agent UP on SQL
    interval: 15m
    rules:
      - alert: Datadog_agent_UP_on_SQL
        expr: windows_service_state{instance=~"(?i)((n|e|t|g03p)[0-9]sup.*(ssn|db)[0-9]{2}$|(n|e|t|g03)w[0-9]sup.*(ssn|db)[0-9]{2}$|(n|e|t|g03p)[0-9]wup.*(ssn|db)[0-9]{2}$|(n|e|t|g03)w[0-9]wup.*(ssn|db)[0-9]{2}$|(n|e|t|g03p)[0-9]sup.*(ssn)[0-9]{1}$|(n|e|t|g03)w[0-9]sup.*(ssn)[0-9]{1}$|(n|e|t|g03p)[0-9]wup.*(ssn)[0-9]{1}$|(n|e|t|g03)w[0-9]wup.*(ssn)[0-9]{1}$)", name=~"(datadogagent)"} == 1
        for: 5m
        labels:
          severity: critical
          route: prosre
        annotations:
          summary: "Datadog agent UP on SQL"
          description: "Datadog agent should remain DOWN on SQL servers so it will show RED if Datadog agent is UP"
          __dashboardUid__: cdu4ak94a4lj4a
          __panelId__: '112'
          
  - name: SSO service LogOn
    interval: 15m
    rules:
      - alert: SSO service LogOn
        expr: windows_service_info{instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(as)[0-9]{2}$", name=~"(ultimate software sso host service)", run_as!~"(?i)usg(us|ca)saas.*SVC.*ULTI"}
        for: 5m
        labels:
          severity: critical
          route: prosre
        annotations:
          summary: "SSO service LogOn property not running with ULTISVC account"
          description: "SSO service LogOn property not running with ULTISVC account"
          __dashboardUid__: cdu4ak94a4lj4a
          __panelId__: '114'
          
   #Pro-SRE Datadog agent UP on Citrix
  # - name: Datadog agent UP on Citrix
  #   interval: 15m
  #   rules:
  #     - alert: Datadog_agent_UP_on_Citrix
  #       expr: windows_service_state{instance=~"(?i)((n|e|t|g03p)[0-9]sup.*(ts)[0-9]{2}$|(n|e|t|g03)w[0-9]sup.*(ts)[0-9]{2}$|(n|e|t|g03p)[0-9]wup.*(ts)[0-9]{2}$|(n|e|t|g03)w[0-9]wup.*(ts)[0-9]{2}$)", name=~"(datadogagent)"} == 1
  #       for: 5m
  #       labels:
  #         severity: critical
  #         route: prosre
  #       annotations:
  #         summary: "Datadog agent UP on Citrix"
  #         description: "Datadog agent should remain DOWN on Citrix servers so it will show RED if Datadog agent is UP"
  #         __dashboardUid__: cdu4ak94a4lj4a
  #         __panelId__: '113'
  #CPK
  - name: CPK - Kubernetes Daemonset
    rules:
      # Unavailable daemonset in US-East1
      - alert: (Critical) Unavailable daemonset
        expr:  (sum  by (cluster_name, daemonset) (kube_daemonset_status_number_misscheduled{datacenter="us-east1" })) > 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Deamonsets are unavailable in US-East1 Dev
          description: "{{ $labels.daemonset }} Deamonsets are unavailable in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: daemonset
          __panelId__: '83'
      # Unavailable daemonset in US-East4 prod
      - alert: (Critical) Unavailable daemonset
        expr:  (sum  by (cluster_name, daemonset) (kube_daemonset_status_number_misscheduled{datacenter="us-east4" })) > 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Deamonsets are unavailable in US-East4 prod
          description: "{{ $labels.daemonset }} Deamonsets are unavailable in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: daemonset
          __panelId__: '79'
      # Unavailable daemonset in northamerica-northeast1
      - alert: (Critical) Unavailable daemonset
        expr:  (sum  by (cluster_name, daemonset) (kube_daemonset_status_number_misscheduled{datacenter="northamerica-northeast1" })) > 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Deamonsets are unavailable in Northamerica-Northeast-1
          description: "{{ $labels.daemonset }} Deamonsets are unavailable in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: daemonset
          __panelId__: '84'
      # Unavailable daemonset in northamerica-northeast2
      - alert: (Critical) Unavailable daemonset
        expr:  (sum  by (cluster_name, daemonset) (kube_daemonset_status_number_misscheduled{datacenter="northamerica-northeast2" })) > 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Deamonsets are unavailable in Northamerica-Northeast-2
          description: "{{ $labels.daemonset }} Deamonsets are unavailable in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: daemonset
          __panelId__: '85'
      # Unavailable daemonset in australia-southeast1
      - alert: (Critical) Unavailable daemonset
        expr:  (sum  by (cluster_name, daemonset) (kube_daemonset_status_number_misscheduled{datacenter="australia-southeast1" })) > 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Deamonsets are unavailable in Australia-Southeast-1
          description: "{{ $labels.daemonset }} Deamonsets are unavailable in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: daemonset
          __panelId__: '86'
      # Unavailable daemonset in australia-southeast2
      - alert: (Critical) Unavailable daemonset
        expr:  (sum  by (cluster_name, daemonset) (kube_daemonset_status_number_misscheduled{datacenter="australia-southeast2" })) > 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Deamonsets are unavailable in Australia-Southeast-2
          description: "{{ $labels.daemonset }} Deamonsets are unavailable in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: daemonset
          __panelId__: '87'
      # Unavailable daemonset in europe-west1
      - alert: (Critical) Unavailable daemonset
        expr:  (sum  by (cluster_name, daemonset) (kube_daemonset_status_number_misscheduled{datacenter="europe-west1" })) > 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Deamonsets are unavailable in Europe-West1
          description: "{{ $labels.daemonset }} Deamonsets are unavailable in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: daemonset
          __panelId__: '89'
      # Unavailable daemonset in europe-west4
      - alert: (Critical) Unavailable daemonset
        expr:  (sum  by (cluster_name, daemonset) (kube_daemonset_status_number_misscheduled{datacenter="europe-west4" })) > 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Deamonsets are unavailable in europe-west4
          description: "{{ $labels.daemonset }} Deamonsets are unavailable in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: daemonset
          __panelId__: '88'
      # Unavailable daemonset in plas1
      - alert: (Critical) Unavailable daemonset
        expr:  (sum  by (cluster_name, daemonset) (kube_daemonset_status_number_misscheduled{datacenter="plas1" })) > 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Deamonsets are unavailable in plas1
          description: "{{ $labels.daemonset }} Deamonsets are unavailable in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: daemonset
          __panelId__: '80'
      # Unavailable daemonset in atl
      - alert: (Critical) Unavailable daemonset
        expr:  (sum  by (cluster_name, daemonset) (kube_daemonset_status_number_misscheduled{datacenter="atl" })) > 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Deamonsets are unavailable in atl
          description: "{{ $labels.daemonset }} Deamonsets are unavailable in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: daemonset
          __panelId__: '78'
      # Unavailable daemonset in tor
      - alert: (Critical) Unavailable daemonset
        expr:  (sum  by (cluster_name, daemonset) (kube_daemonset_status_number_misscheduled{datacenter="tor" })) > 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Deamonsets are unavailable in tor
          description: "{{ $labels.daemonset }} Deamonsets are unavailable in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: daemonset
          __panelId__: '81'
  
  - name: CPK - etcd Controlplane status
    rules:
      # Not Ready etcd| controlplane nodes in tor
      - alert: (Critical) Not Ready nodes
        expr:  kube_node_status_condition{condition="Ready", node=~".*controlplane.*|.*etcd.*", status="true", datacenter="tor"}<1
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Kube node status in tor
          description: "{{ $labels.node }} node is not ready in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: fe2wxksb0nwg0e
          __panelId__: '3'
      
      # Not Ready etcd| controlplane nodes in atl
      - alert: (Critical) Not Ready nodes
        expr:  kube_node_status_condition{condition="Ready", node=~".*controlplane.*|.*etcd.*", status="true", datacenter="atl"}<1
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Kube node status in atl
          description: "{{ $labels.node }} node is not ready in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: fe2wxksb0nwg0e
          __panelId__: '4'
      # Not Ready etcd| controlplane nodes in plas1
      - alert: (Critical) Not Ready nodes
        expr:  kube_node_status_condition{condition="Ready", node=~".*controlplane.*|.*etcd.*", status="true", datacenter="plas1"}<1
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Kube node status in plas1
          description: "{{ $labels.node }} node is not ready in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: fe2wxksb0nwg0e
          __panelId__: '5'
        
      # Unschedulable nodes for etcd and controlplane
      - alert: (Critical) Unschedulable nodes
        expr:  kube_node_spec_unschedulable{datacenter="atl",node=~".*controlplane.*|.*etcd.*"}>0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Kube node unschedulable in atl
          description: "{{ $labels.node }} node is not ready in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: fe2wxksb0nwg0e
          __panelId__: '8'
      
      - alert: (Critical) Unschedulable nodes
        expr:  kube_node_spec_unschedulable{datacenter="tor",node=~".*controlplane.*|.*etcd.*"}>0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Kube node unschedulable in tor
          description: "{{ $labels.node }} node is not ready in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: fe2wxksb0nwg0e
          __panelId__: '9'
      
      - alert: (Critical) Unschedulable nodes
        expr:  kube_node_spec_unschedulable{datacenter="plas1",node=~".*controlplane.*|.*etcd.*"}>0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Kube node unschedulable in plas1
          description: "{{ $labels.node }} node is not ready in {{ $labels.cluster_name }} cluster"
          __dashboardUid__: fe2wxksb0nwg0e
          __panelId__: '10'

  - name: CPK- Deployment Pod status
    rules:
      - alert: Zero deployment pod cluster scheduler
        expr: kube_deployment_status_replicas_available{deployment="cluster-scheduler"} == 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Cluster Schedular pod deployment status
          description: "{{$labels.deployment}} deployment is not running in {{$labels.datacenter}} prod region"
          __dashboardUid__: be5srmox6nh1cb
          __panelId__: '4'
      
      - alert: Zero deployment pod for ingress-nginx-controller
        expr:  kube_deployment_status_replicas_available{deployment="ingress-nginx-controller"} == 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Ingress Nginx Controller pod deployment status
          description: "{{$labels.deployment}} deployment is not running in {{$labels.datacenter}} prod region for cluster {{$labels.cluster_name}}"
          __dashboardUid__: be5srmox6nh1cb
          __panelId__: '5'
        
      - alert: Zero deployment pod for stratospher-api
        expr:  kube_deployment_status_replicas_available{deployment="stratosphere-api"} == 0
        for: 5m
        labels:
          severity: critical
          route: CPK-Mail
        annotations:
          summary: Stratosphere API pod deployment status
          description: "{{$labels.deployment}} deployment is not running in {{$labels.datacenter}} dev region for cluster {{$labels.cluster_name}}"
          __dashboardUid__: be5srmox6nh1cb
          __panelId__: '6'

  #OneIPaaS Infra ALERTS
  - name: OneIPaaS Infrastructure Alerts
    interval: 1m
    rules:
      - alert: '[Alert] : P1 : OneIPaaS : CPU utilization > 90% Critical'
        expr: (100 * sum(rate(container_cpu_usage_seconds_total{namespace=~"common-integration-platform-atomcloud-(prd|uat|cfn).*",pod=~".*cip.*",container!~"istio-proxy"}[1m])) by (namespace,container, pod)/ on (namespace,container,pod) sum(kube_pod_container_resource_requests{namespace=~"common-integration-platform-atomcloud-(prd|uat|cfn).*",pod=~".*cip.*",container!~"istio-proxy", resource="cpu"}) by (namespace,container,pod)) > 90
        for: 1h
        labels:
          severity: critical
          route: P1-noc-ihub+engfalconihubextnoida
        annotations:
          summary: High CPU Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}}
          description: "CPU Usage is above 90% from last 1 hour. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160184"
          __dashboardUid__: bdw6uyxa9svlsb

      - alert: '[Alert] : P2 : OneIPaaS : CPU utilization > 75% Warning'
        expr:  (100 * sum(rate(container_cpu_usage_seconds_total{namespace=~"common-integration-platform-atomcloud-(prd|uat|cfn).*",pod=~".*cip.*",container!~"istio-proxy"}[1m])) by (namespace,container, pod)/ on (namespace,container,pod) sum(kube_pod_container_resource_requests{namespace=~"common-integration-platform-atomcloud-(prd|uat|cfn).*",pod=~".*cip.*",container!~"istio-proxy", resource="cpu"}) by (namespace,container,pod)) > 75
        for: 6h
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: High CPU Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}}
          description: "CPU Usage is above 75% from last 6 hours. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160305"
          __dashboardUid__: bdw6uyxa9svlsb

      - alert: '[Alert] : P1 : OneIPaaS : CPU utilization > 90% Critical'
        expr: (100 * sum(rate(container_cpu_usage_seconds_total{namespace=~"common-integration-platform-(prd|cfn).*",pod=~".*cip.*",container!~"istio-proxy"}[1m])) by (namespace,container, pod)/ on (namespace,container,pod) sum(kube_pod_container_resource_requests{namespace=~"common-integration-platform-(prd|cfn).*",pod=~".*cip.*",container!~"istio-proxy", resource="cpu"}) by (namespace,container,pod)) > 90
        for: 1h
        labels:
          severity: critical
          route: P1-noc-ihub+engfalconihubextnoida
        annotations:
          summary: High CPU Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}}
          description: "CPU Usage is above 90% from last 1 hours. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160259"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P2 : OneIPaaS : CPU utilization > 75% Warning'
        expr: (100 * sum(rate(container_cpu_usage_seconds_total{namespace=~"common-integration-platform-(prd|cfn).*",pod=~".*cip.*",container!~"istio-proxy"}[1m])) by (namespace,container, pod)/ on (namespace,container,pod) sum(kube_pod_container_resource_requests{namespace=~"common-integration-platform-(prd|cfn).*",pod=~".*cip.*",container!~"istio-proxy", resource="cpu"}) by (namespace,container,pod)) > 75
        for: 6h
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: High CPU Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}}
          description: "CPU Usage is above 75% from last 6 hours. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160307"
          __dashboardUid__: bdw6uyxa9svlsb

      - alert: '[Alert] : P1 : OneIPaaS : CPU utilization > 90% Critical'
        expr: (100 * sum(rate(container_cpu_usage_seconds_total{namespace=~"common-integration-platform-ies-(prd|uat|cfn).*",pod=~".*cip.*",container!~"istio-proxy"}[1m])) by (namespace,container, pod)/ on (namespace,container,pod) sum(kube_pod_container_resource_requests{namespace=~"common-integration-platform-ies-(prd|uat|cfn).*",pod=~".*cip.*",container!~"istio-proxy", resource="cpu"}) by (namespace,container,pod)) > 90
        for: 1h
        labels:
          severity: critical
          route: P1-noc-ihub+engfalconihubextnoida
        annotations:
          summary: High CPU Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}}
          description: "CPU Usage is above 90% from last 1 hours. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160262"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P2 : OneIPaaS : CPU utilization > 75% Warning'
        expr: (100 * sum(rate(container_cpu_usage_seconds_total{namespace=~"common-integration-platform-ies-(prd|uat|cfn).*",pod=~".*cip.*",container!~"istio-proxy"}[1m])) by (namespace,container, pod)/ on (namespace,container,pod) sum(kube_pod_container_resource_requests{namespace=~"common-integration-platform-ies-(prd|uat|cfn).*",pod=~".*cip.*",container!~"istio-proxy", resource="cpu"}) by (namespace,container,pod)) > 75
        for: 6h
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: High CPU Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}}
          description: "CPU Usage is above 75% from last 6 hours. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160313"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Memory utilization > 85% Critical'
        expr: 100 * (sum by(namespace, pod, container) (container_memory_usage_bytes{namespace=~"common-integration-platform-atomcloud-(prd|uat|cfn).*", pod=~".*cip.*", container!~".*istio.*"})/on(namespace, pod, container) group_left sum by(namespace, pod, container) (kube_pod_container_resource_limits{namespace=~"common-integration-platform-atomcloud-(prd|uat|cfn).*", pod=~".*cip.*", container!~".*istio.*", resource="memory"})) > 85
        for: 30m
        labels:
          severity: critical
          route: P1-noc-ihub+engfalconihubextnoida
        annotations:
          summary: High Memory Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Memory Usage is above 85% from last 30 Minutes. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160317"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Memory utilization > 75% Warning'
        expr:  100 * (sum by(namespace, pod, container) (container_memory_usage_bytes{namespace=~"common-integration-platform-atomcloud-(prd|uat|cfn).*", pod=~".*cip.*", container!~".*istio.*"})/on(namespace, pod, container) group_left sum by(namespace, pod, container) (kube_pod_container_resource_limits{namespace=~"common-integration-platform-atomcloud-(prd|uat|cfn).*", pod=~".*cip.*", container!~".*istio.*", resource="memory"})) > 75
        for: 60m
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: High Memory Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Memory Usage is above 75% from last 1 hour. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160354"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Memory utilization > 85% Critical'
        expr:  100 * (sum by(namespace, pod, container) (container_memory_usage_bytes{namespace=~"common-integration-platform-ies-(prd|uat|cfn).*", pod=~".*cip.*", container!~".*istio.*"})/on(namespace, pod, container) group_left sum by(namespace, pod, container) (kube_pod_container_resource_limits{namespace=~"common-integration-platform-ies-(prd|uat|cfn).*", pod=~".*cip.*", container!~".*istio.*", resource="memory"})) >85
        for: 30m
        labels:
          severity: critical
          route: P1-noc-ihub+engfalconihubextnoida
        annotations:
          summary: High Memory Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Memory Usage is above 85% from last 30 Minutes. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160323"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Memory utilization > 75% Warning'
        expr: 100 * ( sum by(namespace, pod, container) (container_memory_usage_bytes{namespace=~"common-integration-platform-ies-(prd|uat|cfn).*", pod=~".*cip.*", container!~".*istio.*"})/on(namespace, pod, container) group_left sum by(namespace, pod, container) (kube_pod_container_resource_limits{namespace=~"common-integration-platform-ies-(prd|uat|cfn).*", pod=~".*cip.*", container!~".*istio.*", resource="memory"})) >75
        for: 60m
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: High Memory Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Memory Usage is above 75% from last 1 hour. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160456"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Memory utilization > 85% Critical'
        expr:  100 * ( sum by(namespace, pod, container) (container_memory_usage_bytes{namespace=~"common-integration-platform-(prd|cfn).*", pod=~".*cip.*", container!~".*istio.*"})/on(namespace, pod, container) group_left sum by(namespace, pod, container) (kube_pod_container_resource_limits{namespace=~"common-integration-platform-(prd|cfn).*", pod=~".*cip.*", container!~".*istio.*", resource="memory"})) >85
        for: 30m
        labels:
          severity: critical
          route: P1-noc-ihub+engfalconihubextnoida
        annotations:
          summary: High Memory Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Memory Usage is above 85% from last 30 Minutes. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160321"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Memory utilization > 75% Warning'
        expr:  100 * ( sum by(namespace, pod, container) (container_memory_usage_bytes{namespace=~"common-integration-platform-(prd|cfn).*", pod=~".*cip.*", container!~".*istio.*"})/on(namespace, pod, container) group_left sum by(namespace, pod, container) (kube_pod_container_resource_limits{namespace=~"common-integration-platform-(prd|cfn).*", pod=~".*cip.*", container!~".*istio.*", resource="memory"})) >75
        for: 60m
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: High Memory Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Memory Usage is above 75% from last 1 hour. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160454"
          __dashboardUid__: bdw6uyxa9svlsb

      - alert: '[Alert] : P1 : OneIPaaS : Pod Restart'
        expr:  (sum by(namespace,pod,container)(increase(kube_pod_container_status_restarts_total{namespace=~"common-integration-platform-atomcloud-(prd|uat|cfn).*",pod=~".*cip.*",container!="istio-proxy"}[1m]))) > 0
        for: 0s
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: Pods Restart for OneIPaaS {{$labels.namespace}} {{$labels.pod}}
          description: "Pods Restarted. Please follow the SOP"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Pod Restart'
        expr:  (sum by(namespace,pod,container)(increase(kube_pod_container_status_restarts_total{namespace=~"common-integration-platform-ies-(prd|uat|cfn).*",pod=~".*cip.*",container!="istio-proxy"}[1m]))) > 0
        for: 0s
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: Pods Restart for OneIPaaS {{$labels.namespace}} {{$labels.pod}}
          description: "Pods Restarted. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/display/Falcon/SOP+OneIPaaS+IES%3A+Pod+Restart"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Pod Restart'
        expr: (sum by(namespace,pod,container)(increase(kube_pod_container_status_restarts_total{namespace=~"common-integration-platform-(prd|cfn).*",pod=~".*cip.*",container!="istio-proxy"}[1m]))) > 0
        for: 0s
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: Pods Restart for OneIPaaS {{$labels.namespace}} {{$labels.pod}}
          description: "Pods Restarted. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/display/Falcon/SOP+OneIPaaS+ITC%3A+Pod+Restart"
          __dashboardUid__: bdw6uyxa9svlsb

      - alert: '[Alert] : P1 : OneIPaaS : CPU utilization > 90% Critical'
        expr: (100 * sum(rate(container_cpu_usage_seconds_total{namespace=~"cip-atomcloud-na-ne1-(uat|prd).*",pod=~".*cip.*",container!~"istio-proxy"}[1m])) by (namespace,container, pod)/ on (namespace,container,pod) sum(kube_pod_container_resource_requests{namespace=~"cip-atomcloud-na-ne1-(uat|prd).*",pod=~".*cip.*",container!~"istio-proxy", resource="cpu"}) by (namespace,container,pod)) > 90
        for: 1h
        labels:
          severity: critical
          route: P1-noc-ihub+engfalconihubextnoida
        annotations:
          summary: High CPU Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "CPU Usage is above 90% from last 1 hour. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160184"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P2 : OneIPaaS : CPU utilization > 75% Warning'
        expr: (100 * sum(rate(container_cpu_usage_seconds_total{namespace=~"cip-atomcloud-na-ne1-(uat|prd).*",pod=~".*cip.*",container!~"istio-proxy"}[1m])) by (namespace,container, pod)/ on (namespace,container,pod) sum(kube_pod_container_resource_requests{namespace=~"cip-atomcloud-na-ne1-(uat|prd).*",pod=~".*cip.*",container!~"istio-proxy", resource="cpu"}) by (namespace,container,pod)) > 75
        for: 6h
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: High CPU Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "CPU Usage is above 75% from last 6 hours. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160305"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : CPU utilization > 90% Critical'
        expr: (100 * sum(rate(container_cpu_usage_seconds_total{namespace=~"cip-itc-na-ne1-(uat|prd).*",pod=~".*cip.*",container!~"istio-proxy"}[1m])) by (namespace,container, pod)/ on (namespace,container,pod) sum(kube_pod_container_resource_requests{namespace=~"cip-itc-na-ne1-(uat|prd).*",pod=~".*cip.*",container!~"istio-proxy", resource="cpu"}) by (namespace,container,pod)) > 90
        for: 1h
        labels:
          severity: critical
          route: P1-noc-ihub+engfalconihubextnoida
        annotations:
          summary: High CPU Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "CPU Usage is above 90% from last 1 hour. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160259"
          __dashboardUid__: bdw6uyxa9svlsb

      - alert: '[Alert] : P2 : OneIPaaS : CPU utilization > 75% Warning'
        expr: (100 * sum(rate(container_cpu_usage_seconds_total{namespace=~"cip-itc-na-ne1-(uat|prd).*",pod=~".*cip.*",container!~"istio-proxy"}[1m])) by (namespace,container, pod)/ on (namespace,container,pod) sum(kube_pod_container_resource_requests{namespace=~"cip-itc-na-ne1-(uat|prd).*",pod=~".*cip.*",container!~"istio-proxy", resource="cpu"}) by (namespace,container,pod)) > 75
        for: 6h
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: High CPU Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "CPU Usage is above 75% from last 6 hours. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160307"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : CPU utilization > 90% Critical'
        expr: (100 * sum(rate(container_cpu_usage_seconds_total{namespace=~"cip-ies-na-ne1-(uat|prd).*",pod=~".*cip.*",container!~"istio-proxy"}[1m])) by (namespace,container, pod)/ on (namespace,container,pod) sum(kube_pod_container_resource_requests{namespace=~"cip-ies-na-ne1-(uat|prd).*",pod=~".*cip.*",container!~"istio-proxy", resource="cpu"}) by (namespace,container,pod)) > 90
        for: 1h
        labels:
          severity: critical
          route: P1-noc-ihub+engfalconihubextnoida
        annotations:
          summary: High CPU Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "CPU Usage is above 90% from last 1 hour. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160262"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P2 : OneIPaaS : CPU utilization > 75% Warning'
        expr: (100 * sum(rate(container_cpu_usage_seconds_total{namespace=~"cip-ies-na-ne1-(uat|prd).*",pod=~".*cip.*",container!~"istio-proxy"}[1m])) by (namespace,container, pod)/ on (namespace,container,pod) sum(kube_pod_container_resource_requests{namespace=~"cip-ies-na-ne1-(uat|prd).*",pod=~".*cip.*",container!~"istio-proxy", resource="cpu"}) by (namespace,container,pod)) > 75
        for: 6h
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: High CPU Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "CPU Usage is above 75% from last 6 hours. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160313"
          __dashboardUid__: bdw6uyxa9svlsb

      - alert: '[Alert] : P1 : OneIPaaS : Memory utilization > 85% Critical'
        expr: 100 * (sum by(namespace, pod, container) (container_memory_working_set_bytes{namespace=~"cip-atomcloud-na-ne1-(uat|prd).*",pod=~".*cip.*",container!="istio-proxy"})/sum by(namespace, pod, container) (kube_pod_container_resource_limits{namespace=~"cip-atomcloud-na-ne1-(uat|prd).*",pod=~".*cip.*",container!="istio-proxy",resource="memory"})) > 85
        for: 30m
        labels:
          severity: critical
          route: P1-noc-ihub+engfalconihubextnoida
        annotations:
          summary: High Memory Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Memory Usage is above 85% from last 30 Minutes. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160317"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Memory utilization > 75% Warning'
        expr:  100 * (sum by(namespace, pod, container) (container_memory_working_set_bytes{namespace=~"cip-atomcloud-na-ne1-(uat|prd).*",pod=~".*cip.*",container!="istio-proxy"})/sum by(namespace, pod, container) (kube_pod_container_resource_limits{namespace=~"cip-atomcloud-na-ne1-(uat|prd).*",pod=~".*cip.*",container!="istio-proxy",resource="memory"})) > 75
        for: 60m
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: High Memory Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Memory Usage is above 75% from last 1 hour. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160354"
          __dashboardUid__: bdw6uyxa9svlsb

      - alert: '[Alert] : P1 : OneIPaaS : Memory utilization > 85% Critical'
        expr: 100 * (sum by(namespace, pod, container) (container_memory_usage_bytes{namespace=~"cip-itc-na-ne1-prd", pod=~".*cip.*", container!~".*istio.*"})/on(namespace, pod, container) group_left sum by(namespace, pod, container) (kube_pod_container_resource_limits{namespace=~"cip-itc-na-ne1-prd", pod=~".*cip.*", container!~".*istio.*", resource="memory"})) > 85
        for: 30m
        labels:
          severity: critical
          route: P1-noc-ihub+engfalconihubextnoida
        annotations:
          summary: High Memory Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Memory Usage is above 85% from last 30 Minutes. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160321"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Memory utilization > 75% Warning'
        expr:  100 * (sum by(namespace, pod, container) (container_memory_usage_bytes{namespace=~"cip-itc-na-ne1-prd", pod=~".*cip.*", container!~".*istio.*"})/on(namespace, pod, container) group_left sum by(namespace, pod, container) (kube_pod_container_resource_limits{namespace=~"cip-itc-na-ne1-prd", pod=~".*cip.*", container!~".*istio.*", resource="memory"})) > 75
        for: 60m
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: High Memory Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Memory Usage is above 75% from last 1 hour. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160454"
          __dashboardUid__: bdw6uyxa9svlsb

      - alert: '[Alert] : P1 : OneIPaaS : Memory utilization > 85% Critical'
        expr: 100 * (sum by(namespace, pod, container) (container_memory_usage_bytes{namespace=~"cip-ies-na-ne1-(uat|prd)", pod=~".*cip.*", container!~".*istio.*"})/on(namespace, pod, container) group_left sum by(namespace, pod, container) (kube_pod_container_resource_limits{namespace=~"cip-ies-na-ne1-(uat|prd)", pod=~".*cip.*", container!~".*istio.*", resource="memory"})) > 85
        for: 30m
        labels:
          severity: critical
          route: P1-noc-ihub+engfalconihubextnoida
        annotations:
          summary: High Memory Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Memory Usage is above 85% from last 30 Minutes. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160323"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Memory utilization > 75% Warning'
        expr:  100 * (sum by(namespace, pod, container) (container_memory_usage_bytes{namespace=~"cip-ies-na-ne1-(uat|prd)", pod=~".*cip.*", container!~".*istio.*"})/on(namespace, pod, container) group_left sum by(namespace, pod, container) (kube_pod_container_resource_limits{namespace=~"cip-ies-na-ne1-(uat|prd)", pod=~".*cip.*", container!~".*istio.*", resource="memory"})) > 75
        for: 60m
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: High Memory Utilization for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Memory Usage is above 75% from last 1 hour. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/pages/viewpage.action?pageId=817160456"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Pod Restart'
        expr: (sum by(namespace,pod,container)(increase(kube_pod_container_status_restarts_total{namespace=~"cip-atomcloud-na-ne1-(uat|prd).*",pod=~".*cip.*",container!="istio-proxy"}[1m]))) > 0
        for: 0s
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: Pods Restart for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Pods Restarted. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/display/Falcon/SOP+OneIPaaS+Atom+Cloud%3A+Pod+Rolling+Restart"
          __dashboardUid__: bdw6uyxa9svlsb
      - alert: '[Alert] : P1 : OneIPaaS : Pod Restart'
        expr: (sum by(namespace,pod,container)(increase(kube_pod_container_status_restarts_total{namespace=~"cip-itc-na-ne1-(uat|prd).*",pod=~".*cip.*",container!="istio-proxy"}[1m]))) > 0
        for: 0s
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: Pods Restart for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Pods Restarted. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/display/Falcon/SOP+OneIPaaS+ITC%3A+Pod+Restart"
          __dashboardUid__: bdw6uyxa9svlsb

      - alert: '[Alert] : P1 : OneIPaaS : Pod Restart'
        expr: (sum by(namespace,pod,container)(increase(kube_pod_container_status_restarts_total{namespace=~"cip-ies-na-ne1-(uat|prd).*",pod=~".*cip.*",container!="istio-proxy"}[1m]))) > 0
        for: 0s
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: Pods Restart for OneIPaaS {{$labels.namespace}} {{$labels.pod}} {{$labels.container}}
          description: "Pods Restarted. Please follow the SOP"
          SOPs: "https://engconf.int.kronos.com/display/Falcon/SOP+OneIPaaS+IES%3A+Pod+Restart"
          __dashboardUid__: bdw6uyxa9svlsb

      - alert: '[Alert] : P1 : Atoms Exceed threshold limit'
        expr: 'hub_atoms{} > 1350'
        for: 15m
        labels:
            severity: critical
            route: ihubextintmonitoring
        annotations:
            summary: '{{ $labels.atom_cloud_name }} process has {{ $value }} attached atom'
            description: '{{ $labels.atom_cloud_name }} process has {{ $value }} attached atom'
            SOPs: ""
            __dashboardUid__: bdw6uyxa9svlsb

      - alert: '[Alert] : P2 : Atoms Exceed threshold limit'
        expr: 'hub_atoms{} > 1200'
        for: 12h
        labels:
          severity: warning
          route: ihubextintmonitoring
        annotations:
          summary: '{{ $labels.atom_cloud_name }} process has {{ $value }} attached atom'
          description: '{{ $labels.atom_cloud_name }} process has {{ $value }} attached atom'
          SOPs: ""
          __dashboardUid__: bdw6uyxa9svlsb


  - name: CMP
    rules:
      - alert: CMP K8s - ATL - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="atl", namespace="mp-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: CMP
        annotations:
          summary: CMP K8s - ATL - Pod(s) not in a running phase
          description: "CMP K8s - ATL - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: cdpr49b0dnw8wa
          __panelId__: '4'
      - alert: CMP K8s - PLAS1 - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="plas1", namespace="mp-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: CMP
        annotations:
          summary: CMP K8s - PLAS1 - Pod(s) not in a running phase
          description: "CMP K8s - PLAS1 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: cdpr49b0dnw8wa
          __panelId__: '4'
      - alert: CMP K8s - TOR - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="tor", namespace="mp-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: CMP
        annotations:
          summary: CMP K8s - TOR - Pod(s) not in a running phase
          description: "CMP K8s - TOR - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: cdpr49b0dnw8wa
          __panelId__: '4'
      - alert: CMP K8s - US-EAST1 - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="us-east1", namespace="mp-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: CMP
        annotations:
          summary: CMP K8s - US-EAST1 - Pod(s) not in a running phase
          description: "CMP K8s - US-EAST1 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: cdpr49b0dnw8wa
          __panelId__: '4'
      - alert: CMP K8s - US-EAST4 - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="us-east4", namespace="mp-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: CMP
        annotations:
          summary: CMP K8s - US-EAST4 - Pod(s) not in a running phase
          description: "CMP K8s - US-EAST4 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: cdpr49b0dnw8wa
          __panelId__: '4'
      - alert: CMP K8s - NA-NE1 - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="northamerica-northeast1", namespace="mp-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: CMP
        annotations:
          summary: CMP K8s - NA-NE1 - Pod(s) not in a running phase
          description: "CMP K8s - NA-NE1 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: cdpr49b0dnw8wa
          __panelId__: '4'
      - alert: CMP K8s - NA-NE2 - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="northamerica-northeast2", namespace="mp-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: CMP
        annotations:
          summary: CMP K8s - NA-NE2 - Pod(s) not in a running phase
          description: "CMP K8s - NA-NE2 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: cdpr49b0dnw8wa
          __panelId__: '4'
      - alert: CMP K8s - AUSTRALIA-SOUTHEAST1 - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="australia-southeast1", namespace="mp-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: CMP
        annotations:
          summary: CMP K8s - AUSTRALIA-SOUTHEAST1 - Pod(s) not in a running phase
          description: "CMP K8s - AUSTRALIA-SOUTHEAST1 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: cdpr49b0dnw8wa
          __panelId__: '4'
      - alert: CMP K8s - AUSTRALIA-SOUTHEAST2 - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="australia-southeast2", namespace="mp-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: CMP
        annotations:
          summary: CMP K8s - AUSTRALIA-SOUTHEAST2 - Pod(s) not in a running phase
          description: "CMP K8s - AUSTRALIA-SOUTHEAST2 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: cdpr49b0dnw8wa
          __panelId__: '4'
      - alert: CMP K8s - EUROPE-WEST4 - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="europe-west4", namespace="mp-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: CMP
        annotations:
          summary: CMP K8s - EUROPE-WEST4 - Pod(s) not in a running phase
          description: "CMP K8s - EUROPE-WEST4 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: cdpr49b0dnw8wa
          __panelId__: '4'
      - alert: CMP K8s - EUROPE-WEST1 - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="europe-west1", namespace="mp-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: CMP
        annotations:
          summary: CMP K8s - EUROPE-WEST1 - Pod(s) not in a running phase
          description: "CMP K8s - EUROPE-WEST1 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: cdpr49b0dnw8wa
          __panelId__: '4'
      - alert: Schema Registry - ATL - Average Eventhandler Count
        expr: avg(eventhandler_seconds{datacenter="atl", namespace="mp-prod", application="schema-registry"}) > 0
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - ATL - Average eventhandler count > 0
          description: "Schema Registry - ATL - Average eventhandler count is {{ $value }}"
          __dashboardUid__: edumseqtp2tq8f
          __panelId__: '1'
      - alert: Schema Registry - PLAS1 - Average Eventhandler Count
        expr: avg(eventhandler_seconds{datacenter="plas1", namespace="mp-prod", application="schema-registry"}) > 0
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - PLAS1 - Average eventhandler count > 0
          description: "Schema Registry - PLAS1 - Average eventhandler count is {{ $value }}"
          __dashboardUid__: edumseqtp2tq8f
          __panelId__: '1'
      - alert: Schema Registry - TOR - Average Eventhandler Count
        expr: avg(eventhandler_seconds{datacenter="tor", namespace="mp-prod", application="schema-registry"}) > 0
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - TOR - Average eventhandler count > 0
          description: "Schema Registry - TOR - Average eventhandler count is {{ $value }}"
          __dashboardUid__: edumseqtp2tq8f
          __panelId__: '1'
      - alert: Schema Registry - US-EAST1 - Average Eventhandler Count
        expr: avg(eventhandler_seconds{datacenter="us-east1", namespace="mp-prod", application="schema-registry"}) > 0
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - US-EAST1 - Average eventhandler count > 0
          description: "Schema Registry - US-EAST1 - Average eventhandler count is {{ $value }}"
          __dashboardUid__: edumseqtp2tq8f
          __panelId__: '1'
      - alert: Schema Registry - US-EAST4 - Average Eventhandler Count
        expr: avg(eventhandler_seconds{datacenter="us-east4", namespace="mp-prod", application="schema-registry"}) > 0
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - US-EAST4 - Average eventhandler count > 0
          description: "Schema Registry - US-EAST4 - Average eventhandler count is {{ $value }}"
          __dashboardUid__: edumseqtp2tq8f
          __panelId__: '1'
      - alert: Schema Registry - NA-NE1 - Average Eventhandler Count
        expr: avg(eventhandler_seconds{datacenter="northamerica-northeast1", namespace="mp-prod", application="schema-registry"}) > 0
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - NA-NE1 - Average eventhandler count > 0
          description: "Schema Registry - NA-NE1 - Average eventhandler count is {{ $value }}"
          __dashboardUid__: edumseqtp2tq8f
          __panelId__: '1'
      - alert: Schema Registry - NA-NE2 - Average Eventhandler Count
        expr: avg(eventhandler_seconds{datacenter="northamerica-northeast2", namespace="mp-prod", application="schema-registry"}) > 0
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - NA-NE2 - Average eventhandler count > 0
          description: "Schema Registry - NA-NE2 - Average eventhandler count is {{ $value }}"
          __dashboardUid__: edumseqtp2tq8f
          __panelId__: '1'
      - alert: Schema Registry - AUSTRALIA-SOUTHEAST1 - Average Eventhandler Count
        expr: avg(eventhandler_seconds{datacenter="australia-southeast1", namespace="mp-prod", application="schema-registry"}) > 0
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - AUSTRALIA-SOUTHEAST1 - Average eventhandler count > 0
          description: "Schema Registry - AUSTRALIA-SOUTHEAST1 - Average eventhandler count is {{ $value }}"
          __dashboardUid__: edumseqtp2tq8f
          __panelId__: '1'
      - alert: Schema Registry - AUSTRALIA-SOUTHEAST2 - Average Eventhandler Count
        expr: avg(eventhandler_seconds{datacenter="australia-southeast2", namespace="mp-prod", application="schema-registry"}) > 0
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - AUSTRALIA-SOUTHEAST2 - Average eventhandler count > 0
          description: "Schema Registry - AUSTRALIA-SOUTHEAST2 - Average eventhandler count is {{ $value }}"
          __dashboardUid__: edumseqtp2tq8f
          __panelId__: '1'
      - alert: Schema Registry - EUROPE-WEST4 - Average Eventhandler Count
        expr: avg(eventhandler_seconds{datacenter="europe-west4", namespace="mp-prod", application="schema-registry"}) > 0
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - EUROPE-WEST4 - Average eventhandler count > 0
          description: "Schema Registry - EUROPE-WEST4 - Average eventhandler count is {{ $value }}"
          __dashboardUid__: edumseqtp2tq8f
          __panelId__: '1'
      - alert: Schema Registry - EUROPE-WEST1 - Average Eventhandler Count
        expr: avg(eventhandler_seconds{datacenter="europe-west1", namespace="mp-prod", application="schema-registry"}) > 0
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - EUROPE-WEST1 - Average eventhandler count > 0
          description: "Schema Registry - EUROPE-WEST1 - Average eventhandler count is {{ $value }}"
          __dashboardUid__: edumseqtp2tq8f
          __panelId__: '1'
      - alert: Schema Registry - ATL - Average Request Latency
        expr: avg by(method, uri) (rate(http_server_requests_seconds_sum{datacenter="atl", namespace="mp-prod", application="schema-registry"}[5m])) / avg by(method, uri) (rate(http_server_requests_seconds_count{datacenter="atl", namespace="mp-prod", application="schema-registry"}[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - ATL - Average request latency > 100 ms
          description: "Schema Registry - ATL - Average request latency is {{ $value }} sec"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '2'
      - alert: Schema Registry - PLAS1 - Average Request Latency
        expr: avg by(method, uri) (rate(http_server_requests_seconds_sum{datacenter="plas1", namespace="mp-prod", application="schema-registry"}[5m])) / avg by(method, uri) (rate(http_server_requests_seconds_count{datacenter="plas1", namespace="mp-prod", application="schema-registry"}[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - PLAS1 - Average request latency > 100 ms
          description: "Schema Registry - PLAS1 - Average request latency is {{ $value }} sec"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '2'
      - alert: Schema Registry - TOR - Average Request Latency
        expr: avg by(method, uri) (rate(http_server_requests_seconds_sum{datacenter="tor", namespace="mp-prod", application="schema-registry"}[5m])) / avg by(method, uri) (rate(http_server_requests_seconds_count{datacenter="tor", namespace="mp-prod", application="schema-registry"}[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - TOR - Average request latency > 100 ms
          description: "Schema Registry - TOR - Average request latency is {{ $value }} sec"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '2'
      - alert: Schema Registry - US-EAST1 - Average Request Latency
        expr: avg by(method, uri) (rate(http_server_requests_seconds_sum{datacenter="us-east1", namespace="mp-prod", application="schema-registry"}[5m])) / avg by(method, uri) (rate(http_server_requests_seconds_count{datacenter="us-east1", namespace="mp-prod", application="schema-registry"}[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - US-EAST1 - Average request latency > 100 ms
          description: "Schema Registry - US-EAST1 - Average request latency is {{ $value }} sec"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '2'
      - alert: Schema Registry - US-EAST4 - Average Request Latency
        expr: avg by(method, uri) (rate(http_server_requests_seconds_sum{datacenter="us-east4", namespace="mp-prod", application="schema-registry"}[5m])) / avg by(method, uri) (rate(http_server_requests_seconds_count{datacenter="us-east4", namespace="mp-prod", application="schema-registry"}[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - US-EAST4 - Average request latency > 100 ms
          description: "Schema Registry - US-EAST4 - Average request latency is {{ $value }} sec"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '2'
      - alert: Schema Registry - NA-NE1 - Average Request Latency
        expr: avg by(method, uri) (rate(http_server_requests_seconds_sum{datacenter="northamerica-northeast1", namespace="mp-prod", application="schema-registry", uri!="/health", uri!="/liveness", uri!="/prometheus"}[5m])) / avg by(method, uri) (rate(http_server_requests_seconds_count{datacenter="northamerica-northeast1", namespace="mp-prod", application="schema-registry", uri!="/health", uri!="/liveness", uri!="/prometheus"}[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - NA-NE1 - Average request latency > 100 ms
          description: "Schema Registry - NA-NE1 - Average request latency is {{ $value }} sec"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '2'
      - alert: Schema Registry - NA-NE2 - Average Request Latency
        expr: avg by(method, uri) (rate(http_server_requests_seconds_sum{datacenter="northamerica-northeast2", namespace="mp-prod", application="schema-registry", uri!="/health", uri!="/liveness", uri!="/prometheus"}[5m])) / avg by(method, uri) (rate(http_server_requests_seconds_count{datacenter="northamerica-northeast2", namespace="mp-prod", application="schema-registry", uri!="/health", uri!="/liveness", uri!="/prometheus"}[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - NA-NE2 - Average request latency > 100 ms
          description: "Schema Registry - NA-NE2 - Average request latency is {{ $value }} sec"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '2'
      - alert: Schema Registry - AUSTRALIA-SOUTHEAST1 - Average Request Latency
        expr: avg by(method, uri) (rate(http_server_requests_seconds_sum{datacenter="australia-southeast1", namespace="mp-prod", application="schema-registry", uri!="/health", uri!="/liveness", uri!="/prometheus"}[5m])) / avg by(method, uri) (rate(http_server_requests_seconds_count{datacenter="australia-southeast1", namespace="mp-prod", application="schema-registry", uri!="/health", uri!="/liveness", uri!="/prometheus"}[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - AUSTRALIA-SOUTHEAST1 - Average request latency > 100 ms
          description: "Schema Registry - AUSTRALIA-SOUTHEAST1 - Average request latency is {{ $value }} sec"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '2'
      - alert: Schema Registry - AUSTRALIA-SOUTHEAST2 - Average Request Latency
        expr: avg by(method, uri) (rate(http_server_requests_seconds_sum{datacenter="australia-southeast2", namespace="mp-prod", application="schema-registry", uri!="/health", uri!="/liveness", uri!="/prometheus"}[5m])) / avg by(method, uri) (rate(http_server_requests_seconds_count{datacenter="australia-southeast2", namespace="mp-prod", application="schema-registry", uri!="/health", uri!="/liveness", uri!="/prometheus"}[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - AUSTRALIA-SOUTHEAST2 - Average request latency > 100 ms
          description: "Schema Registry - AUSTRALIA-SOUTHEAST2 - Average request latency is {{ $value }} sec"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '2'
      - alert: Schema Registry - EUROPE-WEST4 - Average Request Latency
        expr: avg by(method, uri) (rate(http_server_requests_seconds_sum{datacenter="europe-west4", namespace="mp-prod", application="schema-registry", uri!="/health", uri!="/liveness", uri!="/prometheus"}[5m])) / avg by(method, uri) (rate(http_server_requests_seconds_count{datacenter="europe-west4", namespace="mp-prod", application="schema-registry", uri!="/health", uri!="/liveness", uri!="/prometheus"}[5m])) > 0.12
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - EUROPE-WEST4 - Average request latency > 120 ms
          description: "Schema Registry - EUROPE-WEST4 - Average request latency is {{ $value }} sec"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '2'
      - alert: Schema Registry - EUROPE-WEST1 - Average Request Latency
        expr: avg by(method, uri) (rate(http_server_requests_seconds_sum{datacenter="europe-west1", namespace="mp-prod", application="schema-registry", uri!="/health", uri!="/liveness", uri!="/prometheus"}[5m])) / avg by(method, uri) (rate(http_server_requests_seconds_count{datacenter="europe-west1", namespace="mp-prod", application="schema-registry", uri!="/health", uri!="/liveness", uri!="/prometheus"}[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - EUROPE-WEST1 - Average request latency > 100 ms
          description: "Schema Registry - EUROPE-WEST1 - Average request latency is {{ $value }} sec"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '2'
      - alert: Schema Registry - ATL - Response Status
        expr: sum by(status) (increase(http_server_requests_seconds_count{datacenter="atl", namespace="mp-prod", application="schema-registry", status!~"(2|4).*", exception!="RequestRejectedException"}[5m])) > 0
        for: 1m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - ATL - Unexpected Response Status
          description: "Schema Registry - ATL - Received {{ $value }} unexpected response statuses"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '3'
      - alert: Schema Registry - PLAS1 - Response Status
        expr: sum by(status) (increase(http_server_requests_seconds_count{datacenter="plas1", namespace="mp-prod", application="schema-registry", status!~"(2|4).*", exception!="RequestRejectedException"}[5m])) > 0
        for: 1m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - PLAS1 - Unexpected Response Status
          description: "Schema Registry - PLAS1 - Received {{ $value }} unexpected response statuses"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '3'
      - alert: Schema Registry - TOR - Response Status
        expr: sum by(status) (increase(http_server_requests_seconds_count{datacenter="tor", namespace="mp-prod", application="schema-registry", status!~"(2|4).*", exception!="RequestRejectedException"}[5m])) > 0
        for: 1m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - TOR - Unexpected Response Status
          description: "Schema Registry - TOR - Received {{ $value }} unexpected response statuses"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '3'
      - alert: Schema Registry - US-EAST1 - Response Status
        expr: sum by(status) (increase(http_server_requests_seconds_count{datacenter="us-east1", namespace="mp-prod", application="schema-registry", status!~"(2|4).*", exception!="RequestRejectedException"}[5m])) > 0
        for: 1m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - US-EAST1 - Unexpected Response Status
          description: "Schema Registry - US-EAST1 - Received {{ $value }} unexpected response statuses"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '3'
      - alert: Schema Registry - US-EAST4 - Response Status
        expr: sum by(status) (increase(http_server_requests_seconds_count{datacenter="us-east4", namespace="mp-prod", application="schema-registry", status!~"(2|4).*", exception!="RequestRejectedException"}[5m])) > 0
        for: 1m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - US-EAST4 - Unexpected Response Status
          description: "Schema Registry - US-EAST4 - Received {{ $value }} unexpected response statuses"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '3'
      - alert: Schema Registry - NA-NE1 - Response Status
        expr: sum by(status) (increase(http_server_requests_seconds_count{datacenter="northamerica-northeast1", namespace="mp-prod", application="schema-registry", status!~"(2|4).*", exception!="RequestRejectedException"}[5m])) > 0
        for: 1m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - NA-NE1 - Unexpected Response Status
          description: "Schema Registry - NA-NE1 - Received {{ $value }} unexpected response statuses"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '3'
      - alert: Schema Registry - NA-NE2 - Response Status
        expr: sum by(status) (increase(http_server_requests_seconds_count{datacenter="northamerica-northeast2", namespace="mp-prod", application="schema-registry", status!~"(2|4).*", exception!="RequestRejectedException"}[5m])) > 0
        for: 1m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - NA-NE2 - Unexpected Response Status
          description: "Schema Registry - NA-NE2 - Received {{ $value }} unexpected response statuses"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '3'
      - alert: Schema Registry - AUSTRALIA-SOUTHEAST1 - Response Status
        expr: sum by(status) (increase(http_server_requests_seconds_count{datacenter="australia-southeast1", namespace="mp-prod", application="schema-registry", status!~"(2|4).*", exception!="RequestRejectedException"}[5m])) > 0
        for: 1m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - AUSTRALIA-SOUTHEAST1 - Unexpected Response Status
          description: "Schema Registry - AUSTRALIA-SOUTHEAST1 - Received {{ $value }} unexpected response statuses"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '3'
      - alert: Schema Registry - AUSTRALIA-SOUTHEAST2 - Response Status
        expr: sum by(status) (increase(http_server_requests_seconds_count{datacenter="australia-southeast2", namespace="mp-prod", application="schema-registry", status!~"(2|4).*", exception!="RequestRejectedException"}[5m])) > 0
        for: 1m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - AUSTRALIA-SOUTHEAST2 - Unexpected Response Status
          description: "Schema Registry - AUSTRALIA-SOUTHEAST2 - Received {{ $value }} unexpected response statuses"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '3'
      - alert: Schema Registry - EUROPE-WEST4 - Response Status
        expr: sum by(status) (increase(http_server_requests_seconds_count{datacenter="europe-west4", namespace="mp-prod", application="schema-registry", status!~"(2|4).*", exception!="RequestRejectedException"}[5m])) > 0
        for: 1m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - EUROPE-WEST4 - Unexpected Response Status
          description: "Schema Registry - EUROPE-WEST4 - Received {{ $value }} unexpected response statuses"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '3'
      - alert: Schema Registry - EUROPE-WEST1 - Response Status
        expr: sum by(status) (increase(http_server_requests_seconds_count{datacenter="europe-west1", namespace="mp-prod", application="schema-registry", status!~"(2|4).*", exception!="RequestRejectedException"}[5m])) > 0
        for: 1m
        labels:
          severity: warning
          route: CMP
        annotations:
          summary: Schema Registry - EUROPE-WEST1 - Unexpected Response Status
          description: "Schema Registry - EUROPE-WEST1 - Received {{ $value }} unexpected response statuses"
          __dashboardUid__: ddu1jlvb7iby8e
          __panelId__: '3'
   #Informatica - OnPrem
  - name: infa-prod
    interval: 30m
    rules:
      - alert: '[Alert] : infa-prod : P1 : E0IADSFS11 : Disk Usage (Above 80%)'
        expr: |
          (1 - (windows_logical_disk_free_bytes{instance="E0IADSFS11", volume="I:"} 
          / windows_logical_disk_size_bytes{instance="E0IADSFS11", volume="I:"})) * 100 > 80
        for: 30m
        labels:
          severity: critical
          route: informatica_infrastructure_monitoring
        annotations:
          summary: "High disk usage on instance E0IADSFS11"
          description: "Disk usage on E0IADSFS11 is above 80% for drive I:\nVALUE = {{ $value }}"
          __dashboardUid__: "cdx09sa645dkwd"
          __panelId__: '1'

      - alert: '[Alert] : infa-prod : P1 : EW0IADSFS11 : Disk Usage (Above 80%)'
        expr: |
          (1 - (windows_logical_disk_free_bytes{instance="EW0IADSFS11", volume="I:"} 
          / windows_logical_disk_size_bytes{instance="EW0IADSFS11", volume="I:"})) * 100 > 80
        for: 30m
        labels:
          severity: critical
          route: informatica_infrastructure_monitoring
        annotations:
          summary: "High disk usage on instance EW0IADSFS11"
          description: "Disk usage on EW0IADSFS11 is above 80% for drive I:\nVALUE = {{ $value }}"
          __dashboardUid__: "cdx09sa645dkwd"
          __panelId__: '2'

      - alert: '[Alert] : infa-prod : P1 : n0iadsfs12 : Disk Usage (Above 80%)'
        expr: |
          (1 - (windows_logical_disk_free_bytes{instance="n0iadsfs12", volume="J:"} 
          / windows_logical_disk_size_bytes{instance="n0iadsfs12", volume="J:"})) * 100 > 80
        for: 30m
        labels:
          severity: critical
          route: informatica_infrastructure_monitoring
        annotations:
          summary: "High disk usage on instance n0iadsfs12"
          description: "Disk usage on n0iadsfs12 is above 80% for drive J:\nVALUE = {{ $value }}"
          __dashboardUid__: "cdx09sa645dkwd"
          __panelId__: '3'

      - alert: '[Alert] : infa-prod : P1 : CPU Usage (Above 80%)'
        expr: |
          100 - (avg by (instance) (irate(windows_cpu_time_total{mode="idle", instance=~"e0infoap01|e0infohv01|e0infomc01|ew0infoap01|ew0infohv01|ew0infomc01|n0infoap01|n0infohv01|n0infomc01"}[5m])) * 100) > 80
        for: 20m
        labels:
          severity: critical
          route: informatica_infrastructure_monitoring
        annotations:
          summary: "High CPU usage on server {{ $labels.instance }}"
          description: "CPU usage on {{ $labels.instance }} is above 80%\nVALUE = {{ $value }}"
          __dashboardUid__: "bdx3bq77v5ds0d"
          __panelId__: '19'

      - alert: '[Alert] : infa-prod : P1 : Memory Usage (Above 80%)'
        expr: |
          (windows_cs_physical_memory_bytes{instance=~"e0infoap01|e0infohv01|e0infomc01|ew0infoap01|ew0infohv01|ew0infomc01|n0infoap01|n0infohv01|n0infomc01"} - windows_os_physical_memory_free_bytes{instance=~"e0infoap01|e0infohv01|e0infomc01|ew0infoap01|ew0infohv01|ew0infomc01|n0infoap01|n0infohv01|n0infomc01"}) / windows_cs_physical_memory_bytes{instance=~"e0infoap01|e0infohv01|e0infomc01|ew0infoap01|ew0infohv01|ew0infomc01|n0infoap01|n0infohv01|n0infomc01"} * 100 > 80
        for: 20m
        labels:
          severity: critical
          route: informatica_infrastructure_monitoring
        annotations:
          summary: "High memory usage on server {{ $labels.instance }}"
          description: "Memory usage on {{ $labels.instance }} is above 80%\nVALUE = {{ $value }}"
          __dashboardUid__: "bdx3bq77v5ds0d"
          __panelId__: '21'

      - alert: '[Alert] : infa-prod : P1 : Disk Usage (Above 80%)'
        expr: |
          (sum(windows_logical_disk_size_bytes{volume!~"Harddisk.*", instance=~"e0infoap01|e0infohv01|e0infomc01|ew0infoap01|ew0infohv01|ew0infomc01|n0infoap01|n0infohv01|n0infomc01"}) by (instance) - sum(windows_logical_disk_free_bytes{volume!~"Harddisk.*", instance=~"e0infoap01|e0infohv01|e0infomc01|ew0infoap01|ew0infohv01|ew0infomc01|n0infoap01|n0infohv01|n0infomc01"}) by (instance)) / sum(windows_logical_disk_size_bytes{volume!~"Harddisk.*", instance=~"e0infoap01|e0infohv01|e0infomc01|ew0infoap01|ew0infohv01|ew0infomc01|n0infoap01|n0infohv01|n0infomc01"}) by (instance) * 100 > 80
        for: 30m
        labels:
          severity: critical
          route: informatica_infrastructure_monitoring
        annotations:
          summary: "High disk usage on server {{ $labels.instance }}"
          description: "Disk usage on {{ $labels.instance }} is above 80%\nVALUE = {{ $value }}"
          __dashboardUid__: "bdx3bq77v5ds0d"
          __panelId__: '23'

      - alert: '[Alert] : infa-prod : P1 : Hard Disk Usage (Above 80%)'
        expr: |
          100 - (windows_logical_disk_free_bytes{instance=~"e0infoap01|e0infohv01|e0infomc01|ew0infoap01|ew0infohv01|ew0infomc01|n0infoap01|n0infohv01|n0infomc01", volume=~"C:|D:|HarddiskVolume1"} / windows_logical_disk_size_bytes{instance=~"e0infoap01|e0infohv01|e0infomc01|ew0infoap01|ew0infohv01|ew0infomc01|n0infoap01|n0infohv01|n0infomc01", volume=~"C:|D:|HarddiskVolume1"}) * 100 > 80
        for: 30m
        labels:
          severity: critical
          route: informatica_infrastructure_monitoring
        annotations:
          summary: "Hard disk usage on server {{ $labels.instance }} for volume {{ $labels.volume }}"
          description: "Hard Disk usage on {{ $labels.instance }} for volume {{ $labels.volume }} is above 80%\nVALUE = {{ $value }}"
          __dashboardUid__: "bdx3bq77v5ds0d"
          __panelId__: '40'

      - alert: '[Alert] : infa-prod : P1 : Bandwidth Usage (Above 150MB/s)'
        expr: |
          rate(windows_net_bytes_sent_total{instance=~"e0infoap01|e0infohv01|e0infomc01|ew0infoap01|ew0infohv01|ew0infomc01|n0infoap01|n0infohv01|n0infomc01"}[1m]) > 150
        for: 10m
        labels:
          severity: critical
          route: informatica_infrastructure_monitoring
        annotations:
          summary: "High disk write usage on server {{ $labels.instance }}"
          description: " Bandwidth usage on {{ $labels.instance }} is above 150 MiB/s for more than 10 minutes\nVALUE = {{ $value }}"
          __dashboardUid__: "bdx3bq77v5ds0d"
          __panelId__: '11'


      - alert: '[Alert] : infa-prod : P1 : Disk Write (Above 5 MiB/s)'
        expr: |
          irate(windows_logical_disk_write_bytes_total{instance=~"e0infoap01|e0infohv01|e0infomc01|ew0infoap01|ew0infohv01|ew0infomc01|n0infoap01|n0infohv01|n0infomc01", volume !~"HarddiskVolume.+"}[10m])/ 1048576 > 5
        for: 10m
        labels:
          severity: critical
          route: informatica_infrastructure_monitoring
        annotations:
          summary: "High disk write usage on server {{ $labels.instance }}"
          description: "Disk write usage on {{ $labels.instance }} is above 5 MiB/s for more than 10 minutes\nVALUE = {{ $value }}"
          __dashboardUid__: "bdx3bq77v5ds0d"
          __panelId__: '8'

      - alert: '[Alert] : infa-prod : P1 : Disk Read (Above 5 MiB/s)'
        expr: |
          irate(windows_logical_disk_read_bytes_total{instance=~"e0infoap01|e0infohv01|e0infomc01|ew0infoap01|ew0infohv01|ew0infomc01|n0infoap01|n0infohv01|n0infomc01", volume !~"HarddiskVolume.+"}[10m])/ 1048576 > 5
        for: 10m
        labels:
          severity: critical
          route: informatica_infrastructure_monitoring
        annotations:
          summary: "High disk read usage on server {{ $labels.instance }}"
          description: "Disk read usage on {{ $labels.instance }} is above 5 MiB/s for more than 10 minutes\nVALUE = {{ $value }}"
          __dashboardUid__: "bdx3bq77v5ds0d"
          __panelId__: '8'

      - alert: '[Alert] : Informatica Prod : P1 : Informatica Windows Services Down'
        expr: 'windows_service_state{name="infa|info",instance=~"e0infoap01|ew0infoap01|n0infoap01"} < 5'
        for: 1m
        labels:
          severity: critical
          route: informatica_infrastructure_monitoring
        annotations:
          summary:  Informatica Windows Services Down. (instance {{ $labels.instance }})
          description: "Informatica Windows Services Down"
          __dashboardUid__: "b4FAZ7Mmz"
          __panelId__: '5'

      - alert: '[Alert] : edifecs Prod : P1 : edifecs Windows Services Down'
        expr: 'windows_service_state{name="eam|edifecs|vs-",instance=~"e0infohv01|ew0infohv01|n0infohv0"} < 6'
        for: 1m
        labels:
          severity: critical
          route: informatica_infrastructure_monitoring
        annotations:
          summary: edifecs for UCN Windows Services Down. (instance {{ $labels.instance }})
          description: "edifecs for UCN Windows Services Down"
          __dashboardUid__: "b4FAZ7Mmz"
          __panelId__: '5'

  # Trox Alerts
  - name: TROX Alerts
    rules:
      - alert: 'High Memory Usage for Container Envoy Trox in K8s Environment'
        expr: '((sum by (namespace, pod, cluster_name, container, datacenter) (container_memory_working_set_bytes{container="envoy-trox"}) * 100) / sum by (namespace, pod, cluster_name, container, datacenter) (kube_pod_container_resource_limits{resource="memory", container="envoy-trox"})) >= 75'
        for: 5m
        labels:
          severity: critical
          route: troxalerts
        annotations:
          summary: 'High Memory Usage Detected for Envoy Trox Container in K8s Environment [ Data Source is UKG Pro ] '
          description: 'Memory usage for container {{ $labels.container }} in pod {{ $labels.pod }} in namespace {{ $labels.namespace }} in cluster {{ $labels.cluster_name }} in datacenter {{ $labels.datacenter }} has exceeded or is equal to 75% for 5 minutes. Data Source is UKG Pro . '
          __dashboardUid__: cdxcp3j9bby0we
          __panelId__: '17'

      - alert: 'High CPU Usage for Container Envoy Trox in K8s Environment'
        expr: '((sum by (cluster_name, container, datacenter, namespace, pod) (rate(container_cpu_usage_seconds_total{container="envoy-trox"}[1m])) / sum by (cluster_name, container, datacenter, namespace, pod) (kube_pod_container_resource_limits{container="envoy-trox", resource="cpu"})) * 100) >= 90'
        for: 5m
        labels:
          severity: critical
          route: troxalerts
        annotations:
          summary: 'High CPU Usage Detected for Envoy Trox Container in K8s Environment [ Data Source is UKG Pro ] '
          description: 'CPU usage for container {{ $labels.container }} in pod {{ $labels.pod }} in namespace {{ $labels.namespace }} in cluster {{ $labels.cluster_name }} in datacenter {{ $labels.datacenter }} has exceeded or is equal to 90% for 5 minutes. Data Source is UKG Pro .'
          __dashboardUid__: cdxcp3j9bby0we
          __panelId__: '15'

      - alert: 'Envoy Trox Container Restarts in K8s Environment'
        expr: 'increase(kube_pod_container_status_restarts_total{container=~"envoy-trox"}[30m]) >= 2'
        for: 30s
        labels:
          severity: warning
          route: troxalerts
        annotations:
          summary: 'Container Restarts Detected for Envoy Trox Container in K8s Environment [ Data Source is UKG Pro ]  '
          description: 'The container {{ $labels.container }} in pod {{ $labels.pod }} within namespace {{ $labels.namespace }} has restarted 2 or more times within the last 30 minutes in cluster {{ $labels.cluster_name }} at datacenter {{ $labels.datacenter }}. Data Source is UKG Pro . '
          __dashboardUid__: cdxcp3j9bby0we
          __panelId__: '19'

      - alert: 'Error occurred in Target Service in K8s Environment (External Origin Request)'
        expr: 'increase({__name__=~".*_cluster_external_upstream_rq_total", envoy_cluster_name=~".+", envoy_response_code=~"^[45].*", datacenter=~".+", envoy_cluster_name!="opentelemetry_collector"}[1m]) >= 1'
        for: 5m
        labels:
          severity: critical
          route: troxalerts
        annotations:
          summary: 'Error occurred in Target Service in K8s Environment [Data Source is UKG Pro] (External Origin Request) '
          description: 'Error occurred in Target Service (External Origin Request). Envoy cluster name is {{ $labels.envoy_cluster_name }}, datacenter is {{ $labels.datacenter }}, cluster name is {{ $labels.cluster_name }}, and envoy response code is {{ $labels.envoy_response_code }}.Data Source is UKG Pro . '
          __dashboardUid__: edxo585biolc0c
          __panelId__: '14'

      - alert: 'Error occurred in Target Service in K8s Environment (Internal Origin Request)'
        expr: 'increase({__name__=~".*_cluster_internal_upstream_rq_total", envoy_cluster_name=~".+", envoy_response_code=~"^[45].*", datacenter=~".+", envoy_cluster_name!="opentelemetry_collector"}[1m]) >= 1'
        for: 5m
        labels:
          severity: critical
          route: troxalerts
        annotations:
          summary: 'Error occurred in Target Service in K8s Environment [Data Source is UKG Pro] (Internal Origin Request) '
          description: 'Error occurred in Target Service (Internal Origin Request). Envoy cluster name is {{ $labels.envoy_cluster_name }}, datacenter is {{ $labels.datacenter }}, cluster name is {{ $labels.cluster_name }}, and envoy response code is {{ $labels.envoy_response_code }}.Data Source is UKG Pro. '
          __dashboardUid__: edxo585biolc0c
          __panelId__: '14'

      - alert: 'High Memory Usage Detected for Envoy Process in VM'
        expr: 'sum by (cluster_id, env_id, instance, instance_name, machineType, project, scope, service_function, service_name, stack_id, zone) (namedprocess_namegroup_memory_bytes{groupname="envoy", memtype="resident",instance_name=~".+"}) / sum by (cluster_id, env_id, instance, instance_name, machineType, project, scope, service_function, service_name, stack_id, zone) (envoy_memory_max{instance_name=~".+"}) * 100 >= 75'
        for: 5m
        labels:
          severity: critical
          route: troxalerts
        annotations:
          summary: 'High Memory Usage Detected for Envoy Process in VM [ Data Source is UKG Pro ] '
          description: 'Memory usage for Envoy process in VM {{ $labels.instance_name }} (instance {{ $labels.instance }}) in project {{ $labels.project }} in zone {{ $labels.zone }} has exceeded or is equal to 75% of the allocated memory max for 5 minutes. Environment: {{ $labels.env_id }}, Stack: {{ $labels.stack_id }}, Service: {{ $labels.service_name }}, Machine Type: {{ $labels.machineType }} .  Data Source is UKG Pro . '
          __dashboardUid__: fe3synjgt3fuob
          __panelId__: '11'

      - alert: 'Error occurred in Target Service (External Origin Request) (VM)'
        expr: 'increase({__name__=~".*_cluster_external_upstream_rq_total", envoy_cluster_name!="opentelemetry_collector", envoy_cluster_name=~".+", envoy_response_code=~"^[45].*",instance_name=~".+"}[1m]) >= 1'
        for: 5m
        labels:
          severity: critical
          route: troxalerts
        annotations:
          summary: 'Error occurred in Target Service (External Origin Request) (VM) [ Data Source is UKG Pro ] '
          description: 'Error occurred in Target Service (External Origin Request). Instance name is {{ $labels.instance_name }}, Envoy cluster name is {{ $labels.envoy_cluster_name }}, environment is {{ $labels.env_id }}, project is {{ $labels.project }}, zone is {{ $labels.zone }}, service name is {{ $labels.service_name }}, machine type is {{ $labels.machineType }}, envoy response code is {{ $labels.envoy_response_code }}, stack id is {{ $labels.stack_id }}.  Data Source is UKG Pro  .'
          __dashboardUid__: ae1in6jhkm60wa
          __panelId__: '14'

      - alert: 'Error occurred in Target Service (Internal Origin Request) (VM)'
        expr: 'increase({__name__=~".*_cluster_internal_upstream_rq_total", envoy_cluster_name!="opentelemetry_collector", envoy_cluster_name=~".+", envoy_response_code=~"^[45].*",instance_name=~".+"}[1m]) >= 1'
        for: 5m
        labels:
          severity: critical
          route: troxalerts
        annotations:
          summary: 'Error occurred in Target Service (Internal Origin Request) (VM) [ Data Source is UKG Pro ]  '
          description: 'Error occurred in Target Service (Internal Origin Request). Instance name is {{ $labels.instance_name }}, Envoy cluster name is {{ $labels.envoy_cluster_name }}, environment is {{ $labels.env_id }}, project is {{ $labels.project }}, zone is {{ $labels.zone }}, service name is {{ $labels.service_name }}, machine type is {{ $labels.machineType }}, envoy response code is {{ $labels.envoy_response_code }}, stack id is {{ $labels.stack_id }}.  Data Source is UKG Pro  .'
          __dashboardUid__: ae1in6jhkm60wa
          __panelId__: '14'


          
  #UKG Webhooks
  - name: UKG Webhooks prod
    rules:
      - alert: 'Webhooks prod - CPU cunsumption of container is above threshold of 600 milicores.'
        expr: '(sum by(container) (rate(container_cpu_usage_seconds_total{namespace="ukg-webhooks-prod", container!="istio-proxy"}[5m])))*1000 > 600'
        for: 5m
        labels:
          severity: warning
          route: webhooks_prod
        annotations:
          summary: 'Webhooks prod - CPU consumption of container is above threshold of 600 milicores.'
          description: "Webhooks prod - CPU cunsumption per container is above threshold"
          __dashboardUid__: xHa_tY1Io
          __panelId__: '83'

      - alert: 'Webhooks prod - Memory consumption of container is above threshold of 100MB.'
        expr: 'sum by(container) (rate(container_memory_usage_bytes{namespace="$namespace", container!~"ukg-webhooks-consumer-service|istio-proxy"}[1m])) > 100000000'
        for: 5m
        labels:
          severity: warning
          route: webhooks_prod
        annotations:
          summary: 'Webhooks prod - Memory consumption of container is above threshold of 100MB.'
          description: "Webhooks prod - Memory consumption of container is above threshold"
          __dashboardUid__: xHa_tY1Io
          __panelId__: '82'
  - name: MFT (UDES)
    interval: 1m
    rules:
        # CPU monitoring
      - alert: 'MFT(UDES) CPU utilisation [P1] more than 95%'
        expr: '((100 - (irate(windows_cpu_time_total{mode="idle", instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*"}[2m])) * 100) > 95)'
        for: 20m
        labels:
          severity: critical
          route: mft-udes-route-pd
        annotations:
          summary: Query averages CPU limit utilization (in %) over 20 minutes. Evaluation interval - 1m It alerts if the average exceeds 95%
          description: "CPU load is > 95%\n  VALUE = {{ $value }}"
          SOPs: "https://engconf.int.kronos.com/display/COS/UDES+App+Servers+-+High+CPU"
          __dashboardUid__: cdxfk3jlern5sa
          __panelId__: '2'
        # CPU monitoring Webhook
      - alert: 'MFT(UDES) CPU utilisation [P2] more than 85%'
        expr: '((100 - (irate(windows_cpu_time_total{mode="idle", instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*"}[2m])) * 100) > 85)'
        for: 20m
        labels:
          severity: critical
          route: mft-udes-route-webhook
        annotations:
          summary: Query averages CPU limit utilization (in %) over 20 minutes. Evaluation interval - 1m It alerts if the average exceeds 85%
          description: "CPU load is > 85%\n  VALUE = {{ $value }}"
          SOPs: "https://engconf.int.kronos.com/display/COS/UDES+App+Servers+-+High+CPU"
          __dashboardUid__: cdxfk3jlern5sa
          __panelId__: '2'
        # CPU monitoring email
      - alert: 'MFT(UDES) CPU utilisation [P3] more than 75%'
        expr: '((100 - (irate(windows_cpu_time_total{mode="idle", instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*"}[2m])) * 100) > 75)'
        for: 20m
        labels:
          severity: critical
          route: mft-udes-route-email
        annotations:
          summary: Query averages CPU limit utilization (in %) over 20 minutes. Evaluation interval - 1m It alerts if the average exceeds 75%
          description: "CPU load is > 75%\n  VALUE = {{ $value }}"
          SOPs: "https://engconf.int.kronos.com/display/COS/UDES+App+Servers+-+High+CPU"
          __dashboardUid__: cdxfk3jlern5sa
          __panelId__: '2'
        # Disk monitoring Webhook
      - alert: 'MFT(UDES) Disk utilisation more than 80%'
        expr: '((100 - (windows_logical_disk_free_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*", volume=~".:"} /windows_logical_disk_size_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*", volume=~".:"}*100)) > 85)'
        for: 30m
        labels:
          severity: critical
          route: mft-udes-route-webhook
        annotations:
          summary: Query averages Disk utilization (in %) over 30 minutes. Evaluation interval - 1m It alerts if the average exceeds 80%
          description: "Disk utilisation > 85%\n  VALUE = {{ $value }}"
          SOPs: "https://engconf.int.kronos.com/display/COS/UDES+Servers+High+Disk+Space"
          __dashboardUid__: cdxfk3jlern5sa
          __panelId__: '31'
        # Disk monitoring PD
      - alert: 'MFT(UDES) Disk utilisation more than 90%'
        expr: '((100 - (windows_logical_disk_free_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*", volume=~".:"} /windows_logical_disk_size_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*", volume=~".:"}*100)) > 90)'
        for: 30m
        labels:
          severity: critical
          route: mft-udes-route-pd
        annotations:
          summary: Query averages Disk utilization (in %) over 30 minutes. Evaluation interval - 1m It alerts if the average exceeds 90%
          description: "Disk utilisation > 85%\n  VALUE = {{ $value }}"
          SOPs: "https://engconf.int.kronos.com/display/COS/UDES+Servers+High+Disk+Space"
          __dashboardUid__: cdxfk3jlern5sa
          __panelId__: '31'
        # Memory monitoring
      - alert: 'MFT(UDES) Memory utilisation [P1] more than 95% '
        expr: '((100 * (windows_cs_physical_memory_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*"} - windows_os_physical_memory_free_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*"}) / windows_cs_physical_memory_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*"}) > 95)'
        for: 20m
        labels:
          severity: critical
          route: mft-udes-route-pd
        annotations:
          summary: Query averages Memory utilization (in %) over 20 minutes. Evaluation interval - 1m It alerts if the average exceeds 95%
          description: "Memory utilization is > 95%\n  VALUE = {{ $value }}"
          SOPs: "https://engconf.int.kronos.com/display/COS/UDES+App+Servers+-+High+CPU"
          __dashboardUid__: cdxfk3jlern5sa
          __panelId__: '3'
        # Memory monitoring Webhook
      - alert: 'MFT(UDES) Memory utilisation [P2] more than 85% '
        expr: '((100 * (windows_cs_physical_memory_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*"} - windows_os_physical_memory_free_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*"}) / windows_cs_physical_memory_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*"}) > 85)'
        for: 20m
        labels:
          severity: critical
          route: mft-udes-route-webhook
        annotations:
          summary: Query averages Memory utilization (in %) over 20 minutes. Evaluation interval - 1m It alerts if the average exceeds 85%
          description: "Memory utilization is > 85%\n  VALUE = {{ $value }}"
          SOPs: "https://engconf.int.kronos.com/display/COS/UDES+App+Servers+-+High+CPU"
          __dashboardUid__: cdxfk3jlern5sa
          __panelId__: '3'
        # Memory monitoring Email
      - alert: 'MFT(UDES) Memory utilisation [P3] more than 75% '
        expr: '((100 * (windows_cs_physical_memory_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*"} - windows_os_physical_memory_free_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*"}) / windows_cs_physical_memory_bytes{instance=~"(n|e|ew|g03p|t)0ieft(ap|gw).*"}) > 75)'
        for: 20m
        labels:
          severity: critical
          route: mft-udes-route-email
        annotations:
          summary: Query averages Memory utilization (in %) over 20 minutes. Evaluation interval - 1m It alerts if the average exceeds 75%
          description: "Memory utilization is > 75%\n  VALUE = {{ $value }}"
          SOPs: "https://engconf.int.kronos.com/display/COS/UDES+App+Servers+-+High+CPU"
          __dashboardUid__: cdxfk3jlern5sa
          __panelId__: '3'
        # Folder Monitoring Webhook
      - alert: 'MFT(UDES) Folder Monitor Last file created over 15 minutes'
        expr: '(eft_gci_nocfmcreated{instanceEFTcluter=~"(n|e|ew|g03p|t)0ieftap0.*", job="integrations_etf_metrics"} > 20)'
        for: 15m
        labels:
          severity: critical
          route: mft-udes-route-webhook
        annotations:
          summary: Last files generated in data_exchange_USGNOCMonitoring_Archive over 15 minutes
          description: "Last files generated in data_exchange_USGNOCMonitoring_Archive over 15 minutes\n {{ $value }}"
          SOPs: "https://engconf.int.kronos.com/display/COS/UDES+Archived+USGNOCMonitoring+File+Monitor"
          __dashboardUid__: ee0ve19r2eo74c
          __panelId__: '17'
        # SFTP Synthetic upload test Webhook
      - alert: 'MFT(UDES) SFTP upload from Synthetic Last file created over 60 minutes'
        expr: '(eft_gci_sftplastupload{instanceEFTcluter=~"(n|e|ew|g03p|t)0ieftap01", job="integrations_etf_metrics"} > 60)'
        for: 5m
        labels:
          severity: critical
          route: mft-udes-route-webhook
        annotations:
          summary: SFTP upload from Synthetic Last file created over 60 minutes
          description: "SFTP upload from Synthetic Last file created over 60 minutes\n {{ $value }}"
          SOPs: "https://engconf.int.kronos.com/display/COS/UDES+Archived+USGNOCMonitoring+File+Monitor"
          __dashboardUid__: ee0ve19r2eo74c
          __panelId__: '16'
  # Compensation Management Alerting
  - name: Compensation Management Alerts Prod
    rules:
      - alert: (CPU Is Above Thresholf of 80% for Namespace compmgnt-uat)
        expr: '(sum(rate(container_cpu_usage_seconds_total{namespace="compmgnt-uat"}[1m])) / sum(kube_pod_container_resource_requests{namespace="compmgnt-develop", resource="cpu"}) * 100) > 80'
        for: 5m
        labels:
          severity: Critical
          route: comp
        annotations:
          summary: 'High CPU usage in namespace compmgnt-uat'
          description: "CPU usage in the namespace compmgnt-develop is over 80% for the last 5 minutes."
          __dashboardUid__: bdwob49oxf3eoe
      - alert: (CPU Is Above Thresholf of 80% for Namespace compmgnt-prod)
        expr: '(sum(rate(container_cpu_usage_seconds_total{namespace="compmgnt-prod"}[1m])) / sum(kube_pod_container_resource_requests{namespace="compmgnt-psr", resource="cpu"}) * 100) > 80'
        for: 5m
        labels:
          severity: Critical
          route: comp
        annotations:
          summary: 'High CPU usage in namespace compmgnt-prod'
          description: "CPU usage in the namespace compmgnt-psr is over 80% for the last 5 minutes."
          __dashboardUid__: bdwob49oxf3eoe
      - alert: (memory Is Above Thresholf of 80% for Namespace compmgnt-uat)
        expr: '(sum(container_memory_working_set_bytes{namespace="compmgnt-uat"}) / sum(kube_pod_container_resource_requests{namespace="compmgnt-develop", resource="memory"}) * 100) > 80'
        for: 5m
        labels:
          severity: Critical
          route: comp
        annotations:
          summary: 'High Memory usage in namespace compmgnt-uat'
          description: "Memory usage in the namespace compmgnt-uat is over 80% for the last 5 minutes."
          __dashboardUid__: bdwob49oxf3eoe
      - alert: (memory Is Above Thresholf of 80% for Namespace compmgnt-prod)
        expr: '(sum(container_memory_working_set_bytes{namespace="compmgnt-prod"}) / sum(kube_pod_container_resource_requests{namespace="compmgnt-psr", resource="memory"}) * 100) > 80'
        for: 5m
        labels:
          severity: Critical
          route: comp
        annotations:
          summary: 'High Memory usage in namespace compmgnt-prod'
          description: "Memory usage in the namespace compmgnt-psr is over 80% for the last 5 minutes."
          __dashboardUid__: bdwob49oxf3eoe
          # API-Gateway Alerts
  - name: API-Gateway GCP alerts - Prod
    rules:
      - alert: (WARNING) API-Gateway pods Memory Usage
        expr: '(sum by (pod)(container_memory_working_set_bytes{namespace="api-gateway", pod=~".*tyk.*", datacenter="us-east1", container!="istio-proxy"}) / sum by (pod)(kube_pod_container_resource_limits{namespace="api-gateway", pod=~".*tyk.*", container!="istio-proxy", resource="memory", datacenter="us-east1"}) * 100) > 75'
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: '{{ $labels.pod }} memory is more than 75%'
          description: "SOP: https://engconf.int.kronos.com/display/AGT/SOP+for+Memory+Usage+Alert"
          __dashboardUid__: bdxdnrdkc0glce
          __panelId__: '18'

      - alert: (WARNING) API-Gateway pods CPU Usage
        expr: '(sum by (pod)(rate(container_cpu_usage_seconds_total{namespace="api-gateway", pod=~".*tyk.*", datacenter="us-east1", container!="istio-proxy"}[5m])) / sum by (pod)(kube_pod_container_resource_requests{namespace="api-gateway", pod=~".*tyk.*", container!="istio-proxy", resource="cpu", datacenter="us-east1"}) * 100) > 75'
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: '{{ $labels.pod }} CPU is more than 75%'
          description: "SOP: https://engconf.int.kronos.com/display/AGT/SOP+for+CPU+Usage+Alert"
          __dashboardUid__: bdxdnrdkc0glce
          __panelId__: '17'

      - alert: (CRITICAL) API-Gateway pods Memory Usage
        expr: '(sum by (pod)(container_memory_working_set_bytes{namespace="api-gateway", pod=~".*tyk.*", datacenter="us-east1", container!="istio-proxy"}) / sum by (pod)(kube_pod_container_resource_limits{namespace="api-gateway", pod=~".*tyk.*", container!="istio-proxy", resource="memory", datacenter="us-east1"}) * 100) > 85'
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: '{{ $labels.pod }} memory is more than 85%'
          description: "SOP: https://engconf.int.kronos.com/display/AGT/SOP+for+Memory+Usage+Alert"
          __dashboardUid__: bdxdnrdkc0glce
          __panelId__: '18'

      - alert: (CRITICAL) API-Gateway pods CPU Usage
        expr: '(sum by (pod)(rate(container_cpu_usage_seconds_total{namespace="api-gateway", pod=~".*tyk.*", datacenter="us-east1", container!="istio-proxy"}[5m])) / sum by (pod)(kube_pod_container_resource_requests{namespace="api-gateway", pod=~".*tyk.*", container!="istio-proxy", resource="cpu", datacenter="us-east1"}) * 100) > 85'
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: '{{ $labels.pod }} CPU is more than 85%'
          description: "SOP: https://engconf.int.kronos.com/display/AGT/SOP+for+CPU+Usage+Alert"
          __dashboardUid__: bdxdnrdkc0glce
          __panelId__: '17'

      - alert: (CRITICAL) Container restarts on Prod (us-east1)
        expr: 'sum by(pod,container,namespace) (increase(kube_pod_container_status_restarts_total{namespace="api-gateway", container!="istio-proxy", datacenter="us-east1"}[1m])) > 0'
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: 'Container in {{ $labels.pod }} (namespace: {{ $labels.namespace }}) is restarted'
          description: "SOP: https://engconf.int.kronos.com/display/AGT/SOP+for+Container+Restart+Alert"
          __dashboardUid__: bdxdnrdkc0glce
          __panelId__: '14'

      - alert: (WARNING) Container restarts on DR (us-east4)
        expr: 'sum by(pod,container,namespace) (increase(kube_pod_container_status_restarts_total{namespace="api-gateway", container!="istio-proxy", datacenter="us-east4"}[1m])) > 0'
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: 'Container in {{ $labels.pod }} (namespace: {{ $labels.namespace }}) is restarted on us-east4'
          description: "SOP: https://engconf.int.kronos.com/display/AGT/SOP+for+Container+Restart+Alert"
          __dashboardUid__: bdxdnrdkc0glce
          __panelId__: '14'

      - alert: (CRITICAL) TYK Pump POD not running
        expr: 'sum by(pod, phase) (kube_pod_status_phase{datacenter="us-east1", namespace="api-gateway", phase!="Running", pod=~".*tyk-pump.*"}) > 0'
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: '{{ $labels.pod }} not Running, Current state is {{ $labels.phase }}'
          description: "SOP: https://engconf.int.kronos.com/display/AGT/SOP+for+Pod+unavailability+Alert"
          __dashboardUid__: bdxdnrdkc0glce
          __panelId__: '21'

      - alert: (WARNING) Tyk Gateway PODs not running
        expr: 'sum by (pod) (kube_pod_status_phase{datacenter="us-east1", namespace="api-gateway", phase!="Running", pod=~".*tyk-gateway.*"}) >= 1 and sum by (pod) (kube_pod_status_phase{datacenter="us-east1", namespace="api-gateway", phase!="Running", pod=~".*tyk-gateway.*"}) < 2'
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: '{{ $labels.pod }} not in Running State'
          description: "SOP: https://engconf.int.kronos.com/display/AGT/SOP+for+Pod+unavailability+Alert"
          __dashboardUid__: bdxdnrdkc0glce
          __panelId__: '21'

      - alert: (CRITICAL) Tyk Gateway PODs not running
        expr: 'sum by (pod) (kube_pod_status_phase{datacenter="us-east1", namespace="api-gateway", phase!="Running", pod=~".*tyk-gateway.*"}) >= 2 and sum by (pod) (kube_pod_status_phase{datacenter="us-east1", namespace="api-gateway", phase!="Running", pod=~".*tyk-gateway.*"}) < 3'
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: '{{ $labels.pod }} not in Running State'
          description: "SOP: https://engconf.int.kronos.com/display/AGT/SOP+for+Pod+unavailability+Alert"
          __dashboardUid__: bdxdnrdkc0glce
          __panelId__: '21'


      - alert: (CRITICAL) Tyk Gateways all replicas are down
        expr: 'sum (kube_pod_status_phase{datacenter="us-east1", namespace="api-gateway", phase="Running", pod=~".*tyk-gateway.*"}) < 1'
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: 'All Replicas Down for the last 5 mins. Please follow the SOP.'
          description: "SOP: https://engconf.int.kronos.com/display/AGT/SOP+for+Pod+unavailability+Alert"
          __dashboardUid__: bdxdnrdkc0glce
          __panelId__: '21'

  - name: API-Gateway UPC alerts - Prod
    rules:
      - alert: (WARNING) API-Gateway TYK Gateway Memory Usage
        expr: ((max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-t-.*"}[5m])
          -
          max_over_time(node_memory_MemAvailable_bytes{instance=~"^apigateway.*-t-.*"}[5m]))
          /
          max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-t-.*"}[5m])
          * 100) > 75
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: "{{ $labels.instance }} memory is more than 75%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+Tyk+Gateway"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "3"
      - alert: (CRITICAL) API-Gateway TYK Gateway Memory Usage
        expr: ((max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-t-.*"}[5m])
          -
          max_over_time(node_memory_MemAvailable_bytes{instance=~"^apigateway.*-t-.*"}[5m]))
          /
          max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-t-.*"}[5m])
          * 100) > 85
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: "{{ $labels.instance }} memory is more than 85%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+Tyk+Gateway"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "3"
      - alert: (WARNING) API-Gateway TYK Gateway CPU Usage
        expr: (100 - (avg by
          (instance)(rate(node_cpu_seconds_total{instance=~"^apigateway.*-t-.*",
          mode="idle"}[5m])) * 100)) > 75
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: "{{ $labels.instance }} CPU is more than 75%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+CPU+Usage+Ale\
            rt+of+Tyk+Gateway"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "1"
      - alert: (CRITICAL) API-Gateway TYK Gateway CPU Usage
        expr: (100 - (avg by
          (instance)(rate(node_cpu_seconds_total{instance=~"^apigateway.*-t-.*",
          mode="idle"}[5m])) * 100)) > 85
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: "{{ $labels.instance }} CPU is more than 85%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+CPU+Usage+Ale\
            rt+of+Tyk+Gateway"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "1"
      - alert: (WARNING) API-Gateway TYK Gateway Disk Usage
        expr: ((1 - (avg by (instance)
          (node_filesystem_free_bytes{instance=~"^apigateway.*-t-.*"})) / avg by
          (instance) (node_filesystem_size_bytes{instance=~"^apigateway.*-t-.*"}))
          * 100) > 75
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: "{{ $labels.instance }} Disk is more than 75%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+Tyk+Gateway"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "15"
      - alert: (CRITICAL) API-Gateway TYK Gateway Disk Usage
        expr: ((1 - (avg by (instance)
          (node_filesystem_free_bytes{instance=~"^apigateway.*-t-.*"})) / avg by
          (instance) (node_filesystem_size_bytes{instance=~"^apigateway.*-t-.*"}))
          * 100) > 85
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: "{{ $labels.instance }} Disk is more than 85%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+Tyk+Gateway"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "15"
      - alert: (WARNING) API-Gateway Redis Memory Usage
        expr: ((max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-r-.*"}[5m])
          -
          max_over_time(node_memory_MemAvailable_bytes{instance=~"^apigateway.*-r-.*"}[5m]))
          /
          max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-r-.*"}[5m])
          * 100) > 75
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: "{{ $labels.instance }} memory is more than 75%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+Redis"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "4"
      - alert: (CRITICAL) API-Gateway Redis Memory Usage
        expr: ((max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-r-.*"}[5m])
          -
          max_over_time(node_memory_MemAvailable_bytes{instance=~"^apigateway.*-r-.*"}[5m]))
          /
          max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-r-.*"}[5m])
          * 100) > 85
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: "{{ $labels.instance }} memory is more than 85%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+Redis"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "4"
      - alert: (WARNING) API-Gateway Redis CPU Usage
        expr: (100 - (avg by
          (instance)(rate(node_cpu_seconds_total{instance=~"^apigateway.*-r-.*",
          mode="idle"}[5m])) * 100)) > 75
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: "{{ $labels.instance }} CPU is more than 75%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+CPU+Usage+Ale\
            rt+of+Redis"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "8"
      - alert: (CRITICAL) API-Gateway Redis CPU Usage
        expr: (100 - (avg by
          (instance)(rate(node_cpu_seconds_total{instance=~"^apigateway.*-r-.*",
          mode="idle"}[5m])) * 100)) > 85
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: "{{ $labels.instance }} CPU is more than 85%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+CPU+Usage+Ale\
            rt+of+Redis"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "8"
      - alert: (WARNING) API-Gateway Redis Disk Usage
        expr: ((1 - (avg by (instance)
          (node_filesystem_free_bytes{instance=~"^apigateway.*-r-.*"})) / avg by
          (instance) (node_filesystem_size_bytes{instance=~"^apigateway.*-r-.*"}))
          * 100) > 75
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: "{{ $labels.instance }} Disk is more than 75%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+Redis"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "14"
      - alert: (CRITICAL) API-Gateway Redis Disk Usage
        expr: ((1 - (avg by (instance)
          (node_filesystem_free_bytes{instance=~"^apigateway.*-r-.*"})) / avg by
          (instance) (node_filesystem_size_bytes{instance=~"^apigateway.*-r-.*"}))
          * 100) > 85
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: "{{ $labels.instance }} Disk is more than 85%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+Redis"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "14"
      - alert: (WARNING) API-Gateway Ha-Proxy Memory Usage
        expr: ((max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-ha-.*"}[5m])
          -
          max_over_time(node_memory_MemAvailable_bytes{instance=~"^apigateway.*-ha-.*"}[5m]))
          /
          max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-ha-.*"}[5m])
          * 100) > 75
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: "{{ $labels.instance }} memory is more than 75%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+HA+Proxy"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "6"
      - alert: (CRITICAL) API-Gateway Ha-Proxy Memory Usage
        expr: ((max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-ha-.*"}[5m])
          -
          max_over_time(node_memory_MemAvailable_bytes{instance=~"^apigateway.*-ha-.*"}[5m]))
          /
          max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-ha-.*"}[5m])
          * 100) > 85
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: "{{ $labels.instance }} memory is more than 85%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+HA+Proxy"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "6"
      - alert: (WARNING) API-Gateway Ha-Proxy CPU Usage
        expr: (100 - (avg by
          (instance)(rate(node_cpu_seconds_total{instance=~"^apigateway.*-ha-.*",
          mode="idle"}[5m])) * 100)) > 75
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: "{{ $labels.instance }} CPU is more than 75%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+CPU+Usage+Ale\
            rt+of+HA+Proxy"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "2"
      - alert: (CRITICAL) API-Gateway Ha-Proxy CPU Usage
        expr: (100 - (avg by
          (instance)(rate(node_cpu_seconds_total{instance=~"^apigateway.*-ha-.*",
          mode="idle"}[5m])) * 100)) > 85
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: "{{ $labels.instance }} CPU is more than 85%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+CPU+Usage+Ale\
            rt+of+HA+Proxy"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "2"
      - alert: (WARNING) API-Gateway Ha-Proxy Disk Usage
        expr: ((1 - (avg by (instance)
          (node_filesystem_free_bytes{instance=~"^apigateway.*-ha-.*"})) / avg by
          (instance)
          (node_filesystem_size_bytes{instance=~"^apigateway.*-ha-.*"})) * 100) > 75
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: "{{ $labels.instance }} Disk is more than 75%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+HA+Proxy"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "13"
      - alert: (CRITICAL) API-Gateway Ha-Proxy Disk Usage
        expr: ((1 - (avg by (instance)
          (node_filesystem_free_bytes{instance=~"^apigateway.*-ha-.*"})) / avg by
          (instance)
          (node_filesystem_size_bytes{instance=~"^apigateway.*-ha-.*"})) * 100) > 85
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: "{{ $labels.instance }} Disk is more than 85%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+HA+Proxy"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "13"
      - alert: (WARNING) API-Gateway Pump Memory Usage
        expr: ((max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-p-.*"}[5m])
          -
          max_over_time(node_memory_MemAvailable_bytes{instance=~"^apigateway.*-p-.*"}[5m]))
          /
          max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-p-.*"}[5m])
          * 100) > 75
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: "{{ $labels.instance }} memory is more than 75%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+Tyk+Pump"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "5"
      - alert: (CRITICAL) API-Gateway Pump Memory Usage
        expr: ((max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-p-.*"}[5m])
          -
          max_over_time(node_memory_MemAvailable_bytes{instance=~"^apigateway.*-p-.*"}[5m]))
          /
          max_over_time(node_memory_MemTotal_bytes{instance=~"^apigateway.*-p-.*"}[5m])
          * 100) > 85
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: "{{ $labels.instance }} memory is more than 85%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+Tyk+Pump"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "5"
      - alert: (WARNING) API-Gateway Pump CPU Usage
        expr: (100 - (avg by
          (instance)(rate(node_cpu_seconds_total{instance=~"^apigateway.*-p-.*",
          mode="idle"}[5m])) * 100)) > 75
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: "{{ $labels.instance }} CPU is more than 75%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+CPU+Usage+Ale\
            rt+of+Tyk+Pump"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "7"
      - alert: (CRITICAL) API-Gateway Pump CPU Usage
        expr: (100 - (avg by
          (instance)(rate(node_cpu_seconds_total{instance=~"^apigateway.*-p-.*",
          mode="idle"}[5m])) * 100)) > 85
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: "{{ $labels.instance }} CPU is more than 85%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+CPU+Usage+Ale\
            rt+of+Tyk+Pump"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "7"
      - alert: (WARNING) API-Gateway Pump Disk Usage
        expr: ((1 - (avg by (instance)
          (node_filesystem_free_bytes{instance=~"^apigateway.*-p-.*"})) / avg by
          (instance) (node_filesystem_size_bytes{instance=~"^apigateway.*-p-.*"}))
          * 100) > 75
        for: 5m
        labels:
          severity: warning
          route: apigateway_gcp_prod_mail
        annotations:
          summary: "{{ $labels.instance }} Disk is more than 75%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+Tyk+Pump"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "12"
      - alert: (CRITICAL) API-Gateway Pump Disk Usage
        expr: ((1 - (avg by (instance)
          (node_filesystem_free_bytes{instance=~"^apigateway.*-p-.*"})) / avg by
          (instance) (node_filesystem_size_bytes{instance=~"^apigateway.*-p-.*"}))
          * 100) > 85
        for: 5m
        labels:
          severity: critical
          route: apigateway_gcp_prod_pd
        annotations:
          summary: "{{ $labels.instance }} Disk is more than 85%"
          description: "SOP:
            https://engconf.int.kronos.com/display/AGT/SOP+for+High+Memory+Usage+\
            Alert+of+Tyk+Pump"
          __dashboardUid__: cdyvl31mmgydca
          __panelId__: "12"
  # Pro-TMS Infra Alerts
  - name: Pro-TMS Infra Alerts - PROD
    rules:
      - alert: (CRITICAL) PTMS - CPU Usage
        expr: ((sum by (datacenter, pod, container)(rate(container_cpu_usage_seconds_total{datacenter=~"atl|plas1|tor|us-east1|us-east4", namespace="tms", container!~"nginx|istio-proxy"}[5m]))) / sum by (datacenter, pod, container)(kube_pod_container_resource_requests{datacenter=~"atl|plas1|tor|us-east1|us-east4", namespace="tms", container!~"nginx|istio-proxy", resource="cpu"}) * 100) >= 80
        for: 30m
        labels:
          severity: critical
          route: pro_tms_pagerduty
        annotations:
          summary: "CPU usage is more than 80% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "CPU usage is more than 80% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}"
          SOP: https://engconf.int.kronos.com/display/FT/SOP+-+For+High+CPU+Usage+Observed
          __dashboardUid__: ee0jj6gc367swb
          __panelId__: "1"
      - alert: (WARNING) PTMS - CPU Usage
        expr: ((sum by (datacenter, pod, container)(rate(container_cpu_usage_seconds_total{datacenter=~"atl|plas1|tor|us-east1|us-east4", namespace="tms", container!~"nginx|istio-proxy"}[5m]))) / sum by (datacenter, pod, container)(kube_pod_container_resource_requests{datacenter=~"atl|plas1|tor|us-east1|us-east4", namespace="tms", container!~"nginx|istio-proxy", resource="cpu"}) * 100) >= 70
        for: 30m
        labels:
          severity: warning
          route: pro_tms_mail
        annotations:
          summary: "CPU usage is more than 70% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "CPU usage is more than 70% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}"
          SOP: https://engconf.int.kronos.com/display/FT/SOP+-+For+High+CPU+Usage+Observed
          __dashboardUid__: ee0jj6gc367swb
          __panelId__: "1"
      - alert: (CRITICAL) PTMS - Memory Usage
        expr: ((sum by (datacenter, pod, container)(container_memory_working_set_bytes{datacenter=~"atl|plas1|tor|us-east1|us-east4", namespace="tms", container!~"nginx|istio-proxy"})) / sum by (datacenter, pod, container)(kube_pod_container_resource_limits{datacenter=~"atl|plas1|tor|us-east1|us-east4", namespace="tms", container!~"nginx|istio-proxy", resource="memory"}) * 100) >= 80
        for: 30m
        labels:
          severity: critical
          route: pro_tms_pagerduty
        annotations:
          summary: "Memory usage is more than 80% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "Memory usage is more than 80% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}"
          SOP:
          __dashboardUid__: ee0jj6gc367swb
          __panelId__: "2"
      - alert: (WARNING) PTMS - Memory Usage
        expr: ((sum by (datacenter, pod, container)(container_memory_working_set_bytes{datacenter=~"atl|plas1|tor|us-east1|us-east4", namespace="tms", container!~"nginx|istio-proxy"})) / sum by (datacenter, pod, container)(kube_pod_container_resource_limits{datacenter=~"atl|plas1|tor|us-east1|us-east4", namespace="tms", container!~"nginx|istio-proxy", resource="memory"}) * 100) >= 70
        for: 30m
        labels:
          severity: warning
          route: pro_tms_mail
        annotations:
          summary: "Memory usage is more than 70% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "Memory usage is more than 70% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}"
          SOP:
          __dashboardUid__: ee0jj6gc367swb
          __panelId__: "2"
      - alert: (CRITICAL) PTMS - Pod Replica Unavailability
        expr: ((sum by(deployment, datacenter) (kube_deployment_spec_replicas{namespace="tms", datacenter=~"atl|plas1|tor|us-east1|us-east4"})) - (sum by (deployment, datacenter)(kube_deployment_status_replicas_available{namespace="tms", datacenter=~"atl|plas1|tor|us-east1|us-east4"}))) > 0
        for: 30m
        labels:
          severity: critical
          route: pro_tms_pagerduty
        annotations:
          summary: "Pod Replica is less than expected for {{ $labels.deployment }} in {{ $labels.datacenter }}"
          description: "Pod Replica is less than expected for Deployment: {{ $labels.deployment }}, Datacenter: {{ $labels.datacenter }}"
          SOP: https://engconf.int.kronos.com/display/PSRE/Replica+Unavailability
          __dashboardUid__: ee0jj6gc367swb
          __panelId__: "6"
      - alert: (CRITICAL) PTMS - Pod Container Restarts
        expr: (sum by (pod, container, datacenter)(increase(kube_pod_container_status_restarts_total{namespace="tms", container!="istio-proxy", datacenter=~"atl|plas1|tor|us-east1|us-east4"}[1m]))) > 2
        for: 30m
        labels:
          severity: critical
          route: pro_tms_pagerduty
        annotations:
          summary: "Pod Container has been restarted more than twice for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "Pod Container has been restarted more than twice for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}"
          SOP: https://engconf.int.kronos.com/display/PSRE/Container+Restarts
          __dashboardUid__: ee0jj6gc367swb
          __panelId__: "4"
  # UTP Infra Alerts
  - name: UTP Infra Alerts - PROD and CFN
    rules:
      - alert: (CRITICAL) UTP - CPU Usage
        expr: ((sum by (datacenter, pod, container, namespace)(rate(container_cpu_usage_seconds_total{datacenter=~"us-east1|us-east4|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"tenancy-prod-us|tenancy-cfn|tenancy-prod-ca|tenancy-prod-eu|tenancy-prod-aus", container!~"nginx|istio-proxy", container=~"utp.*"}[5m]))) / sum by (datacenter, pod, container, namespace)(kube_pod_container_resource_requests{datacenter=~"us-east1|us-east4|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"tenancy-prod-us|tenancy-cfn|tenancy-prod-ca|tenancy-prod-eu|tenancy-prod-aus", container!~"nginx|istio-proxy", resource="cpu", container=~"utp.*"}) * 100) >= 80
        for: 15m
        labels:
          severity: critical
          route: utp_pagerduty
        annotations:
          summary: "CPU usage is more than 80% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "CPU usage is more than 80% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          SOP: https://engconf.int.kronos.com/display/UTP/K8s-CPU+Usage+Alert+SOP
      - alert: (WARNING) UTP - CPU Usage
        expr: ((sum by (datacenter, pod, container, namespace)(rate(container_cpu_usage_seconds_total{datacenter=~"us-east1|us-east4|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"tenancy-prod-us|tenancy-cfn|tenancy-prod-ca|tenancy-prod-eu|tenancy-prod-aus", container!~"nginx|istio-proxy", container=~"utp.*"}[5m]))) / sum by (datacenter, pod, container, namespace)(kube_pod_container_resource_requests{datacenter=~"us-east1|us-east4|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"tenancy-prod-us|tenancy-cfn|tenancy-prod-ca|tenancy-prod-eu|tenancy-prod-aus", container!~"nginx|istio-proxy", resource="cpu", container=~"utp.*"}) * 100) >= 70
        for: 5m
        labels:
          severity: warning
          route: utp_mail
        annotations:
          summary: "CPU usage is more than 70% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "CPU usage is more than 70% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          SOP: https://engconf.int.kronos.com/display/UTP/K8s-CPU+Usage+Alert+SOP
      - alert: (CRITICAL) UTP - Memory Usage
        expr: ((sum by (datacenter, pod, container, namespace)(container_memory_working_set_bytes{datacenter=~"us-east1|us-east4|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"tenancy-prod-us|tenancy-cfn|tenancy-prod-ca|tenancy-prod-eu|tenancy-prod-aus", container!~"nginx|istio-proxy", container=~"utp.*"})) / sum by (datacenter, pod, container, namespace)(kube_pod_container_resource_limits{datacenter=~"us-east1|us-east4|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"tenancy-prod-us|tenancy-cfn|tenancy-prod-ca|tenancy-prod-eu|tenancy-prod-aus", container!~"nginx|istio-proxy", resource="memory", container=~"utp.*"}) * 100) >= 80
        for: 15m
        labels:
          severity: critical
          route: utp_pagerduty
        annotations:
          summary: "Memory usage is more than 80% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "Memory usage is more than 80% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          SOP: https://engconf.int.kronos.com/display/UTP/K8s-Memory+Usage+Alert+SOP
      - alert: (WARNING) UTP - Memory Usage
        expr: ((sum by (datacenter, pod, container, namespace)(container_memory_working_set_bytes{datacenter=~"us-east1|us-east4|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"tenancy-prod-us|tenancy-cfn|tenancy-prod-ca|tenancy-prod-eu|tenancy-prod-aus", container!~"nginx|istio-proxy", container=~"utp.*"})) / sum by (datacenter, pod, container, namespace)(kube_pod_container_resource_limits{datacenter=~"us-east1|us-east4|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"tenancy-prod-us|tenancy-cfn|tenancy-prod-ca|tenancy-prod-eu|tenancy-prod-aus", container!~"nginx|istio-proxy", resource="memory", container=~"utp.*"}) * 100) >= 70
        for: 15m
        labels:
          severity: warning
          route: utp_mail
        annotations:
          summary: "Memory usage is more than 70% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "Memory usage is more than 70% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          SOP: https://engconf.int.kronos.com/display/UTP/K8s-Memory+Usage+Alert+SOP
      - alert: (CRITICAL) UTP - Pod Replica Unavailability
        expr: ((sum by(deployment, datacenter, namespace) (kube_deployment_spec_replicas{namespace=~"tenancy-prod-us|tenancy-cfn|tenancy-prod-ca|tenancy-prod-eu|tenancy-prod-aus", datacenter=~"us-east1|us-east4|northamerica-northeast1|europe-west4|australia-southeast1", deployment=~"utp.*"})) - (sum by (deployment, datacenter, namespace)(kube_deployment_status_replicas_available{namespace=~"tenancy-prod-us|tenancy-cfn|tenancy-prod-ca|tenancy-prod-eu|tenancy-prod-aus", datacenter=~"us-east1|us-east4|northamerica-northeast1|europe-west4|australia-southeast1", deployment=~"utp.*"}))) > 0
        for: 15m
        labels:
          severity: critical
          route: utp_pagerduty
        annotations:
          summary: "Pod Replica is less than expected for {{ $labels.deployment }} in {{ $labels.datacenter }}"
          description: "Pod Replica is less than expected for Deployment: {{ $labels.deployment }}, Datacenter: {{ $labels.datacenter }}, Namespace: {{ $labels.namespace }}"
          SOP: https://engconf.int.kronos.com/display/PSRE/Replica+Unavailability
      - alert: (CRITICAL) UTP - Pod Container Restarts
        expr: (sum by (pod, container, datacenter, namespace)(increase(kube_pod_container_status_restarts_total{namespace=~"tenancy-prod-us|tenancy-cfn|tenancy-prod-ca|tenancy-prod-eu|tenancy-prod-aus", container!~"nginx|istio-proxy", datacenter=~"us-east1|us-east4|northamerica-northeast1|europe-west4|australia-southeast1", container=~"utp.*"}[1m]))) > 2
        for: 15m
        labels:
          severity: critical
          route: utp_pagerduty
        annotations:
          summary: "Pod Container has been restarted more than twice for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "Pod Container has been restarted more than twice for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          SOP: https://engconf.int.kronos.com/pages/viewpage.action?spaceKey=PSRE&title=Container+Restarts
  - name: UTP Application Alerts - PROD and CFN
    rules:
      - alert: (P1-CRITICAL) UTP - High Request Latency
        expr: (sum by (status, method, uri, datacenter, environment)(rate(http_server_requests_seconds_sum{service="utp-service", datacenter="us-east1", environment=~"prod|cfn", uri!="/health", status!~"5.."}[5m])) / sum by (status, method, uri, datacenter, environment)(rate(http_server_requests_seconds_count{service="utp-service", datacenter="us-east1", environment=~"prod|cfn", uri!="/health", status!~"5.."}[5m]))) > 0.6
        for: 15m
        labels:
          severity: critical
          route: utp_mail
        annotations:
          summary: "Detected High Request Latency for UTP Service in {{ $labels.datacenter }} Datacenter for {{ $labels.environment }} Environment"
          description: "Detected High Request Latency for UTP Service. DATACENTER: {{ $labels.datacenter }}, ENVIRONMENT: {{ $labels.environment }}, URI: {{ $labels.uri }}, METHOD: {{ $labels.method }}, STATUS: {{ $labels.status }}"
          __dashboardUid__: "ee1izor733fggf"
          __panelId__: "13"
      - alert: (P2-CRITICAL) UTP - High Request Latency
        expr: (sum by (status, method, uri, datacenter, environment)(rate(http_server_requests_seconds_sum{service="utp-service", datacenter="us-east1", environment=~"prod|cfn", uri!="/health", status!~"5.."}[5m])) / sum by (status, method, uri, datacenter, environment)(rate(http_server_requests_seconds_count{service="utp-service", datacenter="us-east1", environment=~"prod|cfn", uri!="/health", status!~"5.."}[5m]))) > 0.4
        for: 15m
        labels:
          severity: critical
          route: utp_mail
        annotations:
          summary: "Detected High Request Latency for UTP Service in {{ $labels.datacenter }} Datacenter for {{ $labels.environment }} Environment"
          description: "Detected High Request Latency for UTP Service. DATACENTER: {{ $labels.datacenter }}, ENVIRONMENT: {{ $labels.environment }}, URI: {{ $labels.uri }}, METHOD: {{ $labels.method }}, STATUS: {{ $labels.status }}"
          __dashboardUid__: "ee1izor733fggf"
          __panelId__: "13"
      - alert: (P2-CRITICAL) UTP - Service Uptime
        expr: (sum by (datacenter, environment)(process_uptime_seconds{service="utp-service", datacenter="us-east1", environment=~"prod|cfn"})) < 600
        for: 15m
        labels:
          severity: critical
          route: utp_mail
        annotations:
          summary: "UTP Service Uptime is less than 10 mins in {{ $labels.datacenter }} Datacenter for {{ $labels.environment }} Environment"
          description: "UTP Service Uptime is less than 10 mins in {{ $labels.datacenter }} Datacenter for {{ $labels.environment }} Environment. Please check if service was restarted recently."
          __dashboardUid__: "ee1izor733fggf"
          __panelId__: "12"
      - alert: (P2-CRITICAL) UTP - API Request Failure
        expr: (sum by (status, method, uri, datacenter, environment, exception)(increase(http_server_requests_seconds_count{service="utp-service", datacenter="us-east1", environment=~"prod|cfn", uri!="/health", status=~"4..|5.."}[1m:]))) > 0
        for: 15m
        labels:
          severity: critical
          route: utp_mail
        annotations:
          summary: "API Request failed for UTP Service in {{ $labels.datacenter }} Datacenter for {{ $labels.environment }} Environment"
          description: "API Request failed for UTP Service. DATACENTER: {{ $labels.datacenter }}, ENVIRONMENT: {{ $labels.environment }}, URI: {{ $labels.uri }}, METHOD: {{ $labels.method }}, STATUS: {{ $labels.status }}, EXCEPTION: {{ $labels.exception }}"
          __dashboardUid__: "ee1izor733fggf"
          __panelId__: "16"
  - name: Flex Flow Infra Alerts - PROD
    rules:
      - alert: (CRITICAL) Flex Flow - CPU Usage
        expr: ((sum by (datacenter, pod, container, namespace)(rate(container_cpu_usage_seconds_total{datacenter=~"us-east1", namespace=~"flex-flow-prd", container!~"nginx|istio-proxy", container=~"flex-flow.*"}[5m]))) / sum by (datacenter, pod, container, namespace)(kube_pod_container_resource_requests{datacenter=~"us-east1", namespace=~"flex-flow-prd", container!~"nginx|istio-proxy", resource="cpu", container=~"flex-flow.*"}) * 100) >= 80
        for: 5m
        labels:
          severity: critical
          route: flex_flow_prod_route
        annotations:
          summary: "CPU usage is more than 80% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "CPU usage is more than 80% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          SOP: https://engconf.int.kronos.com/display/FLXF/Flex+Flow+%3A+SOP
      - alert: (WARNING) Flex Flow - CPU Usage
        expr: ((sum by (datacenter, pod, container, namespace)(rate(container_cpu_usage_seconds_total{datacenter=~"us-east1", namespace=~"flex-flow-prd", container!~"nginx|istio-proxy", container=~"flex-flow.*"}[5m]))) / sum by (datacenter, pod, container, namespace)(kube_pod_container_resource_requests{datacenter=~"us-east1", namespace=~"flex-flow-prd", container!~"nginx|istio-proxy", resource="cpu", container=~"flex-flow.*"}) * 100) >= 60
        for: 5m
        labels:
          severity: warning
          route: flex_flow_dev_route
        annotations:
          summary: "CPU usage is more than 60% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "CPU usage is more than 60% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          SOP: https://engconf.int.kronos.com/display/FLXF/Flex+Flow+%3A+SOP
      - alert: (CRITICAL) Flex Flow - Memory Usage
        expr: ((sum by (datacenter, pod, container, namespace)(container_memory_working_set_bytes{datacenter=~"us-east1", namespace=~"flex-flow-prd", container!~"nginx|istio-proxy", container=~"flex-flow.*"})) / sum by (datacenter, pod, container, namespace)(kube_pod_container_resource_limits{datacenter=~"us-east1", namespace=~"flex-flow-prd", container!~"nginx|istio-proxy", resource="memory", container=~"flex-flow.*"}) * 100) >= 80
        for: 5m
        labels:
          severity: critical
          route: flex_flow_prod_route
        annotations:
          summary: "Memory usage is more than 80% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "Memory usage is more than 80% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          SOP: https://engconf.int.kronos.com/display/FLXF/Flex+Flow+%3A+SOP
      - alert: (WARNING) Flex Flow - Memory Usage
        expr: ((sum by (datacenter, pod, container, namespace)(container_memory_working_set_bytes{datacenter=~"us-east1", namespace=~"flex-flow-prd", container!~"nginx|istio-proxy", container=~"flex-flow.*"})) / sum by (datacenter, pod, container, namespace)(kube_pod_container_resource_limits{datacenter=~"us-east1", namespace=~"flex-flow-prd", container!~"nginx|istio-proxy", resource="memory", container=~"flex-flow.*"}) * 100) >= 50
        for: 5m
        labels:
          severity: warning
          route: flex_flow_dev_route
        annotations:
          summary: "Memory usage is more than 50% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "Memory usage is more than 50% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          SOP: https://engconf.int.kronos.com/display/FLXF/Flex+Flow+%3A+SOP
      - alert: (CRITICAL) Flex Flow - Pod Replica Unavailability
        expr: ((sum by(deployment, datacenter, namespace) (kube_deployment_spec_replicas{namespace=~"flex-flow-prd", datacenter=~"us-east1", deployment=~"flex-flow.*"})) - (sum by (deployment, datacenter, namespace)(kube_deployment_status_replicas_available{namespace=~"flex-flow-prd", datacenter=~"us-east1", deployment=~"flex-flow.*"}))) > 0
        for: 5m
        labels:
          severity: critical
          route: flex_flow_prod_route
        annotations:
          summary: "Pod Replica is less than expected for {{ $labels.deployment }} in {{ $labels.datacenter }}"
          description: "Pod Replica is less than expected for Deployment: {{ $labels.deployment }}, Datacenter: {{ $labels.datacenter }}, Namespace: {{ $labels.namespace }}"
          SOP: https://engconf.int.kronos.com/display/FLXF/Flex+Flow+%3A+SOP
      - alert: (CRITICAL) Flex Flow - Pod Container Restarts
        expr: (sum by (pod, container, datacenter, namespace)(increase(kube_pod_container_status_restarts_total{namespace=~"flex-flow-prd", container!~"nginx|istio-proxy", datacenter=~"us-east1", container=~"flex-flow.*"}[1m]))) > 2
        for: 5m
        labels:
          severity: critical
          route: flex_flow_prod_route
        annotations:
          summary: "Pod Container has been restarted more than twice for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "Pod Container has been restarted more than twice for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          SOP: https://engconf.int.kronos.com/pages/viewpage.action?spaceKey=PSRE&title=Container+Restarts
  - name: HRSD Looker Alert
    rules:
      - alert: HighHTTPStatusCode
        expr: avg_over_time(probe_http_status_code{job=~"integrations/blackbox/looker.*"}[5m]) > 200
        for: 5m
        labels:
          severity: critical
          route: AlertHrsdSreEmail
        annotations:
          summary: "High HTTP Status Code detected for {{ $labels.job }}"
          description: "The average HTTP status code for job {{ $labels.job }} over the past 5 minutes is greater than 200."
          grafana_url: https://ukg.grafana.net/d/fe15244yc76dca/hrsd-looker?from=now-5m&to=now&timezone=browser&editPanel=7&viewPanel=panel-7
  # pro people p2 Alerting for IS 
  - name: Pro people P2 alert for Integration Server
    rules:
      - alert: (CPU Is Above Threshold of 75% for Integration server )
        expr: '(100 - (avg by (instance) (irate(windows_cpu_time_total{mode="idle", instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(is)[0-9]{2}$"}[5m])) * 100)) > 75'
        for: 20m
        labels:
          severity: Warning
          route: pro_people
        annotations:
          summary: 'High CPU usage'
          description: "CPU usage is over 75% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
      - alert: (Memory Is Above Threshold of 75% for Integration Server )
        expr: 'avg_over_time(((windows_cs_physical_memory_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(is)[0-9]{2}$"} - windows_os_physical_memory_free_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(is)[0-9]{2}$"}) / windows_cs_physical_memory_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(is)[0-9]{2}$"} * 100) [20m:1m]) > 75'
        for: 20m
        labels:
          severity: Warning
          route: pro_people
        annotations:
          summary: 'High Memory usage'
          description: "Memory usage is over 75% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
      - alert: (Disk Is Above Threshold of 75% for Integration Server )
        expr: |
          avg_over_time(
            max by (instance, volume) (
              (1 - (
                windows_logical_disk_free_bytes{volume!~"HarddiskVolume.*", job=~"integrations/windows_exporter", instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(is)[0-9]{2}$"}
                / windows_logical_disk_size_bytes{volume!~"HarddiskVolume.*", job=~"integrations/windows_exporter", instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(is)[0-9]{2}$"}
              )) * 100
            )[20m:]
          ) > 75
        for: 20m
        labels:
          severity: Warning
          route: pro_people
        annotations:
          summary: 'High Disk usage on {{ $labels.volume }}'
          description: "Disk usage for {{ $labels.volume }} on instance {{ $labels.instance }} is over 75% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
  # pro people p1 Alerting for IS 
  - name: Pro people P1 alert for Integration Server
    rules:
      - alert: (CPU Is Above Thresholf of 85% for Integration Server )
        expr: '(100 - (avg by (instance) (irate(windows_cpu_time_total{mode="idle", instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(is)[0-9]{2}$"}[5m])) * 100)) > 85'
        for: 20m
        labels:
          severity: Critical
          route: pro_people_p1
        annotations:
          summary: 'High CPU usage'
          description: "CPU usage is over 85% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
      - alert: (Memory Is Above Threshold of 85% for Integration Server )
        expr: 'avg_over_time(((windows_cs_physical_memory_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(is)[0-9]{2}$"} - windows_os_physical_memory_free_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(is)[0-9]{2}$"}) / windows_cs_physical_memory_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(is)[0-9]{2}$"} * 100) [20m:1m]) > 85'
        for: 20m
        labels:
          severity: Critical
          route: pro_people_p1
        annotations:
          summary: 'High Memory usage'
          description: "Memory usage is over 85% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
      - alert: (Disk Is Above Threshold of 85% for integration Server )
        expr: |
          avg_over_time(
            max by (instance, volume) (
              (1 - (
                windows_logical_disk_free_bytes{volume!~"HarddiskVolume.*", job=~"integrations/windows_exporter", instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(is)[0-9]{2}$"}
                / windows_logical_disk_size_bytes{volume!~"HarddiskVolume.*", job=~"integrations/windows_exporter", instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(is)[0-9]{2}$"}
              )) * 100
            )[20m:]
          ) > 85
        for: 20m
        labels:
          severity: Critical
          route: pro_people_p1
        annotations:
          summary: 'High Disk usage on {{ $labels.volume }}'
          description: "Disk usage for {{ $labels.volume }} on instance {{ $labels.instance }} is over 85% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
    # pro people HCM Service Alerting for IS 
  - name: Pro people HCM Service alert for Integration Server
    rules:
      - alert: (CPU Is Above Threshold of 90% for Integration Server )
        expr: '(100 - (avg by (instance) (irate(windows_cpu_time_total{mode="idle", instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(is)[0-9]{2}$"}[5m])) * 100)) > 90'
        for: 20m
        labels:
          severity: Critical
          route: pro_people_hcmservice
        annotations:
          summary: 'High CPU usage'
          description: "CPU usage is over 90% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
      - alert: (Memory Is Above Threshold of 90% for Integration Server )
        expr: 'avg_over_time(((windows_cs_physical_memory_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(is)[0-9]{2}$"} - windows_os_physical_memory_free_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(is)[0-9]{2}$"}) / windows_cs_physical_memory_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(is)[0-9]{2}$"} * 100) [20m:1m]) > 90'
        for: 20m
        labels:
          severity: Critical
          route: pro_people_hcmservice
        annotations:
          summary: 'High Memory usage'
          description: "Memory usage is over 90% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
      - alert: (Disk Is Above Threshold of 90% for integration Server )
        expr: |
          avg_over_time(
            max by (instance, volume) (
              (1 - (
                windows_logical_disk_free_bytes{volume!~"HarddiskVolume.*", job=~"integrations/windows_exporter", instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(is)[0-9]{2}$"}
                / windows_logical_disk_size_bytes{volume!~"HarddiskVolume.*", job=~"integrations/windows_exporter", instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(is)[0-9]{2}$"}
              )) * 100
            )[20m:]
          ) > 90
        for: 20m
        labels:
          severity: Critical
          route: pro_people_hcmservice
        annotations:
          summary: 'High Disk usage on {{ $labels.volume }}'
          description: "Disk usage for {{ $labels.volume }} on instance {{ $labels.instance }} is over 90% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
  # pro people p2 Alerting
  - name: Pro people P2 alert
    rules:
      - alert: (CPU Is Above Threshold of 75% for Auth server )
        expr: '(100 - (avg by (instance) (irate(windows_cpu_time_total{mode="idle", instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(as)[0-9]{2}$"}[5m])) * 100)) > 75'
        for: 20m
        labels:
          severity: Warning
          route: pro_people
        annotations:
          summary: 'High CPU usage'
          description: "CPU usage is over 75% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
      - alert: (Memory Is Above Threshold of 75% for Auth Server )
        expr: 'avg_over_time(((windows_cs_physical_memory_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(as)[0-9]{2}$"} - windows_os_physical_memory_free_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(as)[0-9]{2}$"}) / windows_cs_physical_memory_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(as)[0-9]{2}$"} * 100) [20m:1m]) > 75'
        for: 20m
        labels:
          severity: Warning
          route: pro_people
        annotations:
          summary: 'High Memory usage'
          description: "Memory usage is over 75% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
      - alert: (Disk Is Above Threshold of 75% for Auth Server )
        expr: |
          avg_over_time(
            max by (instance, volume) (
              (1 - (
                windows_logical_disk_free_bytes{volume!~"HarddiskVolume.*", job=~"integrations/windows_exporter", instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(as)[0-9]{2}$"}
                / windows_logical_disk_size_bytes{volume!~"HarddiskVolume.*", job=~"integrations/windows_exporter", instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(as)[0-9]{2}$"}
              )) * 100
            )[20m:]
          ) > 75
        for: 20m
        labels:
          severity: Warning
          route: pro_people
        annotations:
          summary: 'High Disk usage on {{ $labels.volume }}'
          description: "Disk usage for {{ $labels.volume }} on instance {{ $labels.instance }} is over 75% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
  # pro people p1 Alerting
  - name: Pro people P1 alert
    rules:
      - alert: (CPU Is Above Thresholf of 85% for auth Server )
        expr: '(100 - (avg by (instance) (irate(windows_cpu_time_total{mode="idle", instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(as)[0-9]{2}$"}[5m])) * 100)) > 85'
        for: 20m
        labels:
          severity: Critical
          route: pro_people_p1
        annotations:
          summary: 'High CPU usage'
          description: "CPU usage is over 85% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
      - alert: (Memory Is Above Threshold of 85% for Auth Server )
        expr: 'avg_over_time(((windows_cs_physical_memory_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(as)[0-9]{2}$"} - windows_os_physical_memory_free_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(as)[0-9]{2}$"}) / windows_cs_physical_memory_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(as)[0-9]{2}$"} * 100) [20m:1m]) > 85'
        for: 20m
        labels:
          severity: Critical
          route: pro_people_p1
        annotations:
          summary: 'High Memory usage'
          description: "Memory usage is over 85% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
      - alert: (Disk Is Above Threshold of 85% for Auth Server )
        expr: |
          avg_over_time(
            max by (instance, volume) (
              (1 - (
                windows_logical_disk_free_bytes{volume!~"HarddiskVolume.*", job=~"integrations/windows_exporter", instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(as)[0-9]{2}$"}
                / windows_logical_disk_size_bytes{volume!~"HarddiskVolume.*", job=~"integrations/windows_exporter", instance=~"(?i)^(e[0-4]|ew[0-4]|ez[0-4]|n[0-4]|nw[0-4]|nz[0-4]|t[0-4]|tw[0-4]|tz[0-4]|g03).*(as)[0-9]{2}$"}
              )) * 100
            )[20m:]
          ) > 85
        for: 20m
        labels:
          severity: Critical
          route: pro_people_p1
        annotations:
          summary: 'High Disk usage on {{ $labels.volume }}'
          description: "Disk usage for {{ $labels.volume }} on instance {{ $labels.instance }} is over 85% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
   # pro people HCM Service Alerting
  - name: Pro people HCM Service alert
    rules:
      - alert: (CPU Is Above Threshold of 90% for auth Server )
        expr: '(100 - (avg by (instance) (irate(windows_cpu_time_total{mode="idle", instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(as)[0-9]{2}$"}[5m])) * 100)) > 90'
        for: 20m
        labels:
          severity: Critical
          route: pro_people_hcmservice
        annotations:
          summary: 'High CPU usage'
          description: "CPU usage is over 90% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
      - alert: (Memory Is Above Threshold of 90% for Auth Server )
        expr: 'avg_over_time(((windows_cs_physical_memory_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(as)[0-9]{2}$"} - windows_os_physical_memory_free_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(as)[0-9]{2}$"}) / windows_cs_physical_memory_bytes{instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(as)[0-9]{2}$"} * 100) [20m:1m]) > 90'
        for: 20m
        labels:
          severity: Critical
          route: pro_people_hcmservice
        annotations:
          summary: 'High Memory usage'
          description: "Memory usage is over 90% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
      - alert: (Disk Is Above Threshold of 90% for Auth Server )
        expr: |
          avg_over_time(
            max by (instance, volume) (
              (1 - (
                windows_logical_disk_free_bytes{volume!~"HarddiskVolume.*", job=~"integrations/windows_exporter", instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(as)[0-9]{2}$"}
                / windows_logical_disk_size_bytes{volume!~"HarddiskVolume.*", job=~"integrations/windows_exporter", instance=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(as)[0-9]{2}$"}
              )) * 100
            )[20m:]
          ) > 90
        for: 20m
        labels:
          severity: Critical
          route: pro_people_hcmservice
        annotations:
          summary: 'High Disk usage on {{ $labels.volume }}'
          description: "Disk usage for {{ $labels.volume }} on instance {{ $labels.instance }} is over 90% for the last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}%."
          __dashboardUid__: adz520xpm1m2od
   # pro people HCM Service Alerting for UES Service and Apps 
  - name: Pro people HCM Service alert UES Service
    rules:
      - alert: (UES 32 Bit Is Above Threshold)
        expr: '((memory_ratio{commandLine="\"D:/Program Files (x86)/US Group/UltiPro Enterprise Server/UltimateSoftware.Integration.ApplicationServer.WindowsService.exe\" \"Profile1\"", hostname=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(as)[0-9]{2}$"})/1000000000) > 4'
        for: 20m
        labels:
          severity: Critical
          route: pro_people_hcmservice_email
        annotations:
          summary: 'High Memory usage'
          description: "UES 32 Bit Has Reached Above Threshold in last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}GB."
          __dashboardUid__: ce34ofh3ki9dse
      - alert: (UES 64 Bit Is Above Threshold)
        expr: '((memory_ratio{commandLine="\"D:/Program Files (x86)/US Group/UltiPro Enterprise Server/UltimateSoftware.Integration.ApplicationServer.WindowsService64.exe\" \"Profile2\"", hostname=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(as)[0-9]{2}$"})/1000000000) > 12'
        for: 20m
        labels:
          severity: Critical
          route: pro_people_hcmservice_email
        annotations:
          summary: 'High Memory usage'
          description: "UES 64 Bit Has Reached Above Threshold in last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}GB."
          __dashboardUid__: ce34ofh3ki9dse
      - alert: (UES Customs Is Above Threshold)
        expr: '((memory_ratio{commandLine="\"D:/Program Files (x86)/US Group/UltiPro Enterprise Server/UltimateSoftware.Integration.ApplicationServer.WindowsService.exe\" \"Profile3\"", hostname=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(as)[0-9]{2}$"})/1000000000) > 4'
        for: 20m
        labels:
          severity: Critical
          route: pro_people_hcmservice_email
        annotations:
          summary: 'High Memory usage'
          description: "UES Customs Has Reached Above Threshold in last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}GB."
          __dashboardUid__: ce34ofh3ki9dse
  - name: Pro people HCM Service alert UltiproServices
    rules:
      - alert: (UltiproServices Application Is Above Threshold)
        expr: '((max by (hostname)(totalMem_ratio{commandLine="\"D:/Program Files (x86)/US Group/UltiPro Enterprise Server/UltimateSoftware.Integration.ApplicationServer.WindowsService64.exe\" \"Profile2\"", hostname=~"(?i)^(e[0-4]|ew[0-4]|n[0-4]|nw[0-4]|t[0-4]|tw[0-4]|g03).*(as)[0-9]{2}$", application="UltiProServices"}))/1000000000) > 1'
        for: 20m
        labels:
          severity: Critical
          route: pro_people_hcmservice_email
        annotations:
          summary: 'High Memory usage'
          description: "UltiproServices Application Has Reached Above Threshold in last 20 minutes. Current usage: {{ printf \"%.2f\" $value }}GB."
          __dashboardUid__: ce34ofh3ki9dse
          # Run rate Limiter suite alerting
  - name: (PROD) Run Rate suite queue above threshold
    rules:
      - alert: (ATL) Run Rate suite queue size is above 500)
        expr: '(sum(com_ultimatesoftware_service_kubeJobRequestService_noOfQueuedRequest_prometheus{datacenter="atl", stack="integration-run-rate-limiter"} >=0)) > 500'
        for: 5m
        labels:
          severity: Critical
          route: ist_prod
        annotations:
          summary: 'Run Rate suite queue size is above 500'
          description: "Run Rate limiter suite queue size is increased above 500 over the past 5 minutes."
          __dashboardUid__: ae0xtxcpyja4gf
          __panelId__: '20'
      - alert: (PLAS) Run Rate suite queue size is above 500)
        expr: '(sum(com_ultimatesoftware_service_kubeJobRequestService_noOfQueuedRequest_prometheus{datacenter="plas1", stack="integration-run-rate-limiter"} >= 0)) > 500'
        for: 5m
        labels:
          severity: Critical
          route: ist_prod
        annotations:
          summary: 'Run Rate suite queue size is above 500'
          description: "Run Rate limiter suite queue size is increased above 500 over the past 5 minutes."
          __dashboardUid__: ae0xtxcpyja4gf
          __panelId__: '18'
      - alert: (TOR) Run Rate suite queue size is above 500)
        expr: '(sum(com_ultimatesoftware_service_kubeJobRequestService_noOfQueuedRequest_prometheus{datacenter="tor", stack="integration-run-rate-limiter"} >0)) > 500'
        for: 5m
        labels:
          severity: Critical
          route: ist_prod
        annotations:
          summary: 'Run Rate suite queue size is above 500'
          description: "Run Rate limiter suite queue size is increased above 500 over the past 5 minutes."
          __dashboardUid__: ae0xtxcpyja4gf
          __panelId__: '21'
      - alert: (US-EAST1) Run Rate suite queue size is above 500)
        expr: '(sum(com_ultimatesoftware_service_kubeJobRequestService_noOfQueuedRequest_prometheus{datacenter="us-east1", stack="integration-run-rate-limiter"} >=0)) > 500'
        for: 5m
        labels:
          severity: Critical
          route: ist_prod
        annotations:
          summary: 'Run Rate suite queue size is above 500'
          description: "Run Rate limiter suite queue size is increased above 500 over the past 5 minutes."
          __dashboardUid__: ae0xtxcpyja4gf
          __panelId__: '17'
 # UKG Reporting hub 
  - name: UKG Reporting Hub - PROD
    rules:
      # Prod env
      - alert: (CRITICAL) UKG Reporting Hub - App Availability - PROD
        expr: (sum by(phase) (kube_pod_status_phase{namespace="ukg-reporting-hub", phase="Running"})) < 1
        for: 1m
        labels:
          severity: critical
          route: UKG_Reporting_hub_PD_mail
        annotations:
          summary: UKG Reporting Hub - All Pods Down - PROD
          description: "All Pods are down, for the application in the namespace ukg-reporting-hub. Please check and do the needful"
          __dashboardUid__: bdq49rcr931moa
      - alert: (WARNING) UKG Reporting Hub - Minimum Pods Availability - PROD
        expr: (kube_horizontalpodautoscaler_status_current_replicas{namespace="ukg-reporting-hub", horizontalpodautoscaler="ukg-reporting-hub"} - kube_horizontalpodautoscaler_spec_min_replicas{namespace="ukg-reporting-hub",horizontalpodautoscaler="ukg-reporting-hub"}) <0
        for: 5m
        labels:
          severity: critical
          route: UKG_Reporting_hub_PD_mail
        annotations:
          summary: UKG Reporting Hub - Min Pods Availability  - PROD
          description: "Number of running pods are less than minimum replicas defined for namespace ukg-reporting-hub. Please check and do the needful"
          __dashboardUid__: bdq49rcr931moa
      #Pre sales env
      - alert: (CRITICAL) UKG Reporting Hub - App Availability - PS
        expr: (sum by(phase) (kube_pod_status_phase{namespace="ukg-reporting-hub-ps", phase="Running"})) < 1
        for: 1m
        labels:
          severity: critical
          route: UKG_Reporting_hub_PD_mail
        annotations:
          summary: UKG Reporting Hub - All Pods Down - PS
          description: "All Pods are down, for the application in the namespace ukg-reporting-hub-ps. Please check and do the needful"
          __dashboardUid__: bdq49rcr931moa
      - alert: (WARNING) UKG Reporting Hub - Minimum Pods Availability - PS
        expr: (kube_horizontalpodautoscaler_status_current_replicas{namespace="ukg-reporting-hub-ps", horizontalpodautoscaler="ukg-reporting-hub"} - kube_horizontalpodautoscaler_spec_min_replicas{namespace="ukg-reporting-hub-ps",horizontalpodautoscaler="ukg-reporting-hub"}) <0
        for: 5m
        labels:
          severity: critical
          route: UKG_Reporting_hub_PD_mail
        annotations:
          summary: UKG Reporting Hub - Min Pods Availability  - PS
          description: "Number of running pods are less than minimum replicas defined for namespace ukg-reporting-hub-ps. Please check and do the needful"
          __dashboardUid__: bdq49rcr931moa
 # Data Dictionary Denodo Service Prod Alerts
  - name: Data Dictionary Denodo Service - PROD
    rules:
      - alert: (CRITICAL) Denodo Service - App Availability - PROD
        expr: (sum by(phase) (kube_pod_status_phase{namespace="denodo-prd", pod!~"denodo-service-green.*", phase="Running"})) < 1
        for: 5m
        labels:
          severity: critical
          route: Pagerduty_Denodo_Prod_Critical_route
        annotations:
          summary: All Pods are down for namespace {{ $labels.namespace }}
          description: "All Pods are down, for the application in the namespace {{ $labels.namespace }}. Please check and do the needful"
          SOP: "https://engconf.int.kronos.com/display/DPFI/SOP+for+All+Pods+are+down" 
          __dashboardUid__: b2a0317b-a509-41ad-8f5e-50615ebde7e2
          __panelId__: '40'
      - alert: (WARNING) Denodo Service - Minimum Pods Availability - PROD
        expr: (sum by(phase) (kube_pod_status_phase{namespace="denodo-prd", pod!~"denodo-service-green.*", phase="Running"})) < 2 > 2
        for: 5m
        labels:
          severity: warning
          route: Pagerduty_Denodo_Prod_Warning_route
        annotations:
          summary: Number of running Pods changed for {{ $labels.namespace }}
          description: "Either 1 or 3 Pods are running for the application in the namespace {{ $labels.namespace }}. Active pods are { $labels.pod }} .Please check and do the needful"
          SOP: "https://engconf.int.kronos.com/display/DPFI/SOP+for+All+Pods+are+down" 
          __dashboardUid__: b2a0317b-a509-41ad-8f5e-50615ebde7e2
          __panelId__: '40'
      - alert: (WARNING) Denodo Service - High CPU Usage - PROD
        expr: ((sum by(pod) (rate(container_cpu_usage_seconds_total{namespace="denodo-prd", container="denodo-service"}[5m])) * 100) / sum by(pod) (kube_pod_container_resource_requests{namespace="denodo-prd", container=~"denodo-service", resource="cpu"})) >= 30 < 75
        for: 15m
        labels:
          severity: warning
          route: Pagerduty_Denodo_Prod_Warning_route
        annotations:
          summary: CPU Usage Above 30% for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}
          description: "CPU Usage is above 30% from last 15 mins for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}. Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/DPFI/SOP+for+CPU+Usage+Alert+SOP"   
          __dashboardUid__: b2a0317b-a509-41ad-8f5e-50615ebde7e2
          __panelId__: '35'                    
      - alert: (CRITICAL) Denodo Service - High CPU Usage - PROD
        expr: ((sum by(container) (rate(container_cpu_usage_seconds_total{namespace="denodo-prd", container="denodo-service"}[5m])) * 100) / sum by(container) (kube_pod_container_resource_requests{namespace="denodo-prd", container=~"denodo-service", resource="cpu"})) >= 75
        for: 15m
        labels:
          severity: critical
          route: Pagerduty_Denodo_Prod_Critical_route
        annotations:
          summary: CPU Usage Above 75% for {{ $labels.container }}  in {{ $labels.namespace }}
          description: "CPU Usage is above 75% from last 15 mins for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}. Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/DPFI/SOP+for+CPU+Usage+Alert+SOP"   
          __dashboardUid__: b2a0317b-a509-41ad-8f5e-50615ebde7e2
          __panelId__: '35' 
      - alert: (WARNING) Denodo Service - High Memory Utilization - PROD
        expr: ((sum by(pod) (container_memory_working_set_bytes{namespace="denodo-prd", container="denodo-service"}) * 100) / sum by(pod) (kube_pod_container_resource_requests{namespace="denodo-prd", container="denodo-service", resource="memory"})) >= 75 < 90
        for: 15m
        labels:
          severity: warning
          route: Pagerduty_Denodo_Prod_Warning_route
        annotations:
          summary: Memory Usage Above 75% for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}
          description: "Memory Usage is above 75% from last 15 mins for {{ $labels.container }} / {{ $labels.pod }} in {{ $labels.namespace }}. Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/DPFI/SOP+for+Memory+Usage+Alert+SOP"
          __dashboardUid__: b2a0317b-a509-41ad-8f5e-50615ebde7e2
          __panelId__: '36'
      - alert: (CRITICAL) Denodo Service - High Memory Utilization - PROD
        expr: ((sum by(container) (container_memory_working_set_bytes{namespace="denodo-prd", container="denodo-service"}) * 100) / sum by(container) (kube_pod_container_resource_requests{namespace="denodo-prd", container="denodo-service", resource="memory"})) >= 90
        for: 15m
        labels:
          severity: critical
          route: Pagerduty_Denodo_Prod_Critical_route
        annotations:
          summary: Memory Usage Above 90% for {{ $labels.container }} in {{ $labels.namespace }}
          description: "Memory Usage is above 90% from last 15 mins for {{ $labels.container }} in {{ $labels.namespace }}. Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/DPFI/SOP+for+Memory+Usage+Alert+SOP"
          __dashboardUid__: b2a0317b-a509-41ad-8f5e-50615ebde7e2
          __panelId__: '36'
      - alert: (CRITICAL) Denodo Service - Container Restarts - PROD
        expr: (sum by(container) (increase(kube_pod_container_status_restarts_total{namespace="denodo-prd", container=~"denodo-service"}[2m]))) > 0
        for: 5m
        labels:
          severity: critical
          route: Pagerduty_Denodo_Prod_Critical_route
        annotations:
          summary: Container is getting restarted for Container -  {{ $labels.container }} Namespace - {{ $labels.namespace }}
          description: "Container is getting restarted for Container -  {{ $labels.container }} Namespace - {{ $labels.namespace }}  Please follow the SOP."
          SOP: "https://engconf.int.kronos.com/display/DPFI/SOP+for+Memory+Usage+Alert+SOP"  
          __dashboardUid__: b2a0317b-a509-41ad-8f5e-50615ebde7e2
          __panelId__: '37'
  - name: HCM Core Eventing - Eventhub Alerts
    rules:
      - alert: Eventhub K8s - ATL Sales Stg - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="atl", namespace="mp-eh-sales-stg", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_UAT_MS_Teams
        annotations:
          summary: Eventhub K8s - ATL Sales Stg - Pod(s) not in a running phase
          description: "Eventhub K8s - ATL Sales Stg - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: Eventhub K8s - ATL Sales Prod - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="atl", namespace="mp-eh-sales", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: Eventhub K8s - ATL Sales Prod - Pod(s) not in a running phase
          description: "Eventhub K8s - ATL Sales Prod - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: Eventhub K8s - ATL Stg - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="atl", namespace="mp-eh-stg", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_UAT_MS_Teams
        annotations:
          summary: Eventhub K8s - ATL Stg - Pod(s) not in a running phase
          description: "Eventhub K8s - ATL Stg - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: Eventhub K8s - ATL Prod - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="atl", namespace="mp-eh-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: Eventhub K8s - ATL Prod - Pod(s) not in a running phase
          description: "Eventhub K8s - ATL Prod - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: Eventhub K8s - PLAS1 Prod - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="plas1", namespace="mp-eh-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: Eventhub K8s - PLAS1 Prod - Pod(s) not in a running phase
          description: "Eventhub K8s - PLAS1 Prod - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: Eventhub K8s - TOR Prod - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="tor", namespace="mp-eh-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: Eventhub K8s - TOR Prod - Pod(s) not in a running phase
          description: "Eventhub K8s - TOR Prod - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: Eventhub K8s - US-EAST1 Prod - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="us-east1", namespace="mp-eh-prod", phase!="Running"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: Eventhub K8s - US-EAST1 Prod - Pod(s) not in a running phase
          description: "Eventhub K8s - US-EAST1 Prod - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
  - name: HCM Core Eventing - Thin Event Adapter Alerts
    rules:
      - alert: ThinEventAdapter K8s - ATL Sales Stg - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="atl", namespace="cevt-salesdemo-staging", phase!="Running", pod=~"^thin-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: ThinEventAdapter K8s - ATL Sales Stg - Pod(s) not in a running phase
          description: "ThinEventAdapter K8s - ATL Sales Stg - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: ThinEventAdapter K8s - ATL Stg - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="atl", namespace="cevt-uat", phase!="Running", pod=~"^thin-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: ThinEventAdapter K8s - ATL Stg - Pod(s) not in a running phase
          description: "ThinEventAdapter K8s - ATL Stg - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: ThinEventAdapter K8s - PLAS1 Stg - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="plas1", namespace="cevt-uat", phase!="Running", pod=~"^thin-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: ThinEventAdapter K8s - PLAS1 Stg - Pod(s) not in a running phase
          description: "ThinEventAdapter K8s - PLAS1 Stg - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: ThinEventAdapter K8s - TOR Stg - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="tor", namespace="cevt-uat", phase!="Running", pod=~"^thin-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: ThinEventAdapter K8s - TOR Stg - Pod(s) not in a running phase
          description: "ThinEventAdapter K8s - TOR Stg - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: ThinEventAdapter K8s - ATL - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="atl", namespace="cevt-prod", phase!="Running", pod=~"^thin-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: ThinEventAdapter K8s - ATL - Pod(s) not in a running phase
          description: "ThinEventAdapter K8s - ATL - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: ThinEventAdapter K8s - PLAS1 - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="plas1", namespace="cevt-prod", phase!="Running", pod=~"^thin-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: ThinEventAdapter K8s - PLAS1 - Pod(s) not in a running phase
          description: "ThinEventAdapter K8s - PLAS1 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: ThinEventAdapter K8s - TOR - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="tor", namespace="cevt-prod", phase!="Running", pod=~"^thin-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: ThinEventAdapter K8s - TOR - Pod(s) not in a running phase
          description: "ThinEventAdapter K8s - TOR - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: ThinEventAdapter K8s - US-EAST1 - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="us-east1", namespace="cevt-prod", phase!="Running" , pod=~"^thin-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: ThinEventAdapter K8s - US-EAST1 - Pod(s) not in a running phase
          description: "ThinEventAdapter K8s - US-EAST1 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: ThinEventAdapter K8s - US-EAST4 - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="us-east4", namespace="cevt-prod", phase!="Running" , pod=~"^thin-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: ThinEventAdapter K8s - US-EAST4 - Pod(s) not in a running phase
          description: "ThinEventAdapter K8s - US-EAST4 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
  - name: HCM Core Eventing - Staging Event Adapter Alerts
    rules:
      - alert: StagingEventAdapter K8s - ATL Sales Stg - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="atl", namespace="cevt-salesdemo-staging", phase!="Running", pod=~"^staging-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: StagingEventAdapter K8s - ATL Sales Stg - Pod(s) not in a running phase
          description: "StagingEventAdapter K8s - ATL Sales Stg - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: StagingEventAdapter K8s - ATL Stg - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="atl", namespace="cevt-uat", phase!="Running", pod=~"^staging-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: StagingEventAdapter K8s - ATL Stg - Pod(s) not in a running phase
          description: "StagingEventAdapter K8s - ATL Stg - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: StagingEventAdapter K8s - PLAS1 Stg - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="plas1", namespace="cevt-uat", phase!="Running", pod=~"^staging-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: StagingEventAdapter K8s - PLAS1 Stg - Pod(s) not in a running phase
          description: "StagingEventAdapter K8s - PLAS1 Stg - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: StagingEventAdapter K8s - TOR Stg - Pod Status Phase
        expr: sum by(pod) (kube_pod_status_phase{datacenter="tor", namespace="cevt-uat", phase!="Running", pod=~"^staging-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: StagingEventAdapter K8s - TOR Stg - Pod(s) not in a running phase
          description: "StagingEventAdapter K8s - TOR Stg - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: StagingEventAdapter K8s - ATL - Pod Status Phase
        expr: sum by (pod) (kube_pod_status_phase{datacenter="atl", namespace="cevt-prod", phase!="Running" , pod=~"^staging-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: StagingEventAdapter K8s - ATL - Pod(s) not in a running phase
          description: "StagingEventAdapter K8s - ATL - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: StagingEventAdapter K8s - PLAS1 - Pod Status Phase
        expr: sum by (pod) (kube_pod_status_phase{datacenter="plas1", namespace="cevt-prod", phase!="Running" , pod=~"^staging-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: StagingEventAdapter K8s - PLAS1 - Pod(s) not in a running phase
          description: "StagingEventAdapter K8s - PLAS1 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: StagingEventAdapter K8s - TOR - Pod Status Phase
        expr: sum by (pod) (kube_pod_status_phase{datacenter="tor", namespace="cevt-prod", phase!="Running" , pod=~"^staging-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: StagingEventAdapter K8s - TOR - Pod(s) not in a running phase
          description: "StagingEventAdapter K8s - TOR - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: StagingEventAdapter K8s - US-EAST1 - Pod Status Phase
        expr: sum by (pod) (kube_pod_status_phase{datacenter="us-east1", namespace="cevt-prod", phase!="Running" , pod=~"^staging-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: StagingEventAdapter K8s - US-EAST1 - Pod(s) not in a running phase
          description: "StagingEventAdapter K8s - US-EAST1 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
      - alert: StagingEventAdapter K8s - US-EAST4 - Pod Status Phase
        expr: sum by (pod) (kube_pod_status_phase{datacenter="us-east4", namespace="cevt-prod", phase!="Running" , pod=~"^staging-event-adapter.*"}) > 0
        for: 30s
        labels:
          severity: critical
          route: Eventing_Prod_MS_Teams
        annotations:
          summary: StagingEventAdapter K8s - US-EAST4 - Pod(s) not in a running phase
          description: "StagingEventAdapter K8s - US-EAST4 - {{ $value }} pod(s) not in a running phase"
          __dashboardUid__: ee396pc9yzvgga
          __panelId__: '2'
  # UKG Webhooks Infra Alerts
  - name: UKG Webhooks Infra Alerts - PROD
    rules:
      - alert: (CRITICAL) UKG Webhooks - CPU Usage
        expr: ((sum by (datacenter, pod, container, namespace)(rate(container_cpu_usage_seconds_total{datacenter=~"us-east1|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"ukg-webhooks-prod|ukg-webhooks-uat", container!~"nginx|istio-proxy", container=~"ukg-webhooks.*"}[5m]))) / sum by (datacenter, pod, container, namespace)(kube_pod_container_resource_requests{datacenter=~"us-east1|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"ukg-webhooks-prod|ukg-webhooks-uat", container!~"nginx|istio-proxy", resource="cpu", container=~"ukg-webhooks.*"}) * 100) >= 80
        for: 15m
        labels:
          severity: critical
          route: ukg_webhooks_mail
        annotations:
          summary: "CPU usage is more than 80% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "CPU usage is more than 80% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          __dashboardUid__: cdyuvrnnarmdce
      - alert: (WARNING) UKG Webhooks - CPU Usage
        expr: ((sum by (datacenter, pod, container, namespace)(rate(container_cpu_usage_seconds_total{datacenter=~"us-east1|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"ukg-webhooks-prod|ukg-webhooks-uat", container!~"nginx|istio-proxy", container=~"ukg-webhooks.*"}[5m]))) / sum by (datacenter, pod, container, namespace)(kube_pod_container_resource_requests{datacenter=~"us-east1|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"ukg-webhooks-prod|ukg-webhooks-uat", container!~"nginx|istio-proxy", resource="cpu", container=~"ukg-webhooks.*"}) * 100) >= 70
        for: 5m
        labels:
          severity: warning
          route: ukg_webhooks_mail
        annotations:
          summary: "CPU usage is more than 70% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "CPU usage is more than 70% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          __dashboardUid__: cdyuvrnnarmdce
      - alert: (CRITICAL) UKG Webhooks - Memory Usage
        expr: ((sum by (datacenter, pod, container, namespace)(container_memory_working_set_bytes{datacenter=~"us-east1|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"ukg-webhooks-prod|ukg-webhooks-uat", container!~"nginx|istio-proxy", container=~"ukg-webhooks.*"})) / sum by (datacenter, pod, container, namespace)(kube_pod_container_resource_limits{datacenter=~"us-east1|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"ukg-webhooks-prod|ukg-webhooks-uat", container!~"nginx|istio-proxy", resource="memory", container=~"ukg-webhooks.*"}) * 100) >= 80
        for: 15m
        labels:
          severity: critical
          route: ukg_webhooks_mail
        annotations:
          summary: "Memory usage is more than 80% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "Memory usage is more than 80% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          __dashboardUid__: cdyuvrnnarmdce
      - alert: (WARNING) UKG Webhooks - Memory Usage
        expr: ((sum by (datacenter, pod, container, namespace)(container_memory_working_set_bytes{datacenter=~"us-east1|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"ukg-webhooks-prod|ukg-webhooks-uat", container!~"nginx|istio-proxy", container=~"ukg-webhooks.*"})) / sum by (datacenter, pod, container, namespace)(kube_pod_container_resource_limits{datacenter=~"us-east1|northamerica-northeast1|europe-west4|australia-southeast1", namespace=~"ukg-webhooks-prod|ukg-webhooks-uat", container!~"nginx|istio-proxy", resource="memory", container=~"ukg-webhooks.*"}) * 100) >= 70
        for: 15m
        labels:
          severity: warning
          route: ukg_webhooks_mail
        annotations:
          summary: "Memory usage is more than 70% for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "Memory usage is more than 70% for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          __dashboardUid__: cdyuvrnnarmdce
      - alert: (CRITICAL) UKG Webhooks - Pod Replica Unavailability
        expr: ((sum by(deployment, datacenter, namespace) (kube_deployment_spec_replicas{namespace=~"ukg-webhooks-prod|ukg-webhooks-uat", datacenter=~"us-east1|northamerica-northeast1|europe-west4|australia-southeast1", deployment=~"ukg-webhooks.*"})) - (sum by (deployment, datacenter, namespace)(kube_deployment_status_replicas_available{namespace=~"ukg-webhooks-prod|ukg-webhooks-uat", datacenter=~"us-east1|northamerica-northeast1|europe-west4|australia-southeast1", deployment=~"ukg-webhooks.*"}))) > 0
        for: 15m
        labels:
          severity: critical
          route: ukg_webhooks_mail
        annotations:
          summary: "Pod Replica is less than expected for {{ $labels.deployment }} in {{ $labels.datacenter }}"
          description: "Pod Replica is less than expected for Deployment: {{ $labels.deployment }}, Datacenter: {{ $labels.datacenter }}, Namespace: {{ $labels.namespace }}"
          __dashboardUid__: cdyuvrnnarmdce
      - alert: (CRITICAL) UKG Webhooks - Pod Container Restarts
        expr: (sum by (pod, container, datacenter, namespace)(increase(kube_pod_container_status_restarts_total{namespace=~"ukg-webhooks-prod|ukg-webhooks-uat", container!~"nginx|istio-proxy", datacenter=~"us-east1|northamerica-northeast1|europe-west4|australia-southeast1", container=~"ukg-webhooks.*"}[10m]))) > 2
        for: 15m
        labels:
          severity: critical
          route: ukg_webhooks_mail
        annotations:
          summary: "Pod Container has been restarted more than twice for {{ $labels.container }} in {{ $labels.datacenter }}"
          description: "Pod Container has been restarted more than twice for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          __dashboardUid__: cdyuvrnnarmdce
  # Pro Recruiting Infra Alerts
  - name: Pro Recruiting Infra Alerts - PROD
    rules:
      - alert: (P2 - CRITICAL) Deployment Replica Not Running at 100 %
        expr: sum by (datacenter, namespace, deployment) (kube_deployment_status_replicas_available{datacenter=~"atl|plas1|tor|us-east1", namespace=~"^rec-.*-prod$", deployment=~"^rec.*"}) / sum by (datacenter, namespace, deployment) (kube_deployment_spec_replicas{datacenter=~"atl|plas1|tor|us-east1", namespace=~"^rec-.*-prod$", deployment=~"^rec.*"}) * 100 < 100
        for: 5m
        labels:
          severity: critical
          route: pro_recruiting
        annotations:
          summary: "Monitoring has detected deployment replicas not running at 100% for {{ $labels.deployment }} in {{ $labels.namespace }}"
          description: "Monitoring has detected deployment replicas not running at 100% for: Datacenter: {{ $labels.datacenter }}, Namespace: {{ $labels.namespace }}, Deployment: {{ $labels.deployment }}"
          __dashboardUid__: fdfh4wr47u5tsb
      - alert: (P2 - CRITICAL) Pod Container Restarts
        expr: sum (increase(kube_pod_container_status_restarts_total{namespace=~"^rec-.*-prod$", datacenter=~"atl|plas1|tor|us-east1", container=~"rec-.*"}[5m])) by (pod, datacenter, namespace, container) > 3
        for: 10m
        labels:
          severity: critical
          route: pro_recruiting
        annotations:
          summary: "Pod Container has been restarted more than thrice for the container {{ $labels.container }} in datacenter {{ $labels.datacenter }}"
          description: "Pod Container has been restarted more than thrice for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}" 
          __dashboardUid__: fdfh4wr47u5tsb        
# HRSD Alerts
  - name: HRSD PRO Integration Failure Alerts
    rules:
      - alert: HRSD PRO Integration Failure 
        expr: 'sum(ulti_metrics_hrsd_pro_integration_error_counter_total{cluster_name=~"kc-p-fleet-.*", instance="mule-integration-hrsd-dev", environment=~"prod-.*"} > 0)'
        for: 5m
        labels:
          severity: Critical
          route: HrsdCoreAlert
        annotations:
          summary: HRSD PRO Integration Failure Alerts for [{{ $labels.environment }}]
          description: "[{{ $labels.environment }}] HRSD PRO Integration Failure for {{ $labels.tenant }}."
          __dashboardUid__: fdzu3wb1dyepsd
          __panelId__: '3'
      - alert: HRSD PRO Integration SFTP Failure 
        expr: 'sum(ulti_metrics_hrsd_pro_integration_sftp_error_counter_total{cluster_name=~"kc-p-fleet-.*", instance="mule-integration-hrsd-dev", environment=~"prod-.*"} > 0)'
        for: 5m
        labels:
          severity: Critical
          route: HrsdCoreAlert
        annotations:
          summary: HRSD PRO Integration SFTP Failure Alerts for [{{ $labels.environment }}]
          description: "[{{ $labels.environment }}] HRSD PRO Integration SFTP Failure for {{ $labels.tenant }}."
          __dashboardUid__: fdzu3wb1dyepsd
          __panelId__: '4'
      - alert: HRSD PRO Integration FileArchive Failure 
        expr: 'sum(ulti_metrics_hrsd_pro_integration_tip_filearchive_error_counter_total{cluster_name=~"kc-p-fleet-.*", instance="mule-integration-hrsd-dev", environment=~"prod-.*"} > 0)'
        for: 5m
        labels:
          severity: Critical
          route: HrsdCoreAlert
        annotations:
          summary: HRSD PRO Integration FileArchive Failure Alerts for [{{ $labels.environment }}]
          description: "[{{ $labels.environment }}] HRSD PRO Integration FileArchive Failure for {{ $labels.tenant }}."
          __dashboardUid__: fdzu3wb1dyepsd
          __panelId__: '5'
  # Pro Recruiting Infra Alerts
  - name: Pro Recruiting Infra Alerts - Staging
    rules:
      - alert: (P2 - CRITICAL) Staging Deployment Replica Not Running at 100 %
        expr: sum by (datacenter, namespace, deployment) (kube_deployment_status_replicas_available{datacenter=~"atl|plas1|tor|us-east1", namespace=~"^rec-[a-z]+-staging", deployment=~"^rec.*"}) / sum by (datacenter, namespace, deployment) (kube_deployment_spec_replicas{datacenter=~"atl|plas1|tor|us-east1", namespace=~"^rec-[a-z]+-staging", deployment=~"^rec.*"}) * 100 < 100
        for: 5m
        labels:
          severity: critical
          route: pro_recruiting
        annotations:
          summary: "Monitoring has detected deployment replicas not running at 100% for {{ $labels.deployment }} in {{ $labels.namespace }}"
          description: "Monitoring has detected deployment replicas not running at 100% for: Datacenter: {{ $labels.datacenter }}, Namespace: {{ $labels.namespace }}, Deployment: {{ $labels.deployment }}"
          __dashboardUid__: fdfh4wr47u5tsb
      - alert: (P2 - CRITICAL) Pod Container Restarts
        expr: sum (increase(kube_pod_container_status_restarts_total{namespace=~"^rec-[a-z]+-staging", datacenter=~"atl|plas1|tor|us-east1", container=~"rec-.*"}[5m])) by (pod, datacenter, namespace, container) > 3
        for: 10m
        labels:
          severity: critical
          route: pro_recruiting
        annotations:
          summary: "Pod Container has been restarted more than thrice for the container {{ $labels.container }} in datacenter {{ $labels.datacenter }}"
          description: "Pod Container has been restarted more than thrice for Container: {{ $labels.container }}, Datacenter: {{ $labels.datacenter }}, Pod: {{ $labels.pod }}, Namespace: {{ $labels.namespace }}"
          __dashboardUid__: fdfh4wr47u5tsb

  # Forgot Username Frontend Alerts
  - name: IAM - UKG AuthN - Forgot Username Frontend Alerts - PROD USEAST1
    rules:
      - alert: (P2 - CRITICAL) Forgot Username Frontend CPU Utilization
        expr: (sum(rate(container_cpu_usage_seconds_total{namespace="ukg-authn-prod-us-east1", pod=~".*forgot-username-frontend.*"}[1m])) / sum (kube_pod_container_resource_requests{namespace="ukg-authn-prod-us-east1", pod=~".*forgot-username-frontend.*", resource="cpu"}) * 100) >= 80
        for: 5m
        labels:
          severity: critical
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: Forgot Username Frontend - CPU Usage Above 80%
          description: "CPU Usage is above 80% from last 5 mins."
          __dashboardUid__: ae5xct5wdxgqof
          __panelId__: '7'
      - alert: (P3 - WARNING) Forgot Username Frontend CPU Utilization - PROD USEAST1
        expr: (sum(rate(container_cpu_usage_seconds_total{namespace="ukg-authn-prod-us-east1", pod=~".*forgot-username-frontend.*"}[1m])) / sum (kube_pod_container_resource_requests{namespace="ukg-authn-prod-us-east1", pod=~".*forgot-username-frontend.*", resource="cpu"}) * 100) >= 70
        for: 5m
        labels:
          severity: warning
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: Forgot Username Frontend - CPU Usage Above 70%
          description: "CPU Usage is above 70% from last 5 mins."
          __dashboardUid__: ae5xct5wdxgqof
          __panelId__: '7'
      - alert: (P2 - CRITICAL) Forgot Username Frontend Memory Utilization - PROD USEAST1
        expr: (sum (container_memory_working_set_bytes{namespace="ukg-authn-prod-us-east1", pod=~".*forgot-username-frontend.*"}) / sum (kube_pod_container_resource_requests{namespace="ukg-authn-prod-us-east1", pod=~".*forgot-username-frontend.*", resource="memory"}) * 100) >= 80
        for: 5m
        labels:
          severity: critical
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: Forgot Username Frontend - Memory Usage Above 80%
          description: "Memory Usage is above 80% from last 5 mins."
          __dashboardUid__: ae5xct5wdxgqof
          __panelId__: '8'
      - alert: (P3 - WARNING) Forgot Username Frontend Memory Utilization - PROD USEAST1
        expr: (sum (container_memory_working_set_bytes{namespace="ukg-authn-prod-us-east1", pod=~".*forgot-username-frontend.*"}) / sum (kube_pod_container_resource_requests{namespace="ukg-authn-prod-us-east1", pod=~".*forgot-username-frontend.*", resource="memory"}) * 100) >= 70
        for: 5m
        labels:
          severity: warning
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: Forgot Username Frontend - Memory Usage Above 70%
          description: "Memory Usage is above 70% from last 5 mins."
          __dashboardUid__: ae5xct5wdxgqof
          __panelId__: '8'
      - alert: (P1 - CRITICAL) Forgot Username Frontend Pod Availability - PROD USEAST1
        expr: (sum(kube_pod_status_phase{namespace="ukg-authn-prod-us-east1", pod=~".*forgot-username-frontend.*", phase="Running"}) < 1)
        for: 5m
        labels:
          severity: critical
          route: UKG-Authn-Pagerduty-Mail
        annotations:
          summary: Migration Tool Frontend - All Replicas Down
          description: "All Replicas Down from last 5 mins."
          __dashboardUid__: ae5xct5wdxgqof
          __panelId__: '13'
